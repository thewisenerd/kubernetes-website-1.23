<!doctype html><html lang=en class=no-js>
<head>
<meta name=ROBOTS content="NOINDEX, NOFOLLOW">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-JPP6RFM2BP"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date),gtag('config','G-JPP6RFM2BP')</script>
<link rel=alternate hreflang=zh href=https://kubernetes.io/zh/docs/tasks/administer-cluster/kubeadm/>
<link rel=alternate hreflang=ko href=https://kubernetes.io/ko/docs/tasks/administer-cluster/kubeadm/>
<link rel=alternate hreflang=ja href=https://kubernetes.io/ja/docs/tasks/administer-cluster/kubeadm/>
<link rel=alternate hreflang=fr href=https://kubernetes.io/fr/docs/tasks/administer-cluster/kubeadm/>
<link rel=alternate hreflang=de href=https://kubernetes.io/de/docs/tasks/administer-cluster/kubeadm/>
<link rel=alternate hreflang=es href=https://kubernetes.io/es/docs/tasks/administer-cluster/kubeadm/>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=generator content="Hugo 0.87.0">
<link rel=canonical type=text/html href=https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/>
<link rel="shortcut icon" type=image/png href=/images/favicon.png>
<link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180>
<link rel=manifest href=/manifest.webmanifest>
<link rel=apple-touch-icon href=/images/kubernetes-192x192.png>
<title>Administration with kubeadm | Kubernetes</title><meta property="og:title" content="Administration with kubeadm">
<meta property="og:description" content="Production-Grade Container Orchestration">
<meta property="og:type" content="website">
<meta property="og:url" content="https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/"><meta property="og:site_name" content="Kubernetes">
<meta itemprop=name content="Administration with kubeadm">
<meta itemprop=description content="Production-Grade Container Orchestration"><meta name=twitter:card content="summary">
<meta name=twitter:title content="Administration with kubeadm">
<meta name=twitter:description content="Production-Grade Container Orchestration">
<link href=/scss/main.css rel=stylesheet>
<script src=/js/jquery-3.3.1.min.js integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin=anonymous></script>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","url":"https://kubernetes.io","logo":"https://kubernetes.io/images/favicon.png"}</script>
<meta name=theme-color content="#326ce5">
<link rel=stylesheet href=/css/feature-states.css>
<meta name=description content>
<meta property="og:description" content>
<meta name=twitter:description content>
<meta property="og:url" content="https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/">
<meta property="og:title" content="Administration with kubeadm">
<meta name=twitter:title content="Administration with kubeadm">
<meta name=twitter:image content="https://kubernetes.io/images/favicon.png">
<meta name=twitter:image:alt content="Kubernetes">
<meta property="og:image" content="/images/kubernetes-horizontal-color.png">
<meta property="og:type" content="article">
<script src=/js/script.js></script>
</head>
<body class=td-section>
<header>
<nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar" data-auto-burger=primary>
<a class=navbar-brand href=/></a>
<div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar>
<ul class="navbar-nav mt-2 mt-lg-0">
<li class="nav-item mr-2 mb-lg-0">
<a class="nav-link active" href=/docs/>Documentation</a>
</li>
<li class="nav-item mr-2 mb-lg-0">
<a class=nav-link href=/blog/>Kubernetes Blog</a>
</li>
<li class="nav-item mr-2 mb-lg-0">
<a class=nav-link href=/training/>Training</a>
</li>
<li class="nav-item mr-2 mb-lg-0">
<a class=nav-link href=/partners/>Partners</a>
</li>
<li class="nav-item mr-2 mb-lg-0">
<a class=nav-link href=/community/>Community</a>
</li>
<li class="nav-item mr-2 mb-lg-0">
<a class=nav-link href=/case-studies/>Case Studies</a>
</li>
<li class="nav-item dropdown">
<a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>
Versions
</a>
<div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink>
<a class=dropdown-item href=/releases>Release Information</a>
<a class=dropdown-item href=https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/>v1.27</a>
<a class=dropdown-item href=https://v1-26.docs.kubernetes.io/docs/tasks/administer-cluster/kubeadm/>v1.26</a>
<a class=dropdown-item href=https://v1-25.docs.kubernetes.io/docs/tasks/administer-cluster/kubeadm/>v1.25</a>
<a class=dropdown-item href=https://v1-24.docs.kubernetes.io/docs/tasks/administer-cluster/kubeadm/>v1.24</a>
<a class=dropdown-item href=https://v1-23.docs.kubernetes.io/docs/tasks/administer-cluster/kubeadm/>v1.23</a>
</div>
</li>
<li class="nav-item dropdown">
<a class="nav-link dropdown-toggle" href=# id=navbarDropdownMenuLink role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>
English
</a>
<div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink>
<a class=dropdown-item href=/zh/docs/tasks/administer-cluster/kubeadm/>中文 Chinese</a>
<a class=dropdown-item href=/ko/docs/tasks/administer-cluster/kubeadm/>한국어 Korean</a>
<a class=dropdown-item href=/ja/docs/tasks/administer-cluster/kubeadm/>日本語 Japanese</a>
<a class=dropdown-item href=/fr/docs/tasks/administer-cluster/kubeadm/>Français</a>
<a class=dropdown-item href=/de/docs/tasks/administer-cluster/kubeadm/>Deutsch</a>
<a class=dropdown-item href=/es/docs/tasks/administer-cluster/kubeadm/>Español</a>
</div>
</li>
</ul>
</div>
<button id=hamburger onclick=kub.toggleMenu() data-auto-burger-exclude><div></div></button>
</nav>
</header>
<div class="container-fluid td-outer">
<div class=td-main>
<div class="row flex-xl-nowrap">
<main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main>
<div class=td-content>
<div class="pageinfo pageinfo-primary d-print-none">
<p>
This is the multi-page printable view of this section.
<a href=# onclick="return print(),!1">Click here to print</a>.
</p><p>
<a href=/docs/tasks/administer-cluster/kubeadm/>Return to the regular view of this page</a>.
</p>
</div>
<h1 class=title>Administration with kubeadm</h1>
<ul>
<li>1: <a href=#pg-f62fba1de4084f3be070785757c8079c>Certificate Management with kubeadm</a></li>
<li>2: <a href=#pg-6134c5061298affa145ddb801b5c29da>Configuring a cgroup driver</a></li>
<li>3: <a href=#pg-98530eb3653d28fef34bff4543364aa7>Reconfiguring a kubeadm cluster</a></li>
<li>4: <a href=#pg-2e173356df5179cab9eec90a606f0aa4>Upgrading kubeadm clusters</a></li>
<li>5: <a href=#pg-9133578f1e75663bb031e5a377ca896d>Adding Windows nodes</a></li>
<li>6: <a href=#pg-e805c7d8d4ad6195cb82dbbc843bfc29>Upgrading Windows nodes</a></li>
</ul>
<div class=content>
</div>
</div>
<div class=td-content>
<h1 id=pg-f62fba1de4084f3be070785757c8079c>1 - Certificate Management with kubeadm</h1>
<div style=margin-top:10px;margin-bottom:10px>
<b>FEATURE STATE:</b> <code>Kubernetes v1.15 [stable]</code>
</div>
<p>Client certificates generated by <a href=/docs/reference/setup-tools/kubeadm/>kubeadm</a> expire after 1 year.
This page explains how to manage certificate renewals with kubeadm. It also covers other tasks related
to kubeadm certificate management.</p>
<h2 id=before-you-begin>Before you begin</h2>
<p>You should be familiar with <a href=/docs/setup/best-practices/certificates/>PKI certificates and requirements in Kubernetes</a>.</p>
<h2 id=custom-certificates>Using custom certificates</h2>
<p>By default, kubeadm generates all the certificates needed for a cluster to run.
You can override this behavior by providing your own certificates.</p>
<p>To do so, you must place them in whatever directory is specified by the
<code>--cert-dir</code> flag or the <code>certificatesDir</code> field of kubeadm's <code>ClusterConfiguration</code>.
By default this is <code>/etc/kubernetes/pki</code>.</p>
<p>If a given certificate and private key pair exists before running <code>kubeadm init</code>,
kubeadm does not overwrite them. This means you can, for example, copy an existing
CA into <code>/etc/kubernetes/pki/ca.crt</code> and <code>/etc/kubernetes/pki/ca.key</code>,
and kubeadm will use this CA for signing the rest of the certificates.</p>
<h2 id=external-ca-mode>External CA mode</h2>
<p>It is also possible to provide only the <code>ca.crt</code> file and not the
<code>ca.key</code> file (this is only available for the root CA file, not other cert pairs).
If all other certificates and kubeconfig files are in place, kubeadm recognizes
this condition and activates the "External CA" mode. kubeadm will proceed without the
CA key on disk.</p>
<p>Instead, run the controller-manager standalone with <code>--controllers=csrsigner</code> and
point to the CA certificate and key.</p>
<p><a href=/docs/setup/best-practices/certificates/>PKI certificates and requirements</a> includes guidance on
setting up a cluster to use an external CA.</p>
<h2 id=check-certificate-expiration>Check certificate expiration</h2>
<p>You can use the <code>check-expiration</code> subcommand to check when certificates expire:</p>
<pre><code>kubeadm certs check-expiration
</code></pre><p>The output is similar to this:</p>
<pre><code>CERTIFICATE                EXPIRES                  RESIDUAL TIME   CERTIFICATE AUTHORITY   EXTERNALLY MANAGED
admin.conf                 Dec 30, 2020 23:36 UTC   364d                                    no
apiserver                  Dec 30, 2020 23:36 UTC   364d            ca                      no
apiserver-etcd-client      Dec 30, 2020 23:36 UTC   364d            etcd-ca                 no
apiserver-kubelet-client   Dec 30, 2020 23:36 UTC   364d            ca                      no
controller-manager.conf    Dec 30, 2020 23:36 UTC   364d                                    no
etcd-healthcheck-client    Dec 30, 2020 23:36 UTC   364d            etcd-ca                 no
etcd-peer                  Dec 30, 2020 23:36 UTC   364d            etcd-ca                 no
etcd-server                Dec 30, 2020 23:36 UTC   364d            etcd-ca                 no
front-proxy-client         Dec 30, 2020 23:36 UTC   364d            front-proxy-ca          no
scheduler.conf             Dec 30, 2020 23:36 UTC   364d                                    no

CERTIFICATE AUTHORITY   EXPIRES                  RESIDUAL TIME   EXTERNALLY MANAGED
ca                      Dec 28, 2029 23:36 UTC   9y              no
etcd-ca                 Dec 28, 2029 23:36 UTC   9y              no
front-proxy-ca          Dec 28, 2029 23:36 UTC   9y              no
</code></pre><p>The command shows expiration/residual time for the client certificates in the <code>/etc/kubernetes/pki</code> folder and for the client certificate embedded in the KUBECONFIG files used by kubeadm (<code>admin.conf</code>, <code>controller-manager.conf</code> and <code>scheduler.conf</code>).</p>
<p>Additionally, kubeadm informs the user if the certificate is externally managed; in this case, the user should take care of managing certificate renewal manually/using other tools.</p>
<div class="alert alert-danger warning callout" role=alert>
<strong>Warning:</strong> <code>kubeadm</code> cannot manage certificates signed by an external CA.
</div>
<div class="alert alert-info note callout" role=alert>
<strong>Note:</strong> <code>kubelet.conf</code> is not included in the list above because kubeadm configures kubelet
for <a href=/docs/tasks/tls/certificate-rotation/>automatic certificate renewal</a>
with rotatable certificates under <code>/var/lib/kubelet/pki</code>.
To repair an expired kubelet client certificate see
<a href=/docs/setup/production-environment/tools/kubeadm/troubleshooting-kubeadm/#kubelet-client-cert>Kubelet client certificate rotation fails</a>.
</div>
<div class="alert alert-danger warning callout" role=alert>
<strong>Warning:</strong> <p>On nodes created with <code>kubeadm init</code>, prior to kubeadm version 1.17, there is a
<a href=https://github.com/kubernetes/kubeadm/issues/1753>bug</a> where you manually have to modify the contents of <code>kubelet.conf</code>. After <code>kubeadm init</code> finishes, you should update <code>kubelet.conf</code> to point to the
rotated kubelet client certificates, by replacing <code>client-certificate-data</code> and <code>client-key-data</code> with:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:green;font-weight:700>client-certificate</span>:<span style=color:#bbb> </span>/var/lib/kubelet/pki/kubelet-client-current.pem<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>client-key</span>:<span style=color:#bbb> </span>/var/lib/kubelet/pki/kubelet-client-current.pem<span style=color:#bbb>
</span></code></pre></div>
</div>
<h2 id=automatic-certificate-renewal>Automatic certificate renewal</h2>
<p>kubeadm renews all the certificates during control plane <a href=/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/>upgrade</a>.</p>
<p>This feature is designed for addressing the simplest use cases;
if you don't have specific requirements on certificate renewal and perform Kubernetes version upgrades regularly (less than 1 year in between each upgrade), kubeadm will take care of keeping your cluster up to date and reasonably secure.</p>
<div class="alert alert-info note callout" role=alert>
<strong>Note:</strong> It is a best practice to upgrade your cluster frequently in order to stay secure.
</div>
<p>If you have more complex requirements for certificate renewal, you can opt out from the default behavior by passing <code>--certificate-renewal=false</code> to <code>kubeadm upgrade apply</code> or to <code>kubeadm upgrade node</code>.</p>
<div class="alert alert-danger warning callout" role=alert>
<strong>Warning:</strong> Prior to kubeadm version 1.17 there is a <a href=https://github.com/kubernetes/kubeadm/issues/1818>bug</a>
where the default value for <code>--certificate-renewal</code> is <code>false</code> for the <code>kubeadm upgrade node</code>
command. In that case, you should explicitly set <code>--certificate-renewal=true</code>.
</div>
<h2 id=manual-certificate-renewal>Manual certificate renewal</h2>
<p>You can renew your certificates manually at any time with the <code>kubeadm certs renew</code> command.</p>
<p>This command performs the renewal using CA (or front-proxy-CA) certificate and key stored in <code>/etc/kubernetes/pki</code>.</p>
<p>After running the command you should restart the control plane Pods. This is required since
dynamic certificate reload is currently not supported for all components and certificates.
<a href=/docs/tasks/configure-pod-container/static-pod/>Static Pods</a> are managed by the local kubelet
and not by the API Server, thus kubectl cannot be used to delete and restart them.
To restart a static Pod you can temporarily remove its manifest file from <code>/etc/kubernetes/manifests/</code>
and wait for 20 seconds (see the <code>fileCheckFrequency</code> value in <a href=/docs/reference/config-api/kubelet-config.v1beta1/>KubeletConfiguration struct</a>.
The kubelet will terminate the Pod if it's no longer in the manifest directory.
You can then move the file back and after another <code>fileCheckFrequency</code> period, the kubelet will recreate
the Pod and the certificate renewal for the component can complete.</p>
<div class="alert alert-danger warning callout" role=alert>
<strong>Warning:</strong> If you are running an HA cluster, this command needs to be executed on all the control-plane nodes.
</div>
<div class="alert alert-info note callout" role=alert>
<strong>Note:</strong> <code>certs renew</code> uses the existing certificates as the authoritative source for attributes (Common Name, Organization, SAN, etc.) instead of the kubeadm-config ConfigMap. It is strongly recommended to keep them both in sync.
</div>
<p><code>kubeadm certs renew</code> provides the following options:</p>
<p>The Kubernetes certificates normally reach their expiration date after one year.</p>
<ul>
<li>
<p><code>--csr-only</code> can be used to renew certificates with an external CA by generating certificate signing requests (without actually renewing certificates in place); see next paragraph for more information.</p>
</li>
<li>
<p>It's also possible to renew a single certificate instead of all.</p>
</li>
</ul>
<h2 id=renew-certificates-with-the-kubernetes-certificates-api>Renew certificates with the Kubernetes certificates API</h2>
<p>This section provides more details about how to execute manual certificate renewal using the Kubernetes certificates API.</p>
<div class="alert alert-warning caution callout" role=alert>
<strong>Caution:</strong> These are advanced topics for users who need to integrate their organization's certificate infrastructure into a kubeadm-built cluster. If the default kubeadm configuration satisfies your needs, you should let kubeadm manage certificates instead.
</div>
<h3 id=set-up-a-signer>Set up a signer</h3>
<p>The Kubernetes Certificate Authority does not work out of the box.
You can configure an external signer such as <a href=https://cert-manager.io/docs/configuration/ca/>cert-manager</a>, or you can use the built-in signer.</p>
<p>The built-in signer is part of <a href=/docs/reference/command-line-tools-reference/kube-controller-manager/><code>kube-controller-manager</code></a>.</p>
<p>To activate the built-in signer, you must pass the <code>--cluster-signing-cert-file</code> and <code>--cluster-signing-key-file</code> flags.</p>
<p>If you're creating a new cluster, you can use a kubeadm <a href=https://pkg.go.dev/k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/v1beta3>configuration file</a>:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubeadm.k8s.io/v1beta3<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ClusterConfiguration<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>controllerManager</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>extraArgs</span>:<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>cluster-signing-cert-file</span>:<span style=color:#bbb> </span>/etc/kubernetes/pki/ca.crt<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>cluster-signing-key-file</span>:<span style=color:#bbb> </span>/etc/kubernetes/pki/ca.key<span style=color:#bbb>
</span></code></pre></div><h3 id=create-certificate-signing-requests-csr>Create certificate signing requests (CSR)</h3>
<p>See <a href=/docs/reference/access-authn-authz/certificate-signing-requests/#create-certificatesigningrequest>Create CertificateSigningRequest</a> for creating CSRs with the Kubernetes API.</p>
<h2 id=renew-certificates-with-external-ca>Renew certificates with external CA</h2>
<p>This section provide more details about how to execute manual certificate renewal using an external CA.</p>
<p>To better integrate with external CAs, kubeadm can also produce certificate signing requests (CSRs).
A CSR represents a request to a CA for a signed certificate for a client.
In kubeadm terms, any certificate that would normally be signed by an on-disk CA can be produced as a CSR instead. A CA, however, cannot be produced as a CSR.</p>
<h3 id=create-certificate-signing-requests-csr-1>Create certificate signing requests (CSR)</h3>
<p>You can create certificate signing requests with <code>kubeadm certs renew --csr-only</code>.</p>
<p>Both the CSR and the accompanying private key are given in the output.
You can pass in a directory with <code>--csr-dir</code> to output the CSRs to the specified location.
If <code>--csr-dir</code> is not specified, the default certificate directory (<code>/etc/kubernetes/pki</code>) is used.</p>
<p>Certificates can be renewed with <code>kubeadm certs renew --csr-only</code>.
As with <code>kubeadm init</code>, an output directory can be specified with the <code>--csr-dir</code> flag.</p>
<p>A CSR contains a certificate's name, domains, and IPs, but it does not specify usages.
It is the responsibility of the CA to specify <a href=/docs/setup/best-practices/certificates/#all-certificates>the correct cert usages</a>
when issuing a certificate.</p>
<ul>
<li>In <code>openssl</code> this is done with the
<a href=https://superuser.com/questions/738612/openssl-ca-keyusage-extension><code>openssl ca</code> command</a>.</li>
<li>In <code>cfssl</code> you specify
<a href=https://github.com/cloudflare/cfssl/blob/master/doc/cmd/cfssl.txt#L170>usages in the config file</a>.</li>
</ul>
<p>After a certificate is signed using your preferred method, the certificate and the private key must be copied to the PKI directory (by default <code>/etc/kubernetes/pki</code>).</p>
<h2 id=certificate-authority-rotation>Certificate authority (CA) rotation</h2>
<p>Kubeadm does not support rotation or replacement of CA certificates out of the box.</p>
<p>For more information about manual rotation or replacement of CA, see <a href=/docs/tasks/tls/manual-rotation-of-ca-certificates/>manual rotation of CA certificates</a>.</p>
<h2 id=kubelet-serving-certs>Enabling signed kubelet serving certificates</h2>
<p>By default the kubelet serving certificate deployed by kubeadm is self-signed.
This means a connection from external services like the
<a href=https://github.com/kubernetes-sigs/metrics-server>metrics-server</a> to a
kubelet cannot be secured with TLS.</p>
<p>To configure the kubelets in a new kubeadm cluster to obtain properly signed serving
certificates you must pass the following minimal configuration to <code>kubeadm init</code>:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubeadm.k8s.io/v1beta3<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ClusterConfiguration<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubelet.config.k8s.io/v1beta1<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>KubeletConfiguration<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>serverTLSBootstrap</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></code></pre></div><p>If you have already created the cluster you must adapt it by doing the following:</p>
<ul>
<li>Find and edit the <code>kubelet-config-1.23</code> ConfigMap in the <code>kube-system</code> namespace.
In that ConfigMap, the <code>kubelet</code> key has a
<a href=/docs/reference/config-api/kubelet-config.v1beta1/#kubelet-config-k8s-io-v1beta1-KubeletConfiguration>KubeletConfiguration</a>
document as its value. Edit the KubeletConfiguration document to set <code>serverTLSBootstrap: true</code>.</li>
<li>On each node, add the <code>serverTLSBootstrap: true</code> field in <code>/var/lib/kubelet/config.yaml</code>
and restart the kubelet with <code>systemctl restart kubelet</code></li>
</ul>
<p>The field <code>serverTLSBootstrap: true</code> will enable the bootstrap of kubelet serving
certificates by requesting them from the <code>certificates.k8s.io</code> API. One known limitation
is that the CSRs (Certificate Signing Requests) for these certificates cannot be automatically
approved by the default signer in the kube-controller-manager -
<a href=/docs/reference/access-authn-authz/certificate-signing-requests/#kubernetes-signers><code>kubernetes.io/kubelet-serving</code></a>.
This will require action from the user or a third party controller.</p>
<p>These CSRs can be viewed using:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>kubectl get csr
NAME        AGE     SIGNERNAME                        REQUESTOR                      CONDITION
csr-9wvgt   112s    kubernetes.io/kubelet-serving     system:node:worker-1           Pending
csr-lz97v   1m58s   kubernetes.io/kubelet-serving     system:node:control-plane-1    Pending
</code></pre></div><p>To approve them you can do the following:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>kubectl certificate approve &lt;CSR-name&gt;
</code></pre></div><p>By default, these serving certificate will expire after one year. Kubeadm sets the
<code>KubeletConfiguration</code> field <code>rotateCertificates</code> to <code>true</code>, which means that close
to expiration a new set of CSRs for the serving certificates will be created and must
be approved to complete the rotation. To understand more see
<a href=/docs/reference/command-line-tools-reference/kubelet-tls-bootstrapping/#certificate-rotation>Certificate Rotation</a>.</p>
<p>If you are looking for a solution for automatic approval of these CSRs it is recommended
that you contact your cloud provider and ask if they have a CSR signer that verifies
the node identity with an out of band mechanism.</p>
<div class="alert alert-secondary callout third-party-content" role=alert><strong>Note:</strong>
This section links to third party projects that provide functionality required by Kubernetes. The Kubernetes project authors aren't responsible for these projects, which are listed alphabetically. To add a project to this list, read the <a href=/docs/contribute/style/content-guide/#third-party-content>content guide</a> before submitting a change. <a href=#third-party-content-disclaimer>More information.</a></div>
<p>Third party custom controllers can be used:</p>
<ul>
<li><a href=https://github.com/postfinance/kubelet-csr-approver>kubelet-csr-approver</a></li>
</ul>
<p>Such a controller is not a secure mechanism unless it not only verifies the CommonName
in the CSR but also verifies the requested IPs and domain names. This would prevent
a malicious actor that has access to a kubelet client certificate to create
CSRs requesting serving certificates for any IP or domain name.</p>
<h2 id=kubeconfig-additional-users>Generating kubeconfig files for additional users</h2>
<p>During cluster creation, kubeadm signs the certificate in the <code>admin.conf</code> to have
<code>Subject: O = system:masters, CN = kubernetes-admin</code>.
<a href=/docs/reference/access-authn-authz/rbac/#user-facing-roles><code>system:masters</code></a>
is a break-glass, super user group that bypasses the authorization layer (e.g. RBAC).
Sharing the <code>admin.conf</code> with additional users is <strong>not recommended</strong>!</p>
<p>Instead, you can use the <a href=/docs/reference/setup-tools/kubeadm/kubeadm-kubeconfig><code>kubeadm kubeconfig user</code></a>
command to generate kubeconfig files for additional users.
The command accepts a mixture of command line flags and
<a href=/docs/reference/config-api/kubeadm-config.v1beta3/>kubeadm configuration</a> options.
The generated kubeconfig will be written to stdout and can be piped to a file
using <code>kubeadm kubeconfig user ... > somefile.conf</code>.</p>
<p>Example configuration file that can be used with <code>--config</code>:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:#080;font-style:italic># example.yaml</span><span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubeadm.k8s.io/v1beta3<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ClusterConfiguration<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:#080;font-style:italic># Will be used as the target &#34;cluster&#34; in the kubeconfig</span><span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>clusterName</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;kubernetes&#34;</span><span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:#080;font-style:italic># Will be used as the &#34;server&#34; (IP or DNS name) of this cluster in the kubeconfig</span><span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>controlPlaneEndpoint</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;some-dns-address:6443&#34;</span><span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:#080;font-style:italic># The cluster CA key and certificate will be loaded from this local directory</span><span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>certificatesDir</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/etc/kubernetes/pki&#34;</span><span style=color:#bbb>
</span></code></pre></div><p>Make sure that these settings match the desired target cluster settings.
To see the settings of an existing cluster use:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>kubectl get cm kubeadm-config -n kube-system -o<span style=color:#666>=</span><span style=color:#b8860b>jsonpath</span><span style=color:#666>=</span><span style=color:#b44>&#34;{.data.ClusterConfiguration}&#34;</span>
</code></pre></div><p>The following example will generate a kubeconfig file with credentials valid for 24 hours
for a new user <code>johndoe</code> that is part of the <code>appdevs</code> group:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>kubeadm kubeconfig user --config example.yaml --org appdevs --client-name johndoe --validity-period 24h
</code></pre></div><p>The following example will generate a kubeconfig file with administrator credentials valid for 1 week:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>kubeadm kubeconfig user --config example.yaml --client-name admin --validity-period 168h
</code></pre></div>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-6134c5061298affa145ddb801b5c29da>2 - Configuring a cgroup driver</h1>
<p>This page explains how to configure the kubelet cgroup driver to match the container
runtime cgroup driver for kubeadm clusters.</p>
<h2 id=before-you-begin>Before you begin</h2>
<p>You should be familiar with the Kubernetes
<a href=/docs/setup/production-environment/container-runtimes>container runtime requirements</a>.</p>
<h2 id=configuring-the-container-runtime-cgroup-driver>Configuring the container runtime cgroup driver</h2>
<p>The <a href=/docs/setup/production-environment/container-runtimes>Container runtimes</a> page
explains that the <code>systemd</code> driver is recommended for kubeadm based setups instead
of the <code>cgroupfs</code> driver, because kubeadm manages the kubelet as a systemd service.</p>
<p>The page also provides details on how to setup a number of different container runtimes with the
<code>systemd</code> driver by default.</p>
<h2 id=configuring-the-kubelet-cgroup-driver>Configuring the kubelet cgroup driver</h2>
<p>kubeadm allows you to pass a <code>KubeletConfiguration</code> structure during <code>kubeadm init</code>.
This <code>KubeletConfiguration</code> can include the <code>cgroupDriver</code> field which controls the cgroup
driver of the kubelet.</p>
<div class="alert alert-info note callout" role=alert>
<strong>Note:</strong> In v1.22, if the user is not setting the <code>cgroupDriver</code> field under <code>KubeletConfiguration</code>,
<code>kubeadm</code> will default it to <code>systemd</code>.
</div>
<p>A minimal example of configuring the field explicitly:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:#080;font-style:italic># kubeadm-config.yaml</span><span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ClusterConfiguration<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubeadm.k8s.io/v1beta3<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>kubernetesVersion</span>:<span style=color:#bbb> </span>v1.21.0<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>KubeletConfiguration<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubelet.config.k8s.io/v1beta1<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>cgroupDriver</span>:<span style=color:#bbb> </span>systemd<span style=color:#bbb>
</span></code></pre></div><p>Such a configuration file can then be passed to the kubeadm command:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>kubeadm init --config kubeadm-config.yaml
</code></pre></div><div class="alert alert-info note callout" role=alert>
<strong>Note:</strong> <p>Kubeadm uses the same <code>KubeletConfiguration</code> for all nodes in the cluster.
The <code>KubeletConfiguration</code> is stored in a <a href=/docs/concepts/configuration/configmap>ConfigMap</a>
object under the <code>kube-system</code> namespace.</p>
<p>Executing the sub commands <code>init</code>, <code>join</code> and <code>upgrade</code> would result in kubeadm
writing the <code>KubeletConfiguration</code> as a file under <code>/var/lib/kubelet/config.yaml</code>
and passing it to the local node kubelet.</p>
</div>
<h2 id=using-the-cgroupfs-driver>Using the <code>cgroupfs</code> driver</h2>
<p>As this guide explains using the <code>cgroupfs</code> driver with kubeadm is not recommended.</p>
<p>To continue using <code>cgroupfs</code> and to prevent <code>kubeadm upgrade</code> from modifying the
<code>KubeletConfiguration</code> cgroup driver on existing setups, you must be explicit
about its value. This applies to a case where you do not wish future versions
of kubeadm to apply the <code>systemd</code> driver by default.</p>
<p>See the below section on "Modify the kubelet ConfigMap" for details on
how to be explicit about the value.</p>
<p>If you wish to configure a container runtime to use the <code>cgroupfs</code> driver,
you must refer to the documentation of the container runtime of your choice.</p>
<h2 id=migrating-to-the-systemd-driver>Migrating to the <code>systemd</code> driver</h2>
<p>To change the cgroup driver of an existing kubeadm cluster to <code>systemd</code> in-place,
a similar procedure to a kubelet upgrade is required. This must include both
steps outlined below.</p>
<div class="alert alert-info note callout" role=alert>
<strong>Note:</strong> Alternatively, it is possible to replace the old nodes in the cluster with new ones
that use the <code>systemd</code> driver. This requires executing only the first step below
before joining the new nodes and ensuring the workloads can safely move to the new
nodes before deleting the old nodes.
</div>
<h3 id=modify-the-kubelet-configmap>Modify the kubelet ConfigMap</h3>
<ul>
<li>
<p>Find the kubelet ConfigMap name using <code>kubectl get cm -n kube-system | grep kubelet-config</code>.</p>
</li>
<li>
<p>Call <code>kubectl edit cm kubelet-config-x.yy -n kube-system</code> (replace <code>x.yy</code> with
the Kubernetes version).</p>
</li>
<li>
<p>Either modify the existing <code>cgroupDriver</code> value or add a new field that looks like this:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:green;font-weight:700>cgroupDriver</span>:<span style=color:#bbb> </span>systemd<span style=color:#bbb>
</span></code></pre></div><p>This field must be present under the <code>kubelet:</code> section of the ConfigMap.</p>
</li>
</ul>
<h3 id=update-the-cgroup-driver-on-all-nodes>Update the cgroup driver on all nodes</h3>
<p>For each node in the cluster:</p>
<ul>
<li><a href=/docs/tasks/administer-cluster/safely-drain-node>Drain the node</a> using <code>kubectl drain &lt;node-name> --ignore-daemonsets</code></li>
<li>Stop the kubelet using <code>systemctl stop kubelet</code></li>
<li>Stop the container runtime</li>
<li>Modify the container runtime cgroup driver to <code>systemd</code></li>
<li>Set <code>cgroupDriver: systemd</code> in <code>/var/lib/kubelet/config.yaml</code></li>
<li>Start the container runtime</li>
<li>Start the kubelet using <code>systemctl start kubelet</code></li>
<li><a href=/docs/tasks/administer-cluster/safely-drain-node>Uncordon the node</a> using <code>kubectl uncordon &lt;node-name></code></li>
</ul>
<p>Execute these steps on nodes one at a time to ensure workloads
have sufficient time to schedule on different nodes.</p>
<p>Once the process is complete ensure that all nodes and workloads are healthy.</p>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-98530eb3653d28fef34bff4543364aa7>3 - Reconfiguring a kubeadm cluster</h1>
<p>kubeadm does not support automated ways of reconfiguring components that
were deployed on managed nodes. One way of automating this would be
by using a custom <a href=/docs/concepts/extend-kubernetes/operator/>operator</a>.</p>
<p>To modify the components configuration you must manually edit associated cluster
objects and files on disk.</p>
<p>This guide shows the correct sequence of steps that need to be performed
to achieve kubeadm cluster reconfiguration.</p>
<h2 id=before-you-begin>Before you begin</h2>
<ul>
<li>You need a cluster that was deployed using kubeadm</li>
<li>Have administrator credentials (<code>/etc/kubernetes/admin.conf</code>) and network connectivity
to a running kube-apiserver in the cluster from a host that has kubectl installed</li>
<li>Have a text editor installed on all hosts</li>
</ul>
<h2 id=reconfiguring-the-cluster>Reconfiguring the cluster</h2>
<p>kubeadm writes a set of cluster wide component configuration options in
ConfigMaps and other objects. These objects must be manually edited. The command <code>kubectl edit</code>
can be used for that.</p>
<p>The <code>kubectl edit</code> command will open a text editor where you can edit and save the object directly.</p>
<p>You can use the environment variables <code>KUBECONFIG</code> and <code>KUBE_EDITOR</code> to specify the location of
the kubectl consumed kubeconfig file and preferred text editor.</p>
<p>For example:</p>
<pre><code>KUBECONFIG=/etc/kubernetes/admin.conf KUBE_EDITOR=nano kubectl edit &lt;parameters&gt;
</code></pre><div class="alert alert-info note callout" role=alert>
<strong>Note:</strong> Upon saving any changes to these cluster objects, components running on nodes may not be
automatically updated. The steps below instruct you on how to perform that manually.
</div>
<div class="alert alert-danger warning callout" role=alert>
<strong>Warning:</strong> Component configuration in ConfigMaps is stored as unstructured data (YAML string).
This means that validation will not be performed upon updating the contents of a ConfigMap.
You have to be careful to follow the documented API format for a particular
component configuration and avoid introducing typos and YAML indentation mistakes.
</div>
<h3 id=applying-cluster-configuration-changes>Applying cluster configuration changes</h3>
<h4 id=updating-the-clusterconfiguration>Updating the <code>ClusterConfiguration</code></h4>
<p>During cluster creation and upgrade, kubeadm writes its
<a href=/docs/reference/config-api/kubeadm-config.v1beta3/><code>ClusterConfiguration</code></a>
in a ConfigMap called <code>kubeadm-config</code> in the <code>kube-system</code> namespace.</p>
<p>To change a particular option in the <code>ClusterConfiguration</code> you can edit the ConfigMap with this command:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>kubectl edit cm -n kube-system kubeadm-config
</code></pre></div><p>The configuration is located under the <code>data.ClusterConfiguration</code> key.</p>
<div class="alert alert-info note callout" role=alert>
<strong>Note:</strong> The <code>ClusterConfiguration</code> includes a variety of options that affect the configuration of individual
components such as kube-apiserver, kube-scheduler, kube-controller-manager, CoreDNS, etcd and kube-proxy.
Changes to the configuration must be reflected on node components manually.
</div>
<h4 id=reflecting-clusterconfiguration-changes-on-control-plane-nodes>Reflecting <code>ClusterConfiguration</code> changes on control plane nodes</h4>
<p>kubeadm manages the control plane components as static Pod manifests located in
the directory <code>/etc/kubernetes/manifests</code>.
Any changes to the <code>ClusterConfiguration</code> under the <code>apiServer</code>, <code>controllerManager</code>, <code>scheduler</code> or <code>etcd</code>
keys must be reflected in the associated files in the manifests directory on a control plane node.</p>
<p>Such changes may include:</p>
<ul>
<li><code>extraArgs</code> - requires updating the list of flags passed to a component container</li>
<li><code>extraMounts</code> - requires updated the volume mounts for a component container</li>
<li><code>*SANs</code> - requires writing new certificates with updated Subject Alternative Names.</li>
</ul>
<p>Before proceeding with these changes, make sure you have backed up the directory <code>/etc/kubernetes/</code>.</p>
<p>To write new certificates you can use:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>kubeadm init phase certs &lt;component-name&gt; --config &lt;config-file&gt;
</code></pre></div><p>To write new manifest files in <code>/etc/kubernetes/manifests</code> you can use:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>kubeadm init phase control-plane &lt;component-name&gt; --config &lt;config-file&gt;
</code></pre></div><p>The <code>&lt;config-file></code> contents must match the updated <code>ClusterConfiguration</code>.
The <code>&lt;component-name></code> value must be the name of the component.</p>
<div class="alert alert-info note callout" role=alert>
<strong>Note:</strong> Updating a file in <code>/etc/kubernetes/manifests</code> will tell the kubelet to restart the static Pod for the corresponding component.
Try doing these changes one node at a time to leave the cluster without downtime.
</div>
<h3 id=applying-kubelet-configuration-changes>Applying kubelet configuration changes</h3>
<h4 id=updating-the-kubeletconfiguration>Updating the <code>KubeletConfiguration</code></h4>
<p>During cluster creation and upgrade, kubeadm writes its
<a href=/docs/reference/config-api/kubelet-config.v1beta1/><code>KubeletConfiguration</code></a>
in a ConfigMap called <code>kubelet-config</code> in the <code>kube-system</code> namespace.</p>
<p>You can edit the ConfigMap with this command:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>kubectl edit cm -n kube-system kubelet-config
</code></pre></div><p>The configuration is located under the <code>data.kubelet</code> key.</p>
<h4 id=reflecting-the-kubelet-changes>Reflecting the kubelet changes</h4>
<p>To reflect the change on kubeadm nodes you must do the following:</p>
<ul>
<li>Log in to a kubeadm node</li>
<li>Run <code>kubeadm upgrade node phase kubelet-config</code> to download the latest <code>kubelet-config</code>
ConfigMap contents into the local file <code>/var/lib/kubelet/config.conf</code></li>
<li>Edit the file <code>/var/lib/kubelet/kubeadm-flags.env</code> to apply additional configuration with
flags</li>
<li>Restart the kubelet service with <code>systemctl restart kubelet</code></li>
</ul>
<div class="alert alert-info note callout" role=alert>
<strong>Note:</strong> Do these changes one node at a time to allow workloads to be rescheduled properly.
</div>
<div class="alert alert-info note callout" role=alert>
<strong>Note:</strong> During <code>kubeadm upgrade</code>, kubeadm downloads the <code>KubeletConfiguration</code> from the
<code>kubelet-config</code> ConfigMap and overwrite the contents of <code>/var/lib/kubelet/config.conf</code>.
This means that node local configuration must be applied either by flags in
<code>/var/lib/kubelet/kubeadm-flags.env</code> or by manually updating the contents of
<code>/var/lib/kubelet/config.conf</code> after <code>kubeadm upgrade</code>, and then restarting the kubelet.
</div>
<h3 id=applying-kube-proxy-configuration-changes>Applying kube-proxy configuration changes</h3>
<h4 id=updating-the-kubeproxyconfiguration>Updating the <code>KubeProxyConfiguration</code></h4>
<p>During cluster creation and upgrade, kubeadm writes its
<a href=/docs/reference/config-api/kube-proxy-config.v1alpha1/><code>KubeProxyConfiguration</code></a>
in a ConfigMap in the <code>kube-system</code> namespace called <code>kube-proxy</code>.</p>
<p>This ConfigMap is used by the <code>kube-proxy</code> DaemonSet in the <code>kube-system</code> namespace.</p>
<p>To change a particular option in the <code>KubeProxyConfiguration</code>, you can edit the ConfigMap with this command:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>kubectl edit cm -n kube-system kube-proxy
</code></pre></div><p>The configuration is located under the <code>data.config.conf</code> key.</p>
<h4 id=reflecting-the-kube-proxy-changes>Reflecting the kube-proxy changes</h4>
<p>Once the <code>kube-proxy</code> ConfigMap is updated, you can restart all kube-proxy Pods:</p>
<p>Obtain the Pod names:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>kubectl get po -n kube-system | grep kube-proxy
</code></pre></div><p>Delete a Pod with:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>kubectl delete po -n kube-system &lt;pod-name&gt;
</code></pre></div><p>New Pods that use the updated ConfigMap will be created.</p>
<div class="alert alert-info note callout" role=alert>
<strong>Note:</strong> Because kubeadm deploys kube-proxy as a DaemonSet, node specific configuration is unsupported.
</div>
<h3 id=applying-coredns-configuration-changes>Applying CoreDNS configuration changes</h3>
<h4 id=updating-the-coredns-deployment-and-service>Updating the CoreDNS Deployment and Service</h4>
<p>kubeadm deploys CoreDNS as a Deployment called <code>coredns</code> and with a Service <code>kube-dns</code>,
both in the <code>kube-system</code> namespace.</p>
<p>To update any of the CoreDNS settings, you can edit the Deployment and
Service objects:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>kubectl edit deployment -n kube-system coredns
kubectl edit service -n kube-system kube-dns
</code></pre></div><h4 id=reflecting-the-coredns-changes>Reflecting the CoreDNS changes</h4>
<p>Once the CoreDNS changes are applied you can delete the CoreDNS Pods:</p>
<p>Obtain the Pod names:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>kubectl get po -n kube-system | grep coredns
</code></pre></div><p>Delete a Pod with:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>kubectl delete po -n kube-system &lt;pod-name&gt;
</code></pre></div><p>New Pods with the updated CoreDNS configuration will be created.</p>
<div class="alert alert-info note callout" role=alert>
<strong>Note:</strong> kubeadm does not allow CoreDNS configuration during cluster creation and upgrade.
This means that if you execute <code>kubeadm upgrade apply</code>, your changes to the CoreDNS
objects will be lost and must be reapplied.
</div>
<h2 id=persisting-the-reconfiguration>Persisting the reconfiguration</h2>
<p>During the execution of <code>kubeadm upgrade</code> on a managed node, kubeadm might overwrite configuration
that was applied after the cluster was created (reconfiguration).</p>
<h3 id=persisting-node-object-reconfiguration>Persisting Node object reconfiguration</h3>
<p>kubeadm writes Labels, Taints, CRI socket and other information on the Node object for a particular
Kubernetes node. To change any of the contents of this Node object you can use:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>kubectl edit no &lt;node-name&gt;
</code></pre></div><p>During <code>kubeadm upgrade</code> the contents of such a Node might get overwritten.
If you would like to persist your modifications to the Node object after upgrade,
you can prepare a <a href=/docs/tasks/manage-kubernetes-objects/update-api-object-kubectl-patch/>kubectl patch</a>
and apply it to the Node object:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>kubectl patch no &lt;node-name&gt; --patch-file &lt;patch-file&gt;
</code></pre></div><h4 id=persisting-control-plane-component-reconfiguration>Persisting control plane component reconfiguration</h4>
<p>The main source of control plane configuration is the <code>ClusterConfiguration</code>
object stored in the cluster. To extend the static Pod manifests configuration,
<a href=/docs/setup/production-environment/tools/kubeadm/control-plane-flags/#patches>patches</a> can be used.</p>
<p>These patch files must remain as files on the control plane nodes to ensure that
they can be used by the <code>kubeadm upgrade ... --patches &lt;directory></code>.</p>
<p>If reconfiguration is done to the <code>ClusterConfiguration</code> and static Pod manifests on disk,
the set of node specific patches must be updated accordingly.</p>
<h4 id=persisting-kubelet-reconfiguration>Persisting kubelet reconfiguration</h4>
<p>Any changes to the <code>KubeletConfiguration</code> stored in <code>/var/lib/kubelet/config.conf</code> will be overwritten on
<code>kubeadm upgrade</code> by downloading the contents of the cluster wide <code>kubelet-config</code> ConfigMap.
To persist kubelet node specific configuration either the file <code>/var/lib/kubelet/config.conf</code>
has to be updated manually post-upgrade or the file <code>/var/lib/kubelet/kubeadm-flags.env</code> can include flags.
The kubelet flags override the associated <code>KubeletConfiguration</code> options, but note that
some of the flags are deprecated.</p>
<p>A kubelet restart will be required after changing <code>/var/lib/kubelet/config.conf</code> or
<code>/var/lib/kubelet/kubeadm-flags.env</code>.</p>
<p>What's next</p>
<ul>
<li><a href=/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade>Upgrading kubeadm clusters</a></li>
<li><a href=/docs/setup/production-environment/tools/kubeadm/control-plane-flags>Customizing components with the kubeadm API</a></li>
<li><a href=/docs/tasks/administer-cluster/kubeadm/kubeadm-certs>Certificate management with kubeadm</a></li>
</ul>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-2e173356df5179cab9eec90a606f0aa4>4 - Upgrading kubeadm clusters</h1>
<p>This page explains how to upgrade a Kubernetes cluster created with kubeadm from version
1.22.x to version 1.23.x, and from version
1.23.x to 1.23.y (where <code>y > x</code>). Skipping MINOR versions
when upgrading is unsupported. For more details, please visit <a href=https://kubernetes.io/releases/version-skew-policy/>Version Skew Policy</a>.</p>
<p>To see information about upgrading clusters created using older versions of kubeadm,
please refer to following pages instead:</p>
<ul>
<li><a href=https://v1-22.docs.kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/>Upgrading a kubeadm cluster from 1.21 to 1.22</a></li>
<li><a href=https://v1-21.docs.kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/>Upgrading a kubeadm cluster from 1.20 to 1.21</a></li>
<li><a href=https://v1-20.docs.kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/>Upgrading a kubeadm cluster from 1.19 to 1.20</a></li>
<li><a href=https://v1-19.docs.kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/>Upgrading a kubeadm cluster from 1.18 to 1.19</a></li>
</ul>
<p>The upgrade workflow at high level is the following:</p>
<ol>
<li>Upgrade a primary control plane node.</li>
<li>Upgrade additional control plane nodes.</li>
<li>Upgrade worker nodes.</li>
</ol>
<h2 id=before-you-begin>Before you begin</h2>
<ul>
<li>Make sure you read the <a href=https://git.k8s.io/kubernetes/CHANGELOG/CHANGELOG-1.27.md>release notes</a> carefully.</li>
<li>The cluster should use a static control plane and etcd pods or external etcd.</li>
<li>Make sure to back up any important components, such as app-level state stored in a database.
<code>kubeadm upgrade</code> does not touch your workloads, only components internal to Kubernetes, but backups are always a best practice.</li>
<li><a href=https://serverfault.com/questions/684771/best-way-to-disable-swap-in-linux>Swap must be disabled</a>.</li>
</ul>
<h3 id=additional-information>Additional information</h3>
<ul>
<li>The instructions below outline when to drain each node during the upgrade process.
If you are performing a <strong>minor</strong> version upgrade for any kubelet, you <strong>must</strong>
first drain the node (or nodes) that you are upgrading. In the case of control plane nodes,
they could be running CoreDNS Pods or other critical workloads. For more information see
<a href=/docs/tasks/administer-cluster/safely-drain-node/>Draining nodes</a>.</li>
<li>All containers are restarted after upgrade, because the container spec hash value is changed.</li>
<li>To verify that the kubelet service has successfully restarted after the kubelet has been upgraded,
you can execute <code>systemctl status kubelet</code> or view the service logs with <code>journalctl -xeu kubelet</code>.</li>
<li>Usage of the <code>--config</code> flag of <code>kubeadm upgrade</code> with
<a href=/docs/reference/config-api/kubeadm-config.v1beta3>kubeadm configuration API types</a>
with the purpose of reconfiguring the cluster is not recommended and can have unexpected results. Follow the steps in
<a href=/docs/tasks/administer-cluster/kubeadm/kubeadm-reconfigure>Reconfiguring a kubeadm cluster</a> instead.</li>
</ul>
<h2 id=determine-which-version-to-upgrade-to>Determine which version to upgrade to</h2>
<p>Find the latest patch release for Kubernetes 1.23 using the OS package manager:</p>
<ul class="nav nav-tabs" id=k8s-install-versions role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#k8s-install-versions-0 role=tab aria-controls=k8s-install-versions-0 aria-selected=true>Ubuntu, Debian or HypriotOS</a></li>
<li class=nav-item><a data-toggle=tab class=nav-link href=#k8s-install-versions-1 role=tab aria-controls=k8s-install-versions-1>CentOS, RHEL or Fedora</a></li></ul>
<div class=tab-content id=k8s-install-versions><div id=k8s-install-versions-0 class="tab-pane show active" role=tabpanel aria-labelledby=k8s-install-versions-0>
<p><pre><code>apt update
apt-cache madison kubeadm
# find the latest 1.23 version in the list
# it should look like 1.23.x-00, where x is the latest patch
</code></pre>
</div>
<div id=k8s-install-versions-1 class=tab-pane role=tabpanel aria-labelledby=k8s-install-versions-1>
<p><pre><code>yum list --showduplicates kubeadm --disableexcludes=kubernetes
# find the latest 1.23 version in the list
# it should look like 1.23.x-0, where x is the latest patch
</code></pre>
</div></div>
<h2 id=upgrading-control-plane-nodes>Upgrading control plane nodes</h2>
<p>The upgrade procedure on control plane nodes should be executed one node at a time.
Pick a control plane node that you wish to upgrade first. It must have the <code>/etc/kubernetes/admin.conf</code> file.</p>
<h3 id=call-kubeadm-upgrade>Call "kubeadm upgrade"</h3>
<p><strong>For the first control plane node</strong></p>
<ul>
<li>Upgrade kubeadm:</li>
</ul>
<p><ul class="nav nav-tabs" id=k8s-install-kubeadm-first-cp role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#k8s-install-kubeadm-first-cp-0 role=tab aria-controls=k8s-install-kubeadm-first-cp-0 aria-selected=true>Ubuntu, Debian or HypriotOS</a></li>
<li class=nav-item><a data-toggle=tab class=nav-link href=#k8s-install-kubeadm-first-cp-1 role=tab aria-controls=k8s-install-kubeadm-first-cp-1>CentOS, RHEL or Fedora</a></li></ul>
<div class=tab-content id=k8s-install-kubeadm-first-cp><div id=k8s-install-kubeadm-first-cp-0 class="tab-pane show active" role=tabpanel aria-labelledby=k8s-install-kubeadm-first-cp-0>
<p><pre><code># replace x in 1.23.x-00 with the latest patch version
apt-mark unhold kubeadm &amp;&amp; \
apt-get update &amp;&amp; apt-get install -y kubeadm=1.23.x-00 &amp;&amp; \
apt-mark hold kubeadm
</code></pre>
</div>
<div id=k8s-install-kubeadm-first-cp-1 class=tab-pane role=tabpanel aria-labelledby=k8s-install-kubeadm-first-cp-1>
<p><pre><code># replace x in 1.23.x-0 with the latest patch version
yum install -y kubeadm-1.23.x-0 --disableexcludes=kubernetes
</code></pre>
</div></div>
<br></p>
<ul>
<li>
<p>Verify that the download works and has the expected version:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>kubeadm version
</code></pre></div></li>
<li>
<p>Verify the upgrade plan:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>kubeadm upgrade plan
</code></pre></div><p>This command checks that your cluster can be upgraded, and fetches the versions you can upgrade to.
It also shows a table with the component config version states.</p>
</li>
</ul>
<div class="alert alert-info note callout" role=alert>
<strong>Note:</strong> <code>kubeadm upgrade</code> also automatically renews the certificates that it manages on this node.
To opt-out of certificate renewal the flag <code>--certificate-renewal=false</code> can be used.
For more information see the <a href=/docs/tasks/administer-cluster/kubeadm/kubeadm-certs>certificate management guide</a>.
</div>
<div class="alert alert-info note callout" role=alert>
<strong>Note:</strong> If <code>kubeadm upgrade plan</code> shows any component configs that require manual upgrade, users must provide
a config file with replacement configs to <code>kubeadm upgrade apply</code> via the <code>--config</code> command line flag.
Failing to do so will cause <code>kubeadm upgrade apply</code> to exit with an error and not perform an upgrade.
</div>
<ul>
<li>
<p>Choose a version to upgrade to, and run the appropriate command. For example:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=color:#080;font-style:italic># replace x with the patch version you picked for this upgrade</span>
sudo kubeadm upgrade apply v1.23.x
</code></pre></div><p>Once the command finishes you should see:</p>
<pre><code>[upgrade/successful] SUCCESS! Your cluster was upgraded to &quot;v1.23.x&quot;. Enjoy!

[upgrade/kubelet] Now that your control plane is upgraded, please proceed with upgrading your kubelets if you haven't already done so.
</code></pre></li>
<li>
<p>Manually upgrade your CNI provider plugin.</p>
<p>Your Container Network Interface (CNI) provider may have its own upgrade instructions to follow.
Check the <a href=/docs/concepts/cluster-administration/addons/>addons</a> page to
find your CNI provider and see whether additional upgrade steps are required.</p>
<p>This step is not required on additional control plane nodes if the CNI provider runs as a DaemonSet.</p>
</li>
</ul>
<p><strong>For the other control plane nodes</strong></p>
<p>Same as the first control plane node but use:</p>
<pre><code>sudo kubeadm upgrade node
</code></pre><p>instead of:</p>
<pre><code>sudo kubeadm upgrade apply
</code></pre><p>Also calling <code>kubeadm upgrade plan</code> and upgrading the CNI provider plugin is no longer needed.</p>
<h3 id=drain-the-node>Drain the node</h3>
<ul>
<li>
<p>Prepare the node for maintenance by marking it unschedulable and evicting the workloads:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=color:#080;font-style:italic># replace &lt;node-to-drain&gt; with the name of your node you are draining</span>
kubectl drain &lt;node-to-drain&gt; --ignore-daemonsets
</code></pre></div></li>
</ul>
<h3 id=upgrade-kubelet-and-kubectl>Upgrade kubelet and kubectl</h3>
<ul>
<li>Upgrade the kubelet and kubectl:</li>
</ul>
<p><ul class="nav nav-tabs" id=k8s-install-kubelet role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#k8s-install-kubelet-0 role=tab aria-controls=k8s-install-kubelet-0 aria-selected=true>Ubuntu, Debian or HypriotOS</a></li>
<li class=nav-item><a data-toggle=tab class=nav-link href=#k8s-install-kubelet-1 role=tab aria-controls=k8s-install-kubelet-1>CentOS, RHEL or Fedora</a></li></ul>
<div class=tab-content id=k8s-install-kubelet><div id=k8s-install-kubelet-0 class="tab-pane show active" role=tabpanel aria-labelledby=k8s-install-kubelet-0>
<p><pre><code># replace x in 1.23.x-00 with the latest patch version
apt-mark unhold kubelet kubectl &amp;&amp; \
apt-get update &amp;&amp; apt-get install -y kubelet=1.23.x-00 kubectl=1.23.x-00 &amp;&amp; \
apt-mark hold kubelet kubectl
</code></pre>
</div>
<div id=k8s-install-kubelet-1 class=tab-pane role=tabpanel aria-labelledby=k8s-install-kubelet-1>
<p><pre><code># replace x in 1.23.x-0 with the latest patch version
yum install -y kubelet-1.23.x-0 kubectl-1.23.x-0 --disableexcludes=kubernetes
</code></pre>
</div></div>
<br></p>
<ul>
<li>
<p>Restart the kubelet:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>sudo systemctl daemon-reload
sudo systemctl restart kubelet
</code></pre></div></li>
</ul>
<h3 id=uncordon-the-node>Uncordon the node</h3>
<ul>
<li>
<p>Bring the node back online by marking it schedulable:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=color:#080;font-style:italic># replace &lt;node-to-drain&gt; with the name of your node</span>
kubectl uncordon &lt;node-to-drain&gt;
</code></pre></div></li>
</ul>
<h2 id=upgrade-worker-nodes>Upgrade worker nodes</h2>
<p>The upgrade procedure on worker nodes should be executed one node at a time or few nodes at a time,
without compromising the minimum required capacity for running your workloads.</p>
<h3 id=upgrade-kubeadm>Upgrade kubeadm</h3>
<ul>
<li>Upgrade kubeadm:</li>
</ul>
<ul class="nav nav-tabs" id=k8s-install-kubeadm-worker-nodes role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#k8s-install-kubeadm-worker-nodes-0 role=tab aria-controls=k8s-install-kubeadm-worker-nodes-0 aria-selected=true>Ubuntu, Debian or HypriotOS</a></li>
<li class=nav-item><a data-toggle=tab class=nav-link href=#k8s-install-kubeadm-worker-nodes-1 role=tab aria-controls=k8s-install-kubeadm-worker-nodes-1>CentOS, RHEL or Fedora</a></li></ul>
<div class=tab-content id=k8s-install-kubeadm-worker-nodes><div id=k8s-install-kubeadm-worker-nodes-0 class="tab-pane show active" role=tabpanel aria-labelledby=k8s-install-kubeadm-worker-nodes-0>
<p><pre><code># replace x in 1.23.x-00 with the latest patch version
apt-mark unhold kubeadm &amp;&amp; \
apt-get update &amp;&amp; apt-get install -y kubeadm=1.23.x-00 &amp;&amp; \
apt-mark hold kubeadm
</code></pre>
</div>
<div id=k8s-install-kubeadm-worker-nodes-1 class=tab-pane role=tabpanel aria-labelledby=k8s-install-kubeadm-worker-nodes-1>
<p><pre><code># replace x in 1.23.x-0 with the latest patch version
yum install -y kubeadm-1.23.x-0 --disableexcludes=kubernetes
</code></pre>
</div></div>
<h3 id=call-kubeadm-upgrade-1>Call "kubeadm upgrade"</h3>
<ul>
<li>
<p>For worker nodes this upgrades the local kubelet configuration:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>sudo kubeadm upgrade node
</code></pre></div></li>
</ul>
<h3 id=drain-the-node-1>Drain the node</h3>
<ul>
<li>
<p>Prepare the node for maintenance by marking it unschedulable and evicting the workloads:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=color:#080;font-style:italic># replace &lt;node-to-drain&gt; with the name of your node you are draining</span>
kubectl drain &lt;node-to-drain&gt; --ignore-daemonsets
</code></pre></div></li>
</ul>
<h3 id=upgrade-kubelet-and-kubectl-1>Upgrade kubelet and kubectl</h3>
<ul>
<li>Upgrade the kubelet and kubectl:</li>
</ul>
<p><ul class="nav nav-tabs" id=k8s-kubelet-and-kubectl role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#k8s-kubelet-and-kubectl-0 role=tab aria-controls=k8s-kubelet-and-kubectl-0 aria-selected=true>Ubuntu, Debian or HypriotOS</a></li>
<li class=nav-item><a data-toggle=tab class=nav-link href=#k8s-kubelet-and-kubectl-1 role=tab aria-controls=k8s-kubelet-and-kubectl-1>CentOS, RHEL or Fedora</a></li></ul>
<div class=tab-content id=k8s-kubelet-and-kubectl><div id=k8s-kubelet-and-kubectl-0 class="tab-pane show active" role=tabpanel aria-labelledby=k8s-kubelet-and-kubectl-0>
<p><pre><code># replace x in 1.23.x-00 with the latest patch version
apt-mark unhold kubelet kubectl &amp;&amp; \
apt-get update &amp;&amp; apt-get install -y kubelet=1.23.x-00 kubectl=1.23.x-00 &amp;&amp; \
apt-mark hold kubelet kubectl
</code></pre>
</div>
<div id=k8s-kubelet-and-kubectl-1 class=tab-pane role=tabpanel aria-labelledby=k8s-kubelet-and-kubectl-1>
<p><pre><code># replace x in 1.23.x-0 with the latest patch version
yum install -y kubelet-1.23.x-0 kubectl-1.23.x-0 --disableexcludes=kubernetes
</code></pre>
</div></div>
<br></p>
<ul>
<li>
<p>Restart the kubelet:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>sudo systemctl daemon-reload
sudo systemctl restart kubelet
</code></pre></div></li>
</ul>
<h3 id=uncordon-the-node-1>Uncordon the node</h3>
<ul>
<li>
<p>Bring the node back online by marking it schedulable:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=color:#080;font-style:italic># replace &lt;node-to-drain&gt; with the name of your node</span>
kubectl uncordon &lt;node-to-drain&gt;
</code></pre></div></li>
</ul>
<h2 id=verify-the-status-of-the-cluster>Verify the status of the cluster</h2>
<p>After the kubelet is upgraded on all nodes verify that all nodes are available again by running the following command
from anywhere kubectl can access the cluster:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>kubectl get nodes
</code></pre></div><p>The <code>STATUS</code> column should show <code>Ready</code> for all your nodes, and the version number should be updated.</p>
<h2 id=recovering-from-a-failure-state>Recovering from a failure state</h2>
<p>If <code>kubeadm upgrade</code> fails and does not roll back, for example because of an unexpected shutdown during execution, you can run <code>kubeadm upgrade</code> again.
This command is idempotent and eventually makes sure that the actual state is the desired state you declare.</p>
<p>To recover from a bad state, you can also run <code>kubeadm upgrade apply --force</code> without changing the version that your cluster is running.</p>
<p>During upgrade kubeadm writes the following backup folders under <code>/etc/kubernetes/tmp</code>:</p>
<ul>
<li><code>kubeadm-backup-etcd-&lt;date>-&lt;time></code></li>
<li><code>kubeadm-backup-manifests-&lt;date>-&lt;time></code></li>
</ul>
<p><code>kubeadm-backup-etcd</code> contains a backup of the local etcd member data for this control plane Node.
In case of an etcd upgrade failure and if the automatic rollback does not work, the contents of this folder
can be manually restored in <code>/var/lib/etcd</code>. In case external etcd is used this backup folder will be empty.</p>
<p><code>kubeadm-backup-manifests</code> contains a backup of the static Pod manifest files for this control plane Node.
In case of a upgrade failure and if the automatic rollback does not work, the contents of this folder can be
manually restored in <code>/etc/kubernetes/manifests</code>. If for some reason there is no difference between a pre-upgrade
and post-upgrade manifest file for a certain component, a backup file for it will not be written.</p>
<h2 id=how-it-works>How it works</h2>
<p><code>kubeadm upgrade apply</code> does the following:</p>
<ul>
<li>Checks that your cluster is in an upgradeable state:
<ul>
<li>The API server is reachable</li>
<li>All nodes are in the <code>Ready</code> state</li>
<li>The control plane is healthy</li>
</ul>
</li>
<li>Enforces the version skew policies.</li>
<li>Makes sure the control plane images are available or available to pull to the machine.</li>
<li>Generates replacements and/or uses user supplied overwrites if component configs require version upgrades.</li>
<li>Upgrades the control plane components or rollbacks if any of them fails to come up.</li>
<li>Applies the new <code>CoreDNS</code> and <code>kube-proxy</code> manifests and makes sure that all necessary RBAC rules are created.</li>
<li>Creates new certificate and key files of the API server and backs up old files if they're about to expire in 180 days.</li>
</ul>
<p><code>kubeadm upgrade node</code> does the following on additional control plane nodes:</p>
<ul>
<li>Fetches the kubeadm <code>ClusterConfiguration</code> from the cluster.</li>
<li>Optionally backups the kube-apiserver certificate.</li>
<li>Upgrades the static Pod manifests for the control plane components.</li>
<li>Upgrades the kubelet configuration for this node.</li>
</ul>
<p><code>kubeadm upgrade node</code> does the following on worker nodes:</p>
<ul>
<li>Fetches the kubeadm <code>ClusterConfiguration</code> from the cluster.</li>
<li>Upgrades the kubelet configuration for this node.</li>
</ul>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-9133578f1e75663bb031e5a377ca896d>5 - Adding Windows nodes</h1>
<div style=margin-top:10px;margin-bottom:10px>
<b>FEATURE STATE:</b> <code>Kubernetes v1.18 [beta]</code>
</div>
<p>You can use Kubernetes to run a mixture of Linux and Windows nodes, so you can mix Pods that run on Linux on with Pods that run on Windows. This page shows how to register Windows nodes to your cluster.</p>
<h2 id=before-you-begin>Before you begin</h2>
Your Kubernetes server must be at or later than version 1.17.
To check the version, enter <code>kubectl version</code>.
<ul>
<li>
<p>Obtain a <a href=https://www.microsoft.com/en-us/cloud-platform/windows-server-pricing>Windows Server 2019 license</a>
(or higher) in order to configure the Windows node that hosts Windows containers.
If you are using VXLAN/Overlay networking you must have also have <a href=https://support.microsoft.com/help/4489899>KB4489899</a> installed.</p>
</li>
<li>
<p>A Linux-based Kubernetes kubeadm cluster in which you have access to the control plane (see <a href=/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/>Creating a single control-plane cluster with kubeadm</a>).</p>
</li>
</ul>
<h2 id=objectives>Objectives</h2>
<ul>
<li>Register a Windows node to the cluster</li>
<li>Configure networking so Pods and Services on Linux and Windows can communicate with each other</li>
</ul>
<h2 id=getting-started-adding-a-windows-node-to-your-cluster>Getting Started: Adding a Windows Node to Your Cluster</h2>
<h3 id=networking-configuration>Networking Configuration</h3>
<p>Once you have a Linux-based Kubernetes control-plane node you are ready to choose a networking solution. This guide illustrates using Flannel in VXLAN mode for simplicity.</p>
<h4 id=configuring-flannel>Configuring Flannel</h4>
<ol>
<li>
<p>Prepare Kubernetes control plane for Flannel</p>
<p>Some minor preparation is recommended on the Kubernetes control plane in our cluster. It is recommended to enable bridged IPv4 traffic to iptables chains when using Flannel. The following command must be run on all Linux nodes:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>sudo sysctl net.bridge.bridge-nf-call-iptables<span style=color:#666>=</span><span style=color:#666>1</span>
</code></pre></div></li>
<li>
<p>Download & configure Flannel for Linux</p>
<p>Download the most recent Flannel manifest:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
</code></pre></div><p>Modify the <code>net-conf.json</code> section of the flannel manifest in order to set the VNI to 4096 and the Port to 4789. It should look as follows:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span>net-conf.json:</span> <span>|</span>
    {
      <span style=color:green;font-weight:700>&#34;Network&#34;</span>: <span style=color:#b44>&#34;10.244.0.0/16&#34;</span>,
      <span style=color:green;font-weight:700>&#34;Backend&#34;</span>: {
        <span style=color:green;font-weight:700>&#34;Type&#34;</span>: <span style=color:#b44>&#34;vxlan&#34;</span>,
        <span style=color:green;font-weight:700>&#34;VNI&#34;</span>: <span style=color:#666>4096</span>,
        <span style=color:green;font-weight:700>&#34;Port&#34;</span>: <span style=color:#666>4789</span>
      }
    }
</code></pre></div><div class="alert alert-info note callout" role=alert>
<strong>Note:</strong> The VNI must be set to 4096 and port 4789 for Flannel on Linux to interoperate with Flannel on Windows. See the <a href=https://github.com/coreos/flannel/blob/master/Documentation/backends.md#vxlan>VXLAN documentation</a>.
for an explanation of these fields.
</div>
<div class="alert alert-info note callout" role=alert>
<strong>Note:</strong> To use L2Bridge/Host-gateway mode instead change the value of <code>Type</code> to <code>"host-gw"</code> and omit <code>VNI</code> and <code>Port</code>.
</div>
</li>
<li>
<p>Apply the Flannel manifest and validate</p>
<p>Let's apply the Flannel configuration:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>kubectl apply -f kube-flannel.yml
</code></pre></div><p>After a few minutes, you should see all the pods as running if the Flannel pod network was deployed.</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>kubectl get pods -n kube-system
</code></pre></div><p>The output should include the Linux flannel DaemonSet as running:</p>
<pre><code>NAMESPACE     NAME                                      READY        STATUS    RESTARTS   AGE
...
kube-system   kube-flannel-ds-54954                     1/1          Running   0          1m
</code></pre></li>
<li>
<p>Add Windows Flannel and kube-proxy DaemonSets</p>
<p>Now you can add Windows-compatible versions of Flannel and kube-proxy. In order
to ensure that you get a compatible version of kube-proxy, you'll need to substitute
the tag of the image. The following example shows usage for Kubernetes v1.23.17,
but you should adjust the version for your own deployment.</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>curl -L https://github.com/kubernetes-sigs/sig-windows-tools/releases/latest/download/kube-proxy.yml | sed <span style=color:#b44>&#39;s/VERSION/v1.23.17/g&#39;</span> | kubectl apply -f -
kubectl apply -f https://github.com/kubernetes-sigs/sig-windows-tools/releases/latest/download/flannel-overlay.yml
</code></pre></div><div class="alert alert-info note callout" role=alert>
<strong>Note:</strong> If you're using host-gateway use <a href=https://github.com/kubernetes-sigs/sig-windows-tools/releases/latest/download/flannel-host-gw.yml>https://github.com/kubernetes-sigs/sig-windows-tools/releases/latest/download/flannel-host-gw.yml</a> instead
</div>
<div class="alert alert-info note callout" role=alert>
<strong>Note:</strong> <p>If you're using a different interface rather than Ethernet (i.e. "Ethernet0 2") on the Windows nodes, you have to modify the line:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-powershell data-lang=powershell>wins <span style=color:#a2f>cli </span><span style=color:#a2f;font-weight:700>process</span> run --path /k/flannel/setup.exe --args <span style=color:#b44>&#34;--mode=overlay --interface=Ethernet&#34;</span>
</code></pre></div><p>in the <code>flannel-host-gw.yml</code> or <code>flannel-overlay.yml</code> file and specify your interface accordingly.</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#080;font-style:italic># Example</span>
curl -L https://github.com/kubernetes-sigs/sig-windows-tools/releases/latest/download/flannel-overlay.yml | sed <span style=color:#b44>&#39;s/Ethernet/Ethernet0 2/g&#39;</span> | kubectl apply -f -
</code></pre></div>
</div>
</li>
</ol>
<h3 id=joining-a-windows-worker-node>Joining a Windows worker node</h3>
<div class="alert alert-info note callout" role=alert>
<strong>Note:</strong> All code snippets in Windows sections are to be run in a PowerShell environment
with elevated permissions (Administrator) on the Windows worker node.
</div>
<ul class="nav nav-tabs" id=tab-windows-kubeadm-runtime-installation role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#tab-windows-kubeadm-runtime-installation-0 role=tab aria-controls=tab-windows-kubeadm-runtime-installation-0 aria-selected=true>Docker EE</a></li>
<li class=nav-item><a data-toggle=tab class=nav-link href=#tab-windows-kubeadm-runtime-installation-1 role=tab aria-controls=tab-windows-kubeadm-runtime-installation-1>CRI-containerD</a></li></ul>
<div class=tab-content id=tab-windows-kubeadm-runtime-installation><div id=tab-windows-kubeadm-runtime-installation-0 class="tab-pane show active" role=tabpanel aria-labelledby=tab-windows-kubeadm-runtime-installation-0>
<p><h4 id=install-docker-ee>Install Docker EE</h4>
<p>Install the <code>Containers</code> feature</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-powershell data-lang=powershell><span style=color:#a2f>Install-WindowsFeature</span> -Name containers
</code></pre></div><p>Install Docker
Instructions to do so are available at <a href="https://docs.microsoft.com/en-us/virtualization/windowscontainers/quick-start/set-up-environment?tabs=Windows-Server#install-docker">Install Docker Engine - Enterprise on Windows Servers</a>.</p>
<h4 id=install-wins-kubelet-and-kubeadm>Install wins, kubelet, and kubeadm</h4>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-PowerShell data-lang=PowerShell>curl.exe -LO https<span>:</span>//raw.githubusercontent.com/<span style=color:#a2f>kubernetes-sigs</span>/<span style=color:#a2f>sig-windows</span>-tools/master/kubeadm/scripts/PrepareNode.ps1
.\PrepareNode.ps1 -KubernetesVersion v1.23.17
</code></pre></div><h4 id=run-kubeadm-to-join-the-node>Run <code>kubeadm</code> to join the node</h4>
<p>Use the command that was given to you when you ran <code>kubeadm init</code> on a control plane host.
If you no longer have this command, or the token has expired, you can run <code>kubeadm token create --print-join-command</code>
(on a control plane host) to generate a new token and join command.</p>
</div>
<div id=tab-windows-kubeadm-runtime-installation-1 class=tab-pane role=tabpanel aria-labelledby=tab-windows-kubeadm-runtime-installation-1>
<p><h4 id=install-containerd>Install containerD</h4>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-powershell data-lang=powershell>curl.exe -LO https<span>:</span>//github.com/<span style=color:#a2f>kubernetes-sigs</span>/<span style=color:#a2f>sig-windows</span>-tools/releases/latest/download/<span style=color:#a2f>Install-Containerd</span>.ps1
.\<span style=color:#a2f>Install-Containerd</span>.ps1
</code></pre></div><div class="alert alert-info note callout" role=alert>
<strong>Note:</strong> <p>To install a specific version of containerD specify the version with -ContainerDVersion.</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-powershell data-lang=powershell><span style=color:#080;font-style:italic># Example</span>
.\<span style=color:#a2f>Install-Containerd</span>.ps1 -ContainerDVersion 1.4.1
</code></pre></div>
</div>
<div class="alert alert-info note callout" role=alert>
<strong>Note:</strong> <p>If you're using a different interface rather than Ethernet (i.e. "Ethernet0 2") on the Windows nodes, specify the name with <code>-netAdapterName</code>.</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-powershell data-lang=powershell><span style=color:#080;font-style:italic># Example</span>
.\<span style=color:#a2f>Install-Containerd</span>.ps1 -netAdapterName <span style=color:#b44>&#34;Ethernet0 2&#34;</span>
</code></pre></div>
</div>
<h4 id=install-wins-kubelet-and-kubeadm>Install wins, kubelet, and kubeadm</h4>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-PowerShell data-lang=PowerShell>curl.exe -LO https<span>:</span>//raw.githubusercontent.com/<span style=color:#a2f>kubernetes-sigs</span>/<span style=color:#a2f>sig-windows</span>-tools/master/kubeadm/scripts/PrepareNode.ps1
.\PrepareNode.ps1 -KubernetesVersion v1.23.17 -ContainerRuntime containerD
</code></pre></div><h4 id=run-kubeadm-to-join-the-node>Run <code>kubeadm</code> to join the node</h4>
<p>Use the command that was given to you when you ran <code>kubeadm init</code> on a control plane host.
If you no longer have this command, or the token has expired, you can run <code>kubeadm token create --print-join-command</code>
(on a control plane host) to generate a new token and join command.</p>
<div class="alert alert-info note callout" role=alert>
<strong>Note:</strong> If using <strong>CRI-containerD</strong> add <code>--cri-socket "npipe:////./pipe/containerd-containerd"</code> to the kubeadm call
</div>
</div></div>
<h3 id=verifying-your-installation>Verifying your installation</h3>
<p>You should now be able to view the Windows node in your cluster by running:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>kubectl get nodes -o wide
</code></pre></div><p>If your new node is in the <code>NotReady</code> state it is likely because the flannel image is still downloading.
You can check the progress as before by checking on the flannel pods in the <code>kube-system</code> namespace:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>kubectl -n kube-system get pods -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>flannel
</code></pre></div><p>Once the flannel Pod is running, your node should enter the <code>Ready</code> state and then be available to handle workloads.</p>
<h2 id=what-s-next>What's next</h2>
<ul>
<li><a href=/docs/tasks/administer-cluster/kubeadm/upgrading-windows-nodes>Upgrading Windows kubeadm nodes</a></li>
</ul>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-e805c7d8d4ad6195cb82dbbc843bfc29>6 - Upgrading Windows nodes</h1>
<div style=margin-top:10px;margin-bottom:10px>
<b>FEATURE STATE:</b> <code>Kubernetes v1.18 [beta]</code>
</div>
<p>This page explains how to upgrade a Windows node <a href=/docs/tasks/administer-cluster/kubeadm/adding-windows-nodes>created with kubeadm</a>.</p>
<h2 id=before-you-begin>Before you begin</h2>
<p><p>You need to have a Kubernetes cluster, and the kubectl command-line tool must
be configured to communicate with your cluster. It is recommended to run this tutorial on a cluster with at least two nodes that are not acting as control plane hosts. If you do not already have a
cluster, you can create one by using
<a href=https://minikube.sigs.k8s.io/docs/tutorials/multi_node/>minikube</a>
or you can use one of these Kubernetes playgrounds:</p>
<ul>
<li><a href=https://www.katacoda.com/courses/kubernetes/playground>Katacoda</a></li>
<li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li>
</ul>
Your Kubernetes server must be at or later than version 1.17.
To check the version, enter <code>kubectl version</code>.
</p>
<ul>
<li>Familiarize yourself with <a href=/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade>the process for upgrading the rest of your kubeadm
cluster</a>. You will want to
upgrade the control plane nodes before upgrading your Windows nodes.</li>
</ul>
<h2 id=upgrading-worker-nodes>Upgrading worker nodes</h2>
<h3 id=upgrade-kubeadm>Upgrade kubeadm</h3>
<ol>
<li>
<p>From the Windows node, upgrade kubeadm:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-powershell data-lang=powershell><span style=color:#080;font-style:italic># replace v1.23.17 with your desired version</span>
curl.exe -Lo C:\k\kubeadm.exe https<span>:</span>//dl.k8s.io/<span style=color:#a2f>/bin/windows/amd64/kubeadm.exe
</code></pre></div></li>
</ol>
<h3 id=drain-the-node>Drain the node</h3>
<ol>
<li>
<p>From a machine with access to the Kubernetes API,
prepare the node for maintenance by marking it unschedulable and evicting the workloads:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=color:#080;font-style:italic># replace &lt;node-to-drain&gt; with the name of your node you are draining</span>
kubectl drain &lt;node-to-drain&gt; --ignore-daemonsets
</code></pre></div><p>You should see output similar to this:</p>
<pre><code>node/ip-172-31-85-18 cordoned
node/ip-172-31-85-18 drained
</code></pre></li>
</ol>
<h3 id=upgrade-the-kubelet-configuration>Upgrade the kubelet configuration</h3>
<ol>
<li>
<p>From the Windows node, call the following command to sync new kubelet configuration:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-powershell data-lang=powershell>kubeadm upgrade node
</code></pre></div></li>
</ol>
<h3 id=upgrade-kubelet>Upgrade kubelet</h3>
<ol>
<li>
<p>From the Windows node, upgrade and restart the kubelet:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-powershell data-lang=powershell><span style=color:#a2f>stop-service</span> kubelet
curl.exe -Lo C:\k\kubelet.exe https<span>:</span>//dl.k8s.io/<span style=color:#a2f>/bin/windows/amd64/kubelet.exe
<span style=color:#a2f>restart-service</span> kubelet
</code></pre></div></li>
</ol>
<h3 id=uncordon-the-node>Uncordon the node</h3>
<ol>
<li>
<p>From a machine with access to the Kubernetes API,
bring the node back online by marking it schedulable:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=color:#080;font-style:italic># replace &lt;node-to-drain&gt; with the name of your node</span>
kubectl uncordon &lt;node-to-drain&gt;
</code></pre></div></li>
</ol>
<h3 id=upgrade-kube-proxy>Upgrade kube-proxy</h3>
<ol>
<li>
<p>From a machine with access to the Kubernetes API, run the following,
again replacing v1.23.17 with your desired version:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>curl -L https://github.com/kubernetes-sigs/sig-windows-tools/releases/latest/download/kube-proxy.yml | sed <span style=color:#b44>&#39;s/VERSION/v1.23.17/g&#39;</span> | kubectl apply -f -
</code></pre></div></li>
</ol>
</div>
</main>
</div>
</div>
<footer class=d-print-none>
<div class=footer__links>
<nav>
<a class=text-white href=/docs/home/>Home</a>
<a class=text-white href=/blog/>Blog</a>
<a class=text-white href=/training/>Training</a>
<a class=text-white href=/partners/>Partners</a>
<a class=text-white href=/community/>Community</a>
<a class=text-white href=/case-studies/>Case Studies</a>
</nav>
</div>
<div class=container-fluid>
<div class=row>
<div class="col-6 col-sm-2 text-xs-center order-sm-2">
<ul class="list-inline mb-0">
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="User mailing list" aria-label="User mailing list">
<a class=text-white target=_blank href=https://discuss.kubernetes.io>
<i class="fa fa-envelope"></i>
</a>
</li>
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Twitter aria-label=Twitter>
<a class=text-white target=_blank href=https://twitter.com/kubernetesio>
<i class="fab fa-twitter"></i>
</a>
</li>
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Calendar aria-label=Calendar>
<a class=text-white target=_blank href="https://calendar.google.com/calendar/embed?src=calendar%40kubernetes.io">
<i class="fas fa-calendar-alt"></i>
</a>
</li>
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Youtube aria-label=Youtube>
<a class=text-white target=_blank href=https://youtube.com/kubernetescommunity>
<i class="fab fa-youtube"></i>
</a>
</li>
</ul>
</div>
<div class="col-6 col-sm-2 text-right text-xs-center order-sm-3">
<ul class="list-inline mb-0">
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub>
<a class=text-white target=_blank href=https://github.com/kubernetes/kubernetes>
<i class="fab fa-github"></i>
</a>
</li>
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Slack aria-label=Slack>
<a class=text-white target=_blank href=https://slack.k8s.io>
<i class="fab fa-slack"></i>
</a>
</li>
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Contribute aria-label=Contribute>
<a class=text-white target=_blank href=https://git.k8s.io/community/contributors/guide>
<i class="fas fa-edit"></i>
</a>
</li>
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="Stack Overflow" aria-label="Stack Overflow">
<a class=text-white target=_blank href=https://stackoverflow.com/questions/tagged/kubernetes>
<i class="fab fa-stack-overflow"></i>
</a>
</li>
</ul>
</div>
<div class="col-12 col-sm-8 text-center order-sm-2">
<small class=text-white>&copy; 2023 The Kubernetes Authors | Documentation Distributed under <a href=https://git.k8s.io/website/LICENSE class=light-text>CC BY 4.0</a></small>
<br>
<small class=text-white>Copyright &copy; 2023 The Linux Foundation &reg;. All rights reserved. The Linux Foundation has registered trademarks and uses trademarks. For a list of trademarks of The Linux Foundation, please see our <a href=https://www.linuxfoundation.org/trademark-usage class=light-text>Trademark Usage page</a></small>
<br>
<small class=text-white>ICP license: 京ICP备17074266号-3</small>
</div>
</div>
</div>
</footer>
</div>
<script src=/js/popper-1.14.3.min.js integrity=sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49 crossorigin=anonymous></script>
<script src=/js/bootstrap-4.3.1.min.js integrity=sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM crossorigin=anonymous></script>
<script src=/js/main.min.40616251a9b6e4b689e7769be0340661efa4d7ebb73f957404e963e135b4ed52.js integrity="sha256-QGFiUam25LaJ53ab4DQGYe+k1+u3P5V0BOlj4TW07VI=" crossorigin=anonymous></script>
</body>
</html>