<!doctype html><html lang=zh class=no-js>
<head>
<meta name=ROBOTS content="NOINDEX, NOFOLLOW">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-JPP6RFM2BP"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date),gtag('config','G-JPP6RFM2BP')</script>
<link rel=alternate hreflang=en href=https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/>
<link rel=alternate hreflang=ko href=https://kubernetes.io/ko/docs/concepts/extend-kubernetes/compute-storage-net/>
<link rel=alternate hreflang=fr href=https://kubernetes.io/fr/docs/concepts/extend-kubernetes/compute-storage-net/>
<link rel=alternate hreflang=es href=https://kubernetes.io/es/docs/concepts/extend-kubernetes/compute-storage-net/>
<link rel=alternate hreflang=pt-br href=https://kubernetes.io/pt-br/docs/concepts/extend-kubernetes/compute-storage-net/>
<link rel=alternate hreflang=id href=https://kubernetes.io/id/docs/concepts/extend-kubernetes/compute-storage-net/>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=generator content="Hugo 0.87.0">
<link rel=canonical type=text/html href=https://kubernetes.io/zh/docs/concepts/extend-kubernetes/compute-storage-net/>
<link rel="shortcut icon" type=image/png href=/images/favicon.png>
<link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180>
<link rel=manifest href=/manifest.webmanifest>
<link rel=apple-touch-icon href=/images/kubernetes-192x192.png>
<title>计算、存储和网络扩展 | Kubernetes</title><meta property="og:title" content="计算、存储和网络扩展">
<meta property="og:description" content="生产级别的容器编排系统">
<meta property="og:type" content="website">
<meta property="og:url" content="https://kubernetes.io/zh/docs/concepts/extend-kubernetes/compute-storage-net/"><meta property="og:site_name" content="Kubernetes">
<meta itemprop=name content="计算、存储和网络扩展">
<meta itemprop=description content="生产级别的容器编排系统"><meta name=twitter:card content="summary">
<meta name=twitter:title content="计算、存储和网络扩展">
<meta name=twitter:description content="生产级别的容器编排系统">
<link href=/scss/main.css rel=stylesheet>
<script src=/js/jquery-3.3.1.min.js integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin=anonymous></script>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","url":"https://kubernetes.io","logo":"https://kubernetes.io/images/favicon.png"}</script>
<meta name=theme-color content="#326ce5">
<link rel=stylesheet href=/css/feature-states.css>
<meta name=description content>
<meta property="og:description" content>
<meta name=twitter:description content>
<meta property="og:url" content="https://kubernetes.io/zh/docs/concepts/extend-kubernetes/compute-storage-net/">
<meta property="og:title" content="计算、存储和网络扩展">
<meta name=twitter:title content="计算、存储和网络扩展">
<meta name=twitter:image content="https://kubernetes.io/images/favicon.png">
<meta name=twitter:image:alt content="Kubernetes">
<meta property="og:image" content="/images/kubernetes-horizontal-color.png">
<meta property="og:type" content="article">
<script src=/js/script.js></script>
</head>
<body class=td-section>
<header>
<nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar" data-auto-burger=primary>
<a class=navbar-brand href=/zh/></a>
<div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar>
<ul class="navbar-nav mt-2 mt-lg-0">
<li class="nav-item mr-2 mb-lg-0">
<a class="nav-link active" href=/zh/docs/>文档</a>
</li>
<li class="nav-item mr-2 mb-lg-0">
<a class=nav-link href=/zh/blog/>Kubernetes 博客</a>
</li>
<li class="nav-item mr-2 mb-lg-0">
<a class=nav-link href=/zh/training/>培训</a>
</li>
<li class="nav-item mr-2 mb-lg-0">
<a class=nav-link href=/zh/partners/>合作伙伴</a>
</li>
<li class="nav-item mr-2 mb-lg-0">
<a class=nav-link href=/zh/community/>社区</a>
</li>
<li class="nav-item mr-2 mb-lg-0">
<a class=nav-link href=/zh/case-studies/>案例分析</a>
</li>
<li class="nav-item dropdown">
<a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>
Versions
</a>
<div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink>
<a class=dropdown-item href=/releases>Release Information</a>
<a class=dropdown-item href=https://kubernetes.io/zh/docs/concepts/extend-kubernetes/compute-storage-net/>v1.27</a>
<a class=dropdown-item href=https://v1-26.docs.kubernetes.io/zh/docs/concepts/extend-kubernetes/compute-storage-net/>v1.26</a>
<a class=dropdown-item href=https://v1-25.docs.kubernetes.io/zh/docs/concepts/extend-kubernetes/compute-storage-net/>v1.25</a>
<a class=dropdown-item href=https://v1-24.docs.kubernetes.io/zh/docs/concepts/extend-kubernetes/compute-storage-net/>v1.24</a>
<a class=dropdown-item href=https://v1-23.docs.kubernetes.io/zh/docs/concepts/extend-kubernetes/compute-storage-net/>v1.23</a>
</div>
</li>
<li class="nav-item dropdown">
<a class="nav-link dropdown-toggle" href=# id=navbarDropdownMenuLink role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>
中文 Chinese
</a>
<div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink>
<a class=dropdown-item href=/docs/concepts/extend-kubernetes/compute-storage-net/>English</a>
<a class=dropdown-item href=/ko/docs/concepts/extend-kubernetes/compute-storage-net/>한국어 Korean</a>
<a class=dropdown-item href=/fr/docs/concepts/extend-kubernetes/compute-storage-net/>Français</a>
<a class=dropdown-item href=/es/docs/concepts/extend-kubernetes/compute-storage-net/>Español</a>
<a class=dropdown-item href=/pt-br/docs/concepts/extend-kubernetes/compute-storage-net/>Português</a>
<a class=dropdown-item href=/id/docs/concepts/extend-kubernetes/compute-storage-net/>Bahasa Indonesia</a>
</div>
</li>
</ul>
</div>
<button id=hamburger onclick=kub.toggleMenu() data-auto-burger-exclude><div></div></button>
</nav>
</header>
<div class="container-fluid td-outer">
<div class=td-main>
<div class="row flex-xl-nowrap">
<main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main>
<div class=td-content>
<div class="pageinfo pageinfo-primary d-print-none">
<p>
这是本节的多页打印视图。
<a href=# onclick="return print(),!1">点击此处打印</a>.
</p><p>
<a href=/zh/docs/concepts/extend-kubernetes/compute-storage-net/>返回本页常规视图</a>.
</p>
</div>
<h1 class=title>计算、存储和网络扩展</h1>
<ul>
<li>1: <a href=#pg-1ac2260db9ecccbf0303a899bc27ce6d>网络插件</a></li>
<li>2: <a href=#pg-53e1ea8892ceca307ba19e8d6a7b8d32>设备插件</a></li>
</ul>
<div class=content>
</div>
</div>
<div class=td-content>
<h1 id=pg-1ac2260db9ecccbf0303a899bc27ce6d>1 - 网络插件</h1>
<p>Kubernetes中的网络插件有几种类型：</p>
<ul>
<li>CNI 插件：遵守<a href=https://github.com/containernetworking/cni>容器网络接口（Container Network Interface，CNI）</a>
规范，其设计上偏重互操作性。
<ul>
<li>Kubernetes 遵从 CNI 规范的
<a href=https://github.com/containernetworking/cni/blob/spec-v0.4.0/SPEC.md>v0.4.0</a>
版本。</li>
</ul>
</li>
<li>Kubenet 插件：使用 <code>bridge</code> 和 <code>host-local</code> CNI 插件实现了基本的 <code>cbr0</code>。</li>
</ul>
<h2 id=安装>安装</h2>
<p>kubelet 有一个单独的默认网络插件，以及一个对整个集群通用的默认网络。
它在启动时探测插件，记住找到的内容，并在 Pod 生命周期的适当时间执行
所选插件（这仅适用于 Docker，因为 CRI 管理自己的 CNI 插件）。
在使用插件时，需要记住两个 kubelet 命令行参数：</p>
<ul>
<li><code>cni-bin-dir</code>： kubelet 在启动时探测这个目录中的插件</li>
<li><code>network-plugin</code>： 要使用的网络插件来自 <code>cni-bin-dir</code>。
它必须与从插件目录探测到的插件报告的名称匹配。
对于 CNI 插件，其值为 "cni"。</li>
</ul>
<h2 id=网络插件要求>网络插件要求</h2>
<p>除了提供
<a href=https://github.com/kubernetes/kubernetes/tree/v1.23.17/pkg/kubelet/dockershim/network/plugins.go><code>NetworkPlugin</code> 接口</a>
来配置和清理 Pod 网络之外，该插件还可能需要对 kube-proxy 的特定支持。
iptables 代理显然依赖于 iptables，插件可能需要确保 iptables 能够监控容器的网络通信。
例如，如果插件将容器连接到 Linux 网桥，插件必须将 <code>net/bridge/bridge-nf-call-iptables</code>
系统参数设置为<code>1</code>，以确保 iptables 代理正常工作。
如果插件不使用 Linux 网桥（而是类似于 Open vSwitch 或者其它一些机制），
它应该确保为代理对容器通信执行正确的路由。</p>
<p>默认情况下，如果未指定 kubelet 网络插件，则使用 <code>noop</code> 插件，
该插件设置 <code>net/bridge/bridge-nf-call-iptables=1</code>，以确保简单的配置
（如带网桥的 Docker ）与 iptables 代理正常工作。</p>
<h3 id=cni>CNI</h3>
<p>通过给 Kubelet 传递 <code>--network-plugin=cni</code> 命令行选项可以选择 CNI 插件。
Kubelet 从 <code>--cni-conf-dir</code> （默认是 <code>/etc/cni/net.d</code>） 读取文件并使用
该文件中的 CNI 配置来设置各个 Pod 的网络。
CNI 配置文件必须与
<a href=https://github.com/containernetworking/cni/blob/master/SPEC.md#network-configuration>CNI 规约</a>
匹配，并且配置所引用的所有所需的 CNI 插件都应存在于
<code>--cni-bin-dir</code>（默认是 <code>/opt/cni/bin</code>）下。</p>
<p>如果这个目录中有多个 CNI 配置文件，kubelet 将会使用按文件名的字典顺序排列
的第一个作为配置文件。</p>
<p>除了配置文件指定的 CNI 插件外，Kubernetes 还需要标准的 CNI
<a href=https://github.com/containernetworking/plugins/blob/master/plugins/main/loopback/loopback.go><code>lo</code></a>
插件，最低版本是0.2.0。</p>
<h4 id=支持-hostport>支持 hostPort</h4>
<p>CNI 网络插件支持 <code>hostPort</code>。 你可以使用官方
<a href=https://github.com/containernetworking/plugins/tree/master/plugins/meta/portmap>portmap</a>
插件，它由 CNI 插件团队提供，或者使用你自己的带有 portMapping 功能的插件。</p>
<p>如果你想要启动 <code>hostPort</code> 支持，则必须在 <code>cni-conf-dir</code> 指定 <code>portMappings capability</code>。
例如：</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json>{
  <span style=color:green;font-weight:700>&#34;name&#34;</span>: <span style=color:#b44>&#34;k8s-pod-network&#34;</span>,
  <span style=color:green;font-weight:700>&#34;cniVersion&#34;</span>: <span style=color:#b44>&#34;0.3.0&#34;</span>,
  <span style=color:green;font-weight:700>&#34;plugins&#34;</span>: [
    {
      <span style=color:green;font-weight:700>&#34;type&#34;</span>: <span style=color:#b44>&#34;calico&#34;</span>,
      <span style=color:green;font-weight:700>&#34;log_level&#34;</span>: <span style=color:#b44>&#34;info&#34;</span>,
      <span style=color:green;font-weight:700>&#34;datastore_type&#34;</span>: <span style=color:#b44>&#34;kubernetes&#34;</span>,
      <span style=color:green;font-weight:700>&#34;nodename&#34;</span>: <span style=color:#b44>&#34;127.0.0.1&#34;</span>,
      <span style=color:green;font-weight:700>&#34;ipam&#34;</span>: {
        <span style=color:green;font-weight:700>&#34;type&#34;</span>: <span style=color:#b44>&#34;host-local&#34;</span>,
        <span style=color:green;font-weight:700>&#34;subnet&#34;</span>: <span style=color:#b44>&#34;usePodCidr&#34;</span>
      },
      <span style=color:green;font-weight:700>&#34;policy&#34;</span>: {
        <span style=color:green;font-weight:700>&#34;type&#34;</span>: <span style=color:#b44>&#34;k8s&#34;</span>
      },
      <span style=color:green;font-weight:700>&#34;kubernetes&#34;</span>: {
        <span style=color:green;font-weight:700>&#34;kubeconfig&#34;</span>: <span style=color:#b44>&#34;/etc/cni/net.d/calico-kubeconfig&#34;</span>
      }
    },
    {
      <span style=color:green;font-weight:700>&#34;type&#34;</span>: <span style=color:#b44>&#34;portmap&#34;</span>,
      <span style=color:green;font-weight:700>&#34;capabilities&#34;</span>: {<span style=color:green;font-weight:700>&#34;portMappings&#34;</span>: <span style=color:#a2f;font-weight:700>true</span>}
    }
  ]
}
</code></pre></div>
<h4 id=支持流量整形>支持流量整形</h4>
<p><strong>实验功能</strong></p>
<p>CNI 网络插件还支持 pod 入口和出口流量整形。
你可以使用 CNI 插件团队提供的
<a href=https://github.com/containernetworking/plugins/tree/master/plugins/meta/bandwidth>bandwidth</a>
插件，也可以使用你自己的具有带宽控制功能的插件。</p>
<p>如果你想要启用流量整形支持，你必须将 <code>bandwidth</code> 插件添加到 CNI 配置文件
（默认是 <code>/etc/cni/net.d</code>）并保证该可执行文件包含在你的 CNI 的 bin
文件夹内 (默认为 <code>/opt/cni/bin</code>)。</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json>{
  <span style=color:green;font-weight:700>&#34;name&#34;</span>: <span style=color:#b44>&#34;k8s-pod-network&#34;</span>,
  <span style=color:green;font-weight:700>&#34;cniVersion&#34;</span>: <span style=color:#b44>&#34;0.3.0&#34;</span>,
  <span style=color:green;font-weight:700>&#34;plugins&#34;</span>: [
    {
      <span style=color:green;font-weight:700>&#34;type&#34;</span>: <span style=color:#b44>&#34;calico&#34;</span>,
      <span style=color:green;font-weight:700>&#34;log_level&#34;</span>: <span style=color:#b44>&#34;info&#34;</span>,
      <span style=color:green;font-weight:700>&#34;datastore_type&#34;</span>: <span style=color:#b44>&#34;kubernetes&#34;</span>,
      <span style=color:green;font-weight:700>&#34;nodename&#34;</span>: <span style=color:#b44>&#34;127.0.0.1&#34;</span>,
      <span style=color:green;font-weight:700>&#34;ipam&#34;</span>: {
        <span style=color:green;font-weight:700>&#34;type&#34;</span>: <span style=color:#b44>&#34;host-local&#34;</span>,
        <span style=color:green;font-weight:700>&#34;subnet&#34;</span>: <span style=color:#b44>&#34;usePodCidr&#34;</span>
      },
      <span style=color:green;font-weight:700>&#34;policy&#34;</span>: {
        <span style=color:green;font-weight:700>&#34;type&#34;</span>: <span style=color:#b44>&#34;k8s&#34;</span>
      },
      <span style=color:green;font-weight:700>&#34;kubernetes&#34;</span>: {
        <span style=color:green;font-weight:700>&#34;kubeconfig&#34;</span>: <span style=color:#b44>&#34;/etc/cni/net.d/calico-kubeconfig&#34;</span>
      }
    },
    {
      <span style=color:green;font-weight:700>&#34;type&#34;</span>: <span style=color:#b44>&#34;bandwidth&#34;</span>,
      <span style=color:green;font-weight:700>&#34;capabilities&#34;</span>: {<span style=color:green;font-weight:700>&#34;bandwidth&#34;</span>: <span style=color:#a2f;font-weight:700>true</span>}
    }
  ]
}
</code></pre></div>
<p>现在，你可以将 <code>kubernetes.io/ingress-bandwidth</code> 和 <code>kubernetes.io/egress-bandwidth</code>
注解添加到 pod 中。例如：</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>kubernetes.io/ingress-bandwidth</span>:<span style=color:#bbb> </span>1M<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>kubernetes.io/egress-bandwidth</span>:<span style=color:#bbb> </span>1M<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></code></pre></div>
<h3 id=kubenet>kubenet</h3>
<p>Kubenet 是一个非常基本的、简单的网络插件，仅适用于 Linux。
它本身并不实现更高级的功能，如跨节点网络或网络策略。
它通常与云驱动一起使用，云驱动为节点间或单节点环境中的通信设置路由规则。</p>
<p>Kubenet 创建名为 <code>cbr0</code> 的网桥，并为每个 pod 创建了一个 veth 对，
每个 Pod 的主机端都连接到 <code>cbr0</code>。
这个 veth 对的 Pod 端会被分配一个 IP 地址，该 IP 地址隶属于节点所被分配的 IP
地址范围内。节点的 IP 地址范围则通过配置或控制器管理器来设置。
<code>cbr0</code> 被分配一个 MTU，该 MTU 匹配主机上已启用的正常接口的最小 MTU。</p>
<p>使用此插件还需要一些其他条件：</p>
<ul>
<li>需要标准的 CNI <code>bridge</code>、<code>lo</code> 以及 <code>host-local</code> 插件，最低版本是0.2.0。
kubenet 首先在 <code>/opt/cni/bin</code> 中搜索它们。 指定 <code>cni-bin-dir</code> 以提供
其它搜索路径。首次找到的匹配将生效。</li>
<li>Kubelet 必须和 <code>--network-plugin=kubenet</code> 参数一起运行，才能启用该插件。</li>
<li>Kubelet 还应该和 <code>--non-masquerade-cidr=&lt;clusterCidr></code> 参数一起运行，
以确保超出此范围的 IP 流量将使用 IP 伪装。</li>
<li>节点必须被分配一个 IP 子网，通过kubelet 命令行的 <code>--pod-cidr</code> 选项或
控制器管理器的命令行选项 <code>--allocate-node-cidrs=true --cluster-cidr=&lt;cidr></code>
来设置。</li>
</ul>
<h3 id=自定义-mtu-使用-kubenet>自定义 MTU（使用 kubenet）</h3>
<p>要获得最佳的网络性能，必须确保 MTU 的取值配置正确。
网络插件通常会尝试推断出一个合理的 MTU，但有时候这个逻辑不会产生一个最优的 MTU。
例如，如果 Docker 网桥或其他接口有一个小的 MTU, kubenet 当前将选择该 MTU。
或者如果你正在使用 IPSEC 封装，则必须减少 MTU，并且这种计算超出了大多数网络插件的能力范围。</p>
<p>如果需要，你可以使用 <code>network-plugin-mtu</code> kubelet 选项显式的指定 MTU。
例如：在 AWS 上 <code>eth0</code> MTU 通常是 9001，因此你可以指定 <code>--network-plugin-mtu=9001</code>。
如果你正在使用 IPSEC ，你可以减少它以允许封装开销，例如 <code>--network-plugin-mtu=8873</code>。</p>
<p>此选项会传递给网络插件； 当前 <strong>仅 kubenet 支持 <code>network-plugin-mtu</code></strong>。</p>
<h2 id=用法总结>用法总结</h2>
<ul>
<li><code>--network-plugin=cni</code> 用来表明我们要使用 <code>cni</code> 网络插件，实际的 CNI 插件
可执行文件位于 <code>--cni-bin-dir</code>（默认是 <code>/opt/cni/bin</code>）下， CNI 插件配置位于
<code>--cni-conf-dir</code>（默认是 <code>/etc/cni/net.d</code>）下。</li>
<li><code>--network-plugin=kubenet</code> 用来表明我们要使用 <code>kubenet</code> 网络插件，CNI <code>bridge</code>，<code>lo</code>
和 <code>host-local</code> 插件位于 <code>/opt/cni/bin</code> 或 <code>cni-bin-dir</code> 中。</li>
<li><code>--network-plugin-mtu=9001</code> 指定了我们使用的 MTU，当前仅被 <code>kubenet</code> 网络插件使用。</li>
</ul>
<h2 id=what-s-next>What's next</h2>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-53e1ea8892ceca307ba19e8d6a7b8d32>2 - 设备插件</h1>
<div class=lead>使用 Kubernetes 设备插件框架来实现适用于 GPU、NIC、FPGA、InfiniBand 以及类似的需要特定于供应商设置的资源的插件。</div>
<div style=margin-top:10px;margin-bottom:10px>
<b>FEATURE STATE:</b> <code>Kubernetes v1.10 [beta]</code>
</div>
<p>Kubernetes 提供了一个
<a href=https://github.com/kubernetes/community/blob/master/contributors/design-proposals/resource-management/device-plugin.md>设备插件框架</a>，你可以用它来将系统硬件资源发布到 <a class=glossary-tooltip title="一个在集群中每个节点上运行的代理。它保证容器都运行在 Pod 中。" data-toggle=tooltip data-placement=top href=/docs/reference/generated/kubelet target=_blank aria-label=Kubelet>Kubelet</a>。</p>
<p>供应商可以实现设备插件，由你手动部署或作为 <a class=glossary-tooltip title="确保 Pod 的副本在集群中的一组节点上运行。" data-toggle=tooltip data-placement=top href=/zh/docs/concepts/workloads/controllers/daemonset/ target=_blank aria-label=DaemonSet>DaemonSet</a>
来部署，而不必定制 Kubernetes 本身的代码。目标设备包括 GPU、高性能 NIC、FPGA、
InfiniBand 适配器以及其他类似的、可能需要特定于供应商的初始化和设置的计算资源。</p>
<h2 id=device-plugin-registration>注册设备插件 </h2>
<p><code>kubelet</code> 提供了一个 <code>Registration</code> 的 gRPC 服务：</p>
<pre><code class=language-gRPC data-lang=gRPC>service Registration {
 rpc Register(RegisterRequest) returns (Empty) {}
}
</code></pre>
<p>设备插件可以通过此 gRPC 服务在 kubelet 进行注册。在注册期间，设备插件需要发送下面几样内容：</p>
<ul>
<li>设备插件的 Unix 套接字。</li>
<li>设备插件的 API 版本。</li>
<li><code>ResourceName</code> 是需要公布的。这里 <code>ResourceName</code> 需要遵循
<a href=/zh/docs/concepts/configuration/manage-resources-containers/#extended-resources>扩展资源命名方案</a>，
类似于 <code>vendor-domain/resourcetype</code>。（比如 NVIDIA GPU 就被公布为 <code>nvidia.com/gpu</code>。）</li>
</ul>
<p>成功注册后，设备插件就向 kubelet 发送它所管理的设备列表，然后 kubelet
负责将这些资源发布到 API 服务器，作为 kubelet 节点状态更新的一部分。</p>
<p>比如，设备插件在 kubelet 中注册了 <code>hardware-vendor.example/foo</code> 并报告了
节点上的两个运行状况良好的设备后，节点状态将更新以通告该节点已安装 2 个
"Foo" 设备并且是可用的。</p>
<p>然后用户需要请求其他类型的资源的时候，就可以在
<a href=/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core>Container</a>
规范请求这类设备，但是有以下的限制：</p>
<ul>
<li>扩展资源仅可作为整数资源使用，并且不能被过量使用</li>
<li>设备不能在容器之间共享</li>
</ul>
<h3 id=example-pod>示例</h3>
<p>假设 Kubernetes 集群正在运行一个设备插件，该插件在一些节点上公布的资源为 <code>hardware-vendor.example/foo</code>。
下面就是一个 Pod 示例，请求此资源以运行一个工作负载的示例：</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>demo-pod<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>demo-container-1<span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/pause:2.0<span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>hardware-vendor.example/foo</span>:<span style=color:#bbb> </span><span style=color:#666>2</span><span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:#080;font-style:italic>#</span><span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:#080;font-style:italic># 这个 pod 需要两个 hardware-vendor.example/foo 设备</span><span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:#080;font-style:italic># 而且只能够调度到满足需求的节点上</span><span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:#080;font-style:italic>#</span><span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:#080;font-style:italic># 如果该节点中有 2 个以上的设备可用，其余的可供其他 Pod 使用</span><span style=color:#bbb>
</span></code></pre></div>
<h2 id=device-plugin-implementation>设备插件的实现 </h2>
<p>设备插件的常规工作流程包括以下几个步骤：</p>
<ul>
<li>
<p>初始化。在这个阶段，设备插件将执行供应商特定的初始化和设置，
以确保设备处于就绪状态。</p>
</li>
<li>
<p>插件使用主机路径 <code>/var/lib/kubelet/device-plugins/</code> 下的 Unix 套接字启动
一个 gRPC 服务，该服务实现以下接口：</p>
<pre><code class=language-gRPC data-lang=gRPC>service DevicePlugin {
      // GetDevicePluginOptions 返回与设备管理器沟通的选项。
      rpc GetDevicePluginOptions(Empty) returns (DevicePluginOptions) {}

      // ListAndWatch 返回 Device 列表构成的数据流。
      // 当 Device 状态发生变化或者 Device 消失时，ListAndWatch
      // 会返回新的列表。
      rpc ListAndWatch(Empty) returns (stream ListAndWatchResponse) {}

      // Allocate 在容器创建期间调用，这样设备插件可以运行一些特定于设备的操作，
      // 并告诉 kubelet 如何令 Device 可在容器中访问的所需执行的具体步骤
      rpc Allocate(AllocateRequest) returns (AllocateResponse) {}

      // GetPreferredAllocation 从一组可用的设备中返回一些优选的设备用来分配，
      // 所返回的优选分配结果不一定会是设备管理器的最终分配方案。
      // 此接口的设计仅是为了让设备管理器能够在可能的情况下做出更有意义的决定。
      rpc GetPreferredAllocation(PreferredAllocationRequest) returns (PreferredAllocationResponse) {}

      // PreStartContainer 在设备插件注册阶段根据需要被调用，调用发生在容器启动之前。
      // 在将设备提供给容器使用之前，设备插件可以运行一些诸如重置设备之类的特定于
      // 具体设备的操作，
      rpc PreStartContainer(PreStartContainerRequest) returns (PreStartContainerResponse) {}
}
</code></pre><div class="alert alert-info note callout" role=alert>
<strong>Note:</strong>
<p>插件并非必须为 <code>GetPreferredAllocation()</code> 或 <code>PreStartContainer()</code> 提供有用
的实现逻辑，调用 <code>GetDevicePluginOptions()</code> 时所返回的 <code>DevicePluginOptions</code>
消息中应该设置这些调用是否可用。<code>kubelet</code> 在真正调用这些函数之前，总会调用
<code>GetDevicePluginOptions()</code> 来查看是否存在这些可选的函数。
</div>
</li>
</ul>
<ul>
<li>插件通过 Unix socket 在主机路径 <code>/var/lib/kubelet/device-plugins/kubelet.sock</code>
处向 kubelet 注册自身。</li>
<li>成功注册自身后，设备插件将以服务模式运行，在此期间，它将持续监控设备运行状况，
并在设备状态发生任何变化时向 kubelet 报告。它还负责响应 <code>Allocate</code> gRPC 请求。
在 <code>Allocate</code> 期间，设备插件可能还会做一些设备特定的准备；例如 GPU 清理或 QRNG 初始化。
如果操作成功，则设备插件将返回 <code>AllocateResponse</code>，其中包含用于访问被分配的设备容器运行时的配置。
kubelet 将此信息传递到容器运行时。</li>
</ul>
<h3 id=处理-kubelet-重启>处理 kubelet 重启</h3>
<p>设备插件应能监测到 kubelet 重启，并且向新的 kubelet 实例来重新注册自己。
在当前实现中，当 kubelet 重启的时候，新的 kubelet 实例会删除 <code>/var/lib/kubelet/device-plugins</code>
下所有已经存在的 Unix 套接字。
设备插件需要能够监控到它的 Unix 套接字被删除，并且当发生此类事件时重新注册自己。</p>
<h2 id=设备插件部署>设备插件部署</h2>
<p>你可以将你的设备插件作为节点操作系统的软件包来部署、作为 DaemonSet 来部署或者手动部署。</p>
<p>规范目录 <code>/var/lib/kubelet/device-plugins</code> 是需要特权访问的，所以设备插件
必须要在被授权的安全的上下文中运行。
如果你将设备插件部署为 DaemonSet，<code>/var/lib/kubelet/device-plugins</code> 目录必须要在插件的
<a href=/docs/reference/generated/kubernetes-api/v1.23/#podspec-v1-core>PodSpec</a>
中声明作为 <a class=glossary-tooltip title="包含可被 Pod 中容器访问的数据的目录。" data-toggle=tooltip data-placement=top href=/zh/docs/concepts/storage/volumes/ target=_blank aria-label=卷（Volume）>卷（Volume）</a> 被挂载到插件中。</p>
<p>如果你选择 DaemonSet 方法，你可以通过 Kubernetes 进行以下操作：
将设备插件的 Pod 放置在节点上，在出现故障后重新启动守护进程 Pod，来进行自动升级。</p>
<h2 id=api-兼容性>API 兼容性</h2>
<p>Kubernetes 设备插件支持还处于 beta 版本。所以在稳定版本出来之前 API 会以不兼容的方式进行更改。
作为一个项目，Kubernetes 建议设备插件开发者：</p>
<ul>
<li>注意未来版本的更改</li>
<li>支持多个版本的设备插件 API，以实现向后/向前兼容性。</li>
</ul>
<p>如果你启用 DevicePlugins 功能，并在需要升级到 Kubernetes 版本来获得较新的设备插件 API
版本的节点上运行设备插件，请在升级这些节点之前先升级设备插件以支持这两个版本。
采用该方法将确保升级期间设备分配的连续运行。</p>
<h2 id=监控设备插件资源>监控设备插件资源</h2>
<div style=margin-top:10px;margin-bottom:10px>
<b>FEATURE STATE:</b> <code>Kubernetes v1.15 [beta]</code>
</div>
<p>为了监控设备插件提供的资源，监控代理程序需要能够发现节点上正在使用的设备，
并获取元数据来描述哪个指标与容器相关联。
设备监控代理暴露给 <a href=https://prometheus.io/>Prometheus</a> 的指标应该遵循
<a href=https://github.com/kubernetes/community/blob/master/contributors/devel/sig-instrumentation/instrumentation.md>Kubernetes Instrumentation Guidelines</a>，
使用 <code>pod</code>、<code>namespace</code> 和 <code>container</code> 标签来标识容器。</p>
<p>kubelet 提供了 gRPC 服务来使得正在使用中的设备被发现，并且还未这些设备提供了元数据：</p>
<pre><code class=language-gRPC data-lang=gRPC>// PodResourcesLister 是一个由 kubelet 提供的服务，用来提供供节点上 
// Pods 和容器使用的节点资源的信息
service PodResourcesLister {
    rpc List(ListPodResourcesRequest) returns (ListPodResourcesResponse) {}
    rpc GetAllocatableResources(AllocatableResourcesRequest) returns (AllocatableResourcesResponse) {}
}
</code></pre><h3 id=grpc-endpoint-list><code>List</code> gRPC 端点</h3>
<p>这一 <code>List</code> 端点提供运行中 Pods 的资源信息，包括类似独占式分配的
CPU ID、设备插件所报告的设备 ID 以及这些设备分配所处的 NUMA 节点 ID。
此外，对于基于 NUMA 的机器，它还会包含为容器保留的内存和大页的信息。</p>
<pre><code class=language-gRPC data-lang=gRPC>// ListPodResourcesResponse 是 List 函数的响应
message ListPodResourcesResponse {
    repeated PodResources pod_resources = 1;
}

// PodResources 包含关于分配给 Pod 的节点资源的信息
message PodResources {
    string name = 1;
    string namespace = 2;
    repeated ContainerResources containers = 3;
}

// ContainerResources 包含分配给容器的资源的信息
message ContainerResources {
    string name = 1;
    repeated ContainerDevices devices = 2;
    repeated int64 cpu_ids = 3;
    repeated ContainerMemory memory = 4;
}

// ContainerMemory 包含分配给容器的内存和大页信息
message ContainerMemory {
    string memory_type = 1;
    uint64 size = 2;
    TopologyInfo topology = 3;
}

// Topology 描述资源的硬件拓扑结构
message TopologyInfo {
        repeated NUMANode nodes = 1;
}

// NUMA 代表的是 NUMA 节点
message NUMANode {
        int64 ID = 1;
}

// ContainerDevices 包含分配给容器的设备信息
message ContainerDevices {
    string resource_name = 1;
    repeated string device_ids = 2;
    TopologyInfo topology = 3;
}
</code></pre>
<div class="alert alert-info note callout" role=alert>
<strong>Note:</strong> <p><code>List</code> 端点中的 <code>ContainerResources</code> 中的 cpu_ids 对应于分配给某个容器的专属 CPU。
如果要统计共享池中的 CPU，<code>List</code> 端点需要与 <code>GetAllocatableResources</code> 端点一起使用，如下所述:</p>
<ol>
<li>调用 <code>GetAllocatableResources</code> 获取所有可用的 CPUs。</li>
<li>在系统中所有的 <code>ContainerResources</code> 上调用 <code>GetCpuIds</code>。</li>
<li>用 <code>GetAllocatableResources</code> 获取的 CPU 数减去 <code>GetCpuIds</code> 获取的 CPU 数。</li>
</ol>
</div>
<h3 id=grpc-endpoint-getallocatableresources><code>GetAllocatableResources</code> gRPC 端点</h3>
<div style=margin-top:10px;margin-bottom:10px>
<b>FEATURE STATE:</b> <code>Kubernetes v1.23 [beta]</code>
</div>
<div class="alert alert-info note callout" role=alert>
<strong>Note:</strong> <code>GetAllocatableResources</code> 应该仅被用于评估一个节点上的<a href=/zh/docs/tasks/administer-cluster/reserve-compute-resources/#node-allocatable>可分配的</a>
资源。如果目标是评估空闲/未分配的资源，此调用应该与 List() 端点一起使用。
除非暴露给 kubelet 的底层资源发生变化 否则 <code>GetAllocatableResources</code> 得到的结果将保持不变。
这种情况很少发生，但当发生时（例如：热插拔，设备健康状况改变），客户端应该调用 <code>GetAlloctableResources</code> 端点。
然而，调用 <code>GetAllocatableResources</code> 端点在 cpu、内存被更新的情况下是不够的，
Kubelet 需要重新启动以获取正确的资源容量和可分配的资源。
</div>
<p>端点 <code>GetAllocatableResources</code> 提供最初在工作节点上可用的资源的信息。
此端点所提供的信息比导出给 API 服务器的信息更丰富。</p>
<pre><code class=language-gRPC data-lang=gRPC>// AllocatableResourcesResponses 包含 kubelet 所了解到的所有设备的信息
message AllocatableResourcesResponse {
    repeated ContainerDevices devices = 1;
    repeated int64 cpu_ids = 2;
    repeated ContainerMemory memory = 3;
}

</code></pre>
<p>从 Kubernetes v1.23 开始，<code>GetAllocatableResources</code> 被默认启用。
你可以通过关闭 <code>KubeletPodResourcesGetAllocatable</code>
<a href=/zh/docs/reference/command-line-tools-reference/feature-gates/>特性门控</a> 来禁用。</p>
<p>在 Kubernetes v1.23 之前，要启用这一功能，<code>kubelet</code> 必须用以下标志启动：</p>
<p><code>--feature-gates=KubeletPodResourcesGetAllocatable=true</code></p>
<p><code>ContainerDevices</code> 会向外提供各个设备所隶属的 NUMA 单元这类拓扑信息。
NUMA 单元通过一个整数 ID 来标识，其取值与设备插件所报告的一致。
<a href=/zh/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/>设备插件注册到 kubelet 时</a>
会报告这类信息。</p>
<p>gRPC 服务通过 <code>/var/lib/kubelet/pod-resources/kubelet.sock</code> 的 UNIX 套接字来提供服务。
设备插件资源的监控代理程序可以部署为守护进程或者 DaemonSet。
规范的路径 <code>/var/lib/kubelet/pod-resources</code> 需要特权来进入，
所以监控代理程序必须要在获得授权的安全的上下文中运行。
如果设备监控代理以 DaemonSet 形式运行，必须要在插件的
<a href=/docs/reference/generated/kubernetes-api/v1.23/#podspec-v1-core>PodSpec</a>
中声明将 <code>/var/lib/kubelet/pod-resources</code> 目录以
<a class=glossary-tooltip title="包含可被 Pod 中容器访问的数据的目录。" data-toggle=tooltip data-placement=top href=/zh/docs/concepts/storage/volumes/ target=_blank aria-label=卷>卷</a>的形式被挂载到设备监控代理中。</p>
<p>对“PodResourcesLister 服务”的支持要求启用 <code>KubeletPodResources</code>
<a href=/zh/docs/reference/command-line-tools-reference/feature-gates/>特性门控</a>。
从 Kubernetes 1.15 开始默认启用，自从 Kubernetes 1.20 开始为 v1。</p>
<h2 id=设备插件与拓扑管理器的集成>设备插件与拓扑管理器的集成</h2>
<div style=margin-top:10px;margin-bottom:10px>
<b>FEATURE STATE:</b> <code>Kubernetes v1.18 [beta]</code>
</div>
<p>拓扑管理器是 Kubelet 的一个组件，它允许以拓扑对齐方式来调度资源。
为了做到这一点，设备插件 API 进行了扩展来包括一个 <code>TopologyInfo</code> 结构体。</p>
<pre><code class=language-gRPC data-lang=gRPC>message TopologyInfo {
 repeated NUMANode nodes = 1;
}

message NUMANode {
    int64 ID = 1;
}
</code></pre>
<p>设备插件希望拓扑管理器可以将填充的 TopologyInfo 结构体作为设备注册的一部分以及设备 ID
和设备的运行状况发送回去。然后设备管理器将使用此信息来咨询拓扑管理器并做出资源分配决策。</p>
<p><code>TopologyInfo</code> 支持定义 <code>nodes</code> 字段，允许为 <code>nil</code>（默认）或者是一个 NUMA 节点的列表。
这样就可以使设备插件可以跨越 NUMA 节点去发布。</p>
<p>下面是一个由设备插件为设备填充 <code>TopologyInfo</code> 结构体的示例：</p>
<pre><code>pluginapi.Device{ID: &quot;25102017&quot;, Health: pluginapi.Healthy, Topology:&amp;pluginapi.TopologyInfo{Nodes: []*pluginapi.NUMANode{&amp;pluginapi.NUMANode{ID: 0,},}}}
</code></pre>
<h2 id=examples>设备插件示例</h2>
<p>下面是一些设备插件实现的示例：</p>
<ul>
<li><a href=https://github.com/RadeonOpenCompute/k8s-device-plugin>AMD GPU 设备插件</a></li>
<li><a href=https://github.com/intel/intel-device-plugins-for-kubernetes>Intel 设备插件</a> 支持 Intel GPU、FPGA 和 QuickAssist 设备</li>
<li><a href=https://github.com/kubevirt/kubernetes-device-plugins>KubeVirt 设备插件</a> 用于硬件辅助的虚拟化</li>
<li>The <a href=https://github.com/NVIDIA/k8s-device-plugin>NVIDIA GPU 设备插件</a></li>
<li>需要 <a href=https://github.com/NVIDIA/nvidia-docker>nvidia-docker</a> 2.0，以允许运行 Docker 容器的时候启用 GPU。</li>
<li><a href=https://github.com/GoogleCloudPlatform/container-engine-accelerators/tree/master/cmd/nvidia_gpu>为 Container-Optimized OS 所提供的 NVIDIA GPU 设备插件</a></li>
<li><a href=https://github.com/hustcat/k8s-rdma-device-plugin>RDMA 设备插件</a></li>
<li><a href=https://github.com/collabora/k8s-socketcan>SocketCAN 设备插件</a></li>
<li><a href=https://github.com/vikaschoudhary16/sfc-device-plugin>Solarflare 设备插件</a></li>
<li><a href=https://github.com/intel/sriov-network-device-plugin>SR-IOV 网络设备插件</a></li>
<li><a href=https://github.com/Xilinx/FPGA_as_a_Service/tree/master/k8s-fpga-device-plugin>Xilinx FPGA 设备插件</a></li>
</ul>
<h2 id=what-s-next>What's next</h2>
<ul>
<li>查看<a href=/zh/docs/tasks/manage-gpus/scheduling-gpus/>调度 GPU 资源</a> 来学习使用设备插件</li>
<li>查看在上如何<a href=/zh/docs/tasks/administer-cluster/extended-resource-node/>公布节点上的扩展资源</a></li>
<li>阅读如何在 Kubernetes 中使用 <a href=https://kubernetes.io/blog/2019/04/24/hardware-accelerated-ssl/tls-termination-in-ingress-controllers-using-kubernetes-device-plugins-and-runtimeclass/>TLS Ingress 的硬件加速</a></li>
<li>学习<a href=/zh/docs/tasks/administer-cluster/topology-manager/>拓扑管理器</a></li>
</ul>
</div>
</main>
</div>
</div>
<footer class=d-print-none>
<div class=footer__links>
<nav>
<a class=text-white href=/zh/docs/home/>主页</a>
<a class=text-white href=/zh/blog/>博客</a>
<a class=text-white href=/zh/training/>培训</a>
<a class=text-white href=/zh/partners/>合作伙伴</a>
<a class=text-white href=/zh/community/>社区</a>
<a class=text-white href=/zh/case-studies/>案例分析</a>
</nav>
</div>
<div class=container-fluid>
<div class=row>
<div class="col-6 col-sm-2 text-xs-center order-sm-2">
<ul class="list-inline mb-0">
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="User mailing list" aria-label="User mailing list">
<a class=text-white target=_blank href=https://discuss.kubernetes.io>
<i class="fa fa-envelope"></i>
</a>
</li>
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Twitter aria-label=Twitter>
<a class=text-white target=_blank href=https://twitter.com/kubernetesio>
<i class="fab fa-twitter"></i>
</a>
</li>
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Calendar aria-label=Calendar>
<a class=text-white target=_blank href="https://calendar.google.com/calendar/embed?src=calendar%40kubernetes.io">
<i class="fas fa-calendar-alt"></i>
</a>
</li>
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Youtube aria-label=Youtube>
<a class=text-white target=_blank href=https://youtube.com/kubernetescommunity>
<i class="fab fa-youtube"></i>
</a>
</li>
</ul>
</div>
<div class="col-6 col-sm-2 text-right text-xs-center order-sm-3">
<ul class="list-inline mb-0">
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub>
<a class=text-white target=_blank href=https://github.com/kubernetes/kubernetes>
<i class="fab fa-github"></i>
</a>
</li>
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Slack aria-label=Slack>
<a class=text-white target=_blank href=https://slack.k8s.io>
<i class="fab fa-slack"></i>
</a>
</li>
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Contribute aria-label=Contribute>
<a class=text-white target=_blank href=https://git.k8s.io/community/contributors/guide>
<i class="fas fa-edit"></i>
</a>
</li>
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="Stack Overflow" aria-label="Stack Overflow">
<a class=text-white target=_blank href=https://stackoverflow.com/questions/tagged/kubernetes>
<i class="fab fa-stack-overflow"></i>
</a>
</li>
</ul>
</div>
<div class="col-12 col-sm-8 text-center order-sm-2">
<small class=text-white>&copy; 2023 The Kubernetes Authors | Documentation Distributed under <a href=https://git.k8s.io/website/LICENSE class=light-text>CC BY 4.0</a></small>
<br>
<small class=text-white>Copyright &copy; 2023 The Linux Foundation &reg;. All rights reserved. The Linux Foundation has registered trademarks and uses trademarks. For a list of trademarks of The Linux Foundation, please see our <a href=https://www.linuxfoundation.org/trademark-usage class=light-text>Trademark Usage page</a></small>
<br>
<small class=text-white>ICP license: 京ICP备17074266号-3</small>
</div>
</div>
</div>
</footer>
</div>
<script src=/js/popper-1.14.3.min.js integrity=sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49 crossorigin=anonymous></script>
<script src=/js/bootstrap-4.3.1.min.js integrity=sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM crossorigin=anonymous></script>
<script src=/js/main.min.40616251a9b6e4b689e7769be0340661efa4d7ebb73f957404e963e135b4ed52.js integrity="sha256-QGFiUam25LaJ53ab4DQGYe+k1+u3P5V0BOlj4TW07VI=" crossorigin=anonymous></script>
</body>
</html>