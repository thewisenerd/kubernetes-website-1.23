<!doctype html><html lang=en class=no-js>
<head>
<meta name=ROBOTS content="NOINDEX, NOFOLLOW">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-JPP6RFM2BP"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date),gtag('config','G-JPP6RFM2BP')</script>
<link rel=alternate hreflang=zh href=https://kubernetes.io/zh/docs/setup/production-environment/windows/>
<link rel=alternate hreflang=ko href=https://kubernetes.io/ko/docs/setup/production-environment/windows/>
<link rel=alternate hreflang=ja href=https://kubernetes.io/ja/docs/setup/production-environment/windows/>
<link rel=alternate hreflang=fr href=https://kubernetes.io/fr/docs/setup/production-environment/windows/>
<link rel=alternate hreflang=uk href=https://kubernetes.io/uk/docs/setup/production-environment/windows/>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=generator content="Hugo 0.87.0">
<link rel=canonical type=text/html href=https://kubernetes.io/docs/setup/production-environment/windows/>
<link rel="shortcut icon" type=image/png href=/images/favicon.png>
<link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180>
<link rel=manifest href=/manifest.webmanifest>
<link rel=apple-touch-icon href=/images/kubernetes-192x192.png>
<title>Windows in Kubernetes | Kubernetes</title><meta property="og:title" content="Windows in Kubernetes">
<meta property="og:description" content="Production-Grade Container Orchestration">
<meta property="og:type" content="website">
<meta property="og:url" content="https://kubernetes.io/docs/setup/production-environment/windows/"><meta property="og:site_name" content="Kubernetes">
<meta itemprop=name content="Windows in Kubernetes">
<meta itemprop=description content="Production-Grade Container Orchestration"><meta name=twitter:card content="summary">
<meta name=twitter:title content="Windows in Kubernetes">
<meta name=twitter:description content="Production-Grade Container Orchestration">
<link href=/scss/main.css rel=stylesheet>
<script src=/js/jquery-3.3.1.min.js integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin=anonymous></script>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","url":"https://kubernetes.io","logo":"https://kubernetes.io/images/favicon.png"}</script>
<meta name=theme-color content="#326ce5">
<link rel=stylesheet href=/css/feature-states.css>
<meta name=description content>
<meta property="og:description" content>
<meta name=twitter:description content>
<meta property="og:url" content="https://kubernetes.io/docs/setup/production-environment/windows/">
<meta property="og:title" content="Windows in Kubernetes">
<meta name=twitter:title content="Windows in Kubernetes">
<meta name=twitter:image content="https://kubernetes.io/images/favicon.png">
<meta name=twitter:image:alt content="Kubernetes">
<meta property="og:image" content="/images/kubernetes-horizontal-color.png">
<meta property="og:type" content="article">
<script src=/js/script.js></script>
</head>
<body class=td-section>
<header>
<nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar" data-auto-burger=primary>
<a class=navbar-brand href=/></a>
<div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar>
<ul class="navbar-nav mt-2 mt-lg-0">
<li class="nav-item mr-2 mb-lg-0">
<a class="nav-link active" href=/docs/>Documentation</a>
</li>
<li class="nav-item mr-2 mb-lg-0">
<a class=nav-link href=/blog/>Kubernetes Blog</a>
</li>
<li class="nav-item mr-2 mb-lg-0">
<a class=nav-link href=/training/>Training</a>
</li>
<li class="nav-item mr-2 mb-lg-0">
<a class=nav-link href=/partners/>Partners</a>
</li>
<li class="nav-item mr-2 mb-lg-0">
<a class=nav-link href=/community/>Community</a>
</li>
<li class="nav-item mr-2 mb-lg-0">
<a class=nav-link href=/case-studies/>Case Studies</a>
</li>
<li class="nav-item dropdown">
<a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>
Versions
</a>
<div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink>
<a class=dropdown-item href=/releases>Release Information</a>
<a class=dropdown-item href=https://kubernetes.io/docs/setup/production-environment/windows/>v1.27</a>
<a class=dropdown-item href=https://v1-26.docs.kubernetes.io/docs/setup/production-environment/windows/>v1.26</a>
<a class=dropdown-item href=https://v1-25.docs.kubernetes.io/docs/setup/production-environment/windows/>v1.25</a>
<a class=dropdown-item href=https://v1-24.docs.kubernetes.io/docs/setup/production-environment/windows/>v1.24</a>
<a class=dropdown-item href=https://v1-23.docs.kubernetes.io/docs/setup/production-environment/windows/>v1.23</a>
</div>
</li>
<li class="nav-item dropdown">
<a class="nav-link dropdown-toggle" href=# id=navbarDropdownMenuLink role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>
English
</a>
<div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink>
<a class=dropdown-item href=/zh/docs/setup/production-environment/windows/>中文 Chinese</a>
<a class=dropdown-item href=/ko/docs/setup/production-environment/windows/>한국어 Korean</a>
<a class=dropdown-item href=/ja/docs/setup/production-environment/windows/>日本語 Japanese</a>
<a class=dropdown-item href=/fr/docs/setup/production-environment/windows/>Français</a>
<a class=dropdown-item href=/uk/docs/setup/production-environment/windows/>Українська</a>
</div>
</li>
</ul>
</div>
<button id=hamburger onclick=kub.toggleMenu() data-auto-burger-exclude><div></div></button>
</nav>
</header>
<div class="container-fluid td-outer">
<div class=td-main>
<div class="row flex-xl-nowrap">
<main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main>
<div class=td-content>
<div class="pageinfo pageinfo-primary d-print-none">
<p>
This is the multi-page printable view of this section.
<a href=# onclick="return print(),!1">Click here to print</a>.
</p><p>
<a href=/docs/setup/production-environment/windows/>Return to the regular view of this page</a>.
</p>
</div>
<h1 class=title>Windows in Kubernetes</h1>
<ul>
<li>1: <a href=#pg-a307d413f1f7430fced233023087e2a1>Windows containers in Kubernetes</a></li>
<li>2: <a href=#pg-3a51e66c5de55f9093a8dc55742006d3>Guide for scheduling Windows containers in Kubernetes</a></li>
</ul>
<div class=content>
</div>
</div>
<div class=td-content>
<h1 id=pg-a307d413f1f7430fced233023087e2a1>1 - Windows containers in Kubernetes</h1>
<p>Windows applications constitute a large portion of the services and applications that
run in many organizations. <a href=https://aka.ms/windowscontainers>Windows containers</a>
provide a way to encapsulate processes and package dependencies, making it easier
to use DevOps practices and follow cloud native patterns for Windows applications.</p>
<p>Organizations with investments in Windows-based applications and Linux-based
applications don't have to look for separate orchestrators to manage their workloads,
leading to increased operational efficiencies across their deployments, regardless
of operating system.</p>
<h2 id=windows-nodes-in-kubernetes>Windows nodes in Kubernetes</h2>
<p>To enable the orchestration of Windows containers in Kubernetes, include Windows nodes
in your existing Linux cluster. Scheduling Windows containers in
<a class=glossary-tooltip title="A Pod represents a set of running containers in your cluster." data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/pods/ target=_blank aria-label=Pods>Pods</a> on Kubernetes is similar to
scheduling Linux-based containers.</p>
<p>In order to run Windows containers, your Kubernetes cluster must include
multiple operating systems.
While you can only run the <a class=glossary-tooltip title="The container orchestration layer that exposes the API and interfaces to define, deploy, and manage the lifecycle of containers." data-toggle=tooltip data-placement=top href="/docs/reference/glossary/?all=true#term-control-plane" target=_blank aria-label="control plane">control plane</a> on Linux, you can deploy worker nodes running either Windows or Linux depending on your workload needs.</p>
<p>Windows <a class=glossary-tooltip title="A node is a worker machine in Kubernetes." data-toggle=tooltip data-placement=top href=/docs/concepts/architecture/nodes/ target=_blank aria-label=nodes>nodes</a> are
<a href=#windows-os-version-support>supported</a> provided that the operating system is
Windows Server 2019.</p>
<p>This document uses the term <em>Windows containers</em> to mean Windows containers with
process isolation. Kubernetes does not support running Windows containers with
<a href=https://docs.microsoft.com/en-us/virtualization/windowscontainers/manage-containers/hyperv-container>Hyper-V isolation</a>.</p>
<h2 id=resource-management>Resource management</h2>
<p>On Linux nodes, <a class=glossary-tooltip title="A group of Linux processes with optional resource isolation, accounting and limits." data-toggle=tooltip data-placement=top href="/docs/reference/glossary/?all=true#term-cgroup" target=_blank aria-label=cgroups>cgroups</a> are used
as a pod boundary for resource control. Containers are created within that boundary
for network, process and file system isolation. The Linux cgroup APIs can be used
to gather CPU, I/O, and memory use statistics.</p>
<p>In contrast, Windows uses a <em>job object</em> per container with a system namespace filter
to contain all processes in a container and provide logical isolation from the
host.
(Job objects are a Windows process isolation mechanism and are different from
what Kubernetes refers to as a <a class=glossary-tooltip title="A finite or batch task that runs to completion." data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/job/ target=_blank aria-label=Job>Job</a>).</p>
<p>There is no way to run a Windows container without the namespace filtering in
place. This means that system privileges cannot be asserted in the context of the
host, and thus privileged containers are not available on Windows.
Containers cannot assume an identity from the host because the Security Account Manager
(SAM) is separate.</p>
<h4 id=resource-management-memory>Memory reservations</h4>
<p>Windows does not have an out-of-memory process killer as Linux does. Windows always
treats all user-mode memory allocations as virtual, and pagefiles are mandatory
(on Linux, the kubelet will by default not start with swap space enabled).</p>
<p>Windows nodes do not overcommit memory for processes running in containers. The
net effect is that Windows won't reach out of memory conditions the same way Linux
does, and processes page to disk instead of being subject to out of memory (OOM)
termination. If memory is over-provisioned and all physical memory is exhausted,
then paging can slow down performance.</p>
<p>You can place bounds on memory use for workloads using the kubelet
parameters <code>--kubelet-reserve</code> and/or <code>--system-reserve</code>; these account
for memory usage on the node (outside of containers), and reduce
<a href=/docs/tasks/administer-cluster/reserve-compute-resources/#node-allocatable>NodeAllocatable</a>.
As you deploy workloads, set resource limits on containers. This also subtracts from
<code>NodeAllocatable</code> and prevents the scheduler from adding more pods once a node is full.</p>
<div class="alert alert-info note callout" role=alert>
<strong>Note:</strong> When you set memory resource limits for Windows containers, you should either set a
limit and leave the memory request unspecified, or set the request equal to the limit.
</div>
<p>On Windows, good practice to avoid over-provisioning is to configure the kubelet
with a system reserved memory of at least 2GiB to account for Windows, Kubernetes
and container runtime overheads.</p>
<h4 id=resource-management-cpu>CPU reservations</h4>
<p>To account for CPU use by the operating system, the container runtime, and by
Kubernetes host processes such as the kubelet, you can (and should) reserve a
percentage of total CPU. You should determine this CPU reservation taking account of
to the number of CPU cores available on the node. To decide on the CPU percentage to
reserve, identify the maximum pod density for each node and monitor the CPU usage of
the system services running there, then choose a value that meets your workload needs.</p>
<p>You can place bounds on CPU usage for workloads using the
kubelet parameters <code>--kubelet-reserve</code> and/or <code>--system-reserve</code> to
account for CPU usage on the node (outside of containers).
This reduces <code>NodeAllocatable</code>.
The cluster-wide scheduler then takes this reservation into account when determining
pod placement.</p>
<p>On Windows, the kubelet supports a command-line flag to set the priority of the
kubelet process: <code>--windows-priorityclass</code>. This flag allows the kubelet process to get
more CPU time slices when compared to other processes running on the Windows host.
More information on the allowable values and their meaning is available at
<a href=https://docs.microsoft.com/en-us/windows/win32/procthread/scheduling-priorities#priority-class>Windows Priority Classes</a>.
To ensure that running Pods do not starve the kubelet of CPU cycles, set this flag to <code>ABOVE_NORMAL_PRIORITY_CLASS</code> or above.</p>
<h2 id=limitations>Compatibility and limitations</h2>
<p>Some node features are only available if you use a specific
<a href=#container-runtime>container runtime</a>; others are not available on Windows nodes,
including:</p>
<ul>
<li>HugePages: not supported for Windows containers</li>
<li>Privileged containers: not supported for Windows containers</li>
<li>TerminationGracePeriod: requires containerD</li>
</ul>
<p>Not all features of shared namespaces are supported. See <a href=#api>API compatibility</a>
for more details.</p>
<p>See <a href=#windows-os-version-support>Windows OS version compatibility</a> for details on
the Windows versions that Kubernetes is tested against.</p>
<p>From an API and kubectl perspective, Windows containers behave in much the same
way as Linux-based containers. However, there are some notable differences in key
functionality which are outlined in this section.</p>
<h3 id=compatibility-linux-similarities>Comparison with Linux</h3>
<p>Key Kubernetes elements work the same way in Windows as they do in Linux. This
section refers to several key workload enablers and how they map to Windows.</p>
<ul>
<li>
<p><a href=/docs/concepts/workloads/pods/>Pods</a></p>
<p>A Pod is the basic building block of Kubernetes–the smallest and simplest unit in
the Kubernetes object model that you create or deploy. You may not deploy Windows and
Linux containers in the same Pod. All containers in a Pod are scheduled onto a single
Node where each Node represents a specific platform and architecture. The following
Pod capabilities, properties and events are supported with Windows containers:</p>
<ul>
<li>Single or multiple containers per Pod with process isolation and volume sharing</li>
<li>Pod <code>status</code> fields</li>
<li>Readiness and Liveness probes</li>
<li>postStart & preStop container lifecycle events</li>
<li>ConfigMap, Secrets: as environment variables or volumes</li>
<li><code>emptyDir</code> volumes</li>
<li>Named pipe host mounts</li>
<li>Resource limits</li>
<li>OS field:
<div style=margin-top:10px;margin-bottom:10px>
<b>FEATURE STATE:</b> <code>Kubernetes v1.23 [alpha]</code>
</div>
<code>.spec.os.name</code> should be set to <code>windows</code> to indicate that the current Pod uses Windows containers.
<code>IdentifyPodOS</code> feature gate needs to be enabled for this field to be recognized and used by control plane
components and kubelet.
<div class="alert alert-info note callout" role=alert>
<strong>Note:</strong> <p>If the <code>IdentifyPodOS</code> feature gate is enabled and you set the <code>.spec.os.name</code> field to <code>windows</code>, you must not set the following fields in the <code>.spec</code> of that Pod:
* <code>spec.hostPID</code>
* <code>spec.hostIPC</code>
* <code>spec.securityContext.seLinuxOptions</code>
* <code>spec.securityContext.seccompProfile</code>
* <code>spec.securityContext.fsGroup</code>
* <code>spec.securityContext.fsGroupChangePolicy</code>
* <code>spec.securityContext.sysctls</code>
* <code>spec.shareProcessNamespace</code>
* <code>spec.securityContext.runAsUser</code>
* <code>spec.securityContext.runAsGroup</code>
* <code>spec.securityContext.supplementalGroups</code>
* <code>spec.containers[*].securityContext.seLinuxOptions</code>
* <code>spec.containers[*].securityContext.seccompProfile</code>
* <code>spec.containers[*].securityContext.capabilities</code>
* <code>spec.containers[*].securityContext.readOnlyRootFilesystem</code>
* <code>spec.containers[*].securityContext.privileged</code>
* <code>spec.containers[*].securityContext.allowPrivilegeEscalation</code>
* <code>spec.containers[*].securityContext.procMount</code>
* <code>spec.containers[*].securityContext.runAsUser</code>
* <code>spec.containers[*].securityContext.runAsGroup</code></p>
<pre><code>        Note: In this table, wildcards (*) indicate all elements in a list. For example, spec.containers[*].securityContext refers to the Security Context object for all defined containers. If not, Pod API validation would fail causing admission failures.</code></pre>
</div></li>
</ul>
</li>
<li>
<p><a href=/docs/concepts/workloads/controllers/>Workload resources</a> including:</p>
<ul>
<li>ReplicaSet</li>
<li>Deployments</li>
<li>StatefulSets</li>
<li>DaemonSet</li>
<li>Job</li>
<li>CronJob</li>
<li>ReplicationController</li>
</ul>
</li>
<li>
<p><a class=glossary-tooltip title="A way to expose an application running on a set of Pods as a network service." data-toggle=tooltip data-placement=top href=/docs/concepts/services-networking/service/ target=_blank aria-label=Services>Services</a>
See <a href=#load-balancing-and-services>Load balancing and Services</a> for more details.</p>
</li>
</ul>
<p>Pods, workload resources, and Services are critical elements to managing Windows
workloads on Kubernetes. However, on their own they are not enough to enable
the proper lifecycle management of Windows workloads in a dynamic cloud native
environment. Kubernetes also supports:</p>
<ul>
<li><code>kubectl exec</code></li>
<li>Pod and container metrics</li>
<li><a class=glossary-tooltip title="An API resource that automatically scales the number of pod replicas based on targeted CPU utilization or custom metric targets." data-toggle=tooltip data-placement=top href=/docs/tasks/run-application/horizontal-pod-autoscale/ target=_blank aria-label="Horizontal pod autoscaling">Horizontal pod autoscaling</a></li>
<li><a class=glossary-tooltip title="Provides constraints that limit aggregate resource consumption per namespace." data-toggle=tooltip data-placement=top href=/docs/concepts/policy/resource-quotas/ target=_blank aria-label="Resource quotas">Resource quotas</a></li>
<li>Scheduler preemption</li>
</ul>
<h3 id=compatibility-networking>Networking on Windows nodes</h3>
<p>Networking for Windows containers is exposed through
<a href=/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/>CNI plugins</a>.
Windows containers function similarly to virtual machines in regards to
networking. Each container has a virtual network adapter (vNIC) which is connected
to a Hyper-V virtual switch (vSwitch). The Host Networking Service (HNS) and the
Host Compute Service (HCS) work together to create containers and attach container
vNICs to networks. HCS is responsible for the management of containers whereas HNS
is responsible for the management of networking resources such as:</p>
<ul>
<li>Virtual networks (including creation of vSwitches)</li>
<li>Endpoints / vNICs</li>
<li>Namespaces</li>
<li>Policies including packet encapsulations, load-balancing rules, ACLs, and NAT rules.</li>
</ul>
<h4 id=networking>Container networking</h4>
<p>The Windows HNS and vSwitch implement namespacing and can
create virtual NICs as needed for a pod or container. However, many configurations such
as DNS, routes, and metrics are stored in the Windows registry database rather than as
files inside <code>/etc</code>, which is how Linux stores those configurations. The Windows registry for the container
is separate from that of the host, so concepts like mapping <code>/etc/resolv.conf</code> from
the host into a container don't have the same effect they would on Linux. These must
be configured using Windows APIs run in the context of that container. Therefore
CNI implementations need to call the HNS instead of relying on file mappings to pass
network details into the pod or container.</p>
<p>The following networking functionality is <em>not</em> supported on Windows nodes:</p>
<ul>
<li>Host networking mode</li>
<li>Local NodePort access from the node itself (works for other nodes or external clients)</li>
<li>More than 64 backend pods (or unique destination addresses) for a single Service</li>
<li>IPv6 communication between Windows pods connected to overlay networks</li>
<li>Local Traffic Policy in non-DSR mode</li>
<li>Outbound communication using the ICMP protocol via the <code>win-overlay</code>, <code>win-bridge</code>, or using the Azure-CNI plugin.<br>
Specifically, the Windows data plane (<a href=https://www.microsoft.com/en-us/research/project/azure-virtual-filtering-platform/>VFP</a>) doesn't support ICMP packet transpositions, and this means:
<ul>
<li>ICMP packets directed to destinations within the same network (such as pod to pod communication via ping) work as expected and without any limitations;</li>
<li>TCP/UDP packets work as expected and without any limitations;</li>
<li>ICMP packets directed to pass through a remote network (e.g. pod to external internet communication via ping) cannot be transposed and thus will not be routed back to their source;</li>
<li>Since TCP/UDP packets can still be transposed, you can substitute <code>ping &lt;destination></code> with <code>curl &lt;destination></code> to get some debugging insight into connectivity with the outside world.</li>
</ul>
</li>
</ul>
<p>Overlay networking support in kube-proxy is a beta feature. In addition, it requires
<a href=https://support.microsoft.com/en-us/help/4482887/windows-10-update-kb4482887>KB4482887</a>
to be installed on Windows Server 2019.</p>
<h4 id=network-modes>Network modes</h4>
<p>Windows supports five different networking drivers/modes: L2bridge, L2tunnel,
Overlay (beta), Transparent, and NAT. In a heterogeneous cluster with Windows and Linux
worker nodes, you need to select a networking solution that is compatible on both
Windows and Linux. The following out-of-tree plugins are supported on Windows,
with recommendations on when to use each CNI:</p>
<table>
<thead>
<tr>
<th>Network Driver</th>
<th>Description</th>
<th>Container Packet Modifications</th>
<th>Network Plugins</th>
<th>Network Plugin Characteristics</th>
</tr>
</thead>
<tbody>
<tr>
<td>L2bridge</td>
<td>Containers are attached to an external vSwitch. Containers are attached to the underlay network, although the physical network doesn't need to learn the container MACs because they are rewritten on ingress/egress.</td>
<td>MAC is rewritten to host MAC, IP may be rewritten to host IP using HNS OutboundNAT policy.</td>
<td><a href=https://github.com/containernetworking/plugins/tree/master/plugins/main/windows/win-bridge>win-bridge</a>, <a href=https://github.com/Azure/azure-container-networking/blob/master/docs/cni.md>Azure-CNI</a>, Flannel host-gateway uses win-bridge</td>
<td>win-bridge uses L2bridge network mode, connects containers to the underlay of hosts, offering best performance. Requires user-defined routes (UDR) for inter-node connectivity.</td>
</tr>
<tr>
<td>L2Tunnel</td>
<td>This is a special case of l2bridge, but only used on Azure. All packets are sent to the virtualization host where SDN policy is applied.</td>
<td>MAC rewritten, IP visible on the underlay network</td>
<td><a href=https://github.com/Azure/azure-container-networking/blob/master/docs/cni.md>Azure-CNI</a></td>
<td>Azure-CNI allows integration of containers with Azure vNET, and allows them to leverage the set of capabilities that <a href=https://azure.microsoft.com/en-us/services/virtual-network/>Azure Virtual Network provides</a>. For example, securely connect to Azure services or use Azure NSGs. See <a href=https://docs.microsoft.com/en-us/azure/aks/concepts-network#azure-cni-advanced-networking>azure-cni for some examples</a></td>
</tr>
<tr>
<td>Overlay (Overlay networking for Windows in Kubernetes is in <em>alpha</em> stage)</td>
<td>Containers are given a vNIC connected to an external vSwitch. Each overlay network gets its own IP subnet, defined by a custom IP prefix.The overlay network driver uses VXLAN encapsulation.</td>
<td>Encapsulated with an outer header.</td>
<td><a href=https://github.com/containernetworking/plugins/tree/master/plugins/main/windows/win-overlay>win-overlay</a>, Flannel VXLAN (uses win-overlay)</td>
<td>win-overlay should be used when virtual container networks are desired to be isolated from underlay of hosts (e.g. for security reasons). Allows for IPs to be re-used for different overlay networks (which have different VNID tags) if you are restricted on IPs in your datacenter. This option requires <a href=https://support.microsoft.com/help/4489899>KB4489899</a> on Windows Server 2019.</td>
</tr>
<tr>
<td>Transparent (special use case for <a href=https://github.com/openvswitch/ovn-kubernetes>ovn-kubernetes</a>)</td>
<td>Requires an external vSwitch. Containers are attached to an external vSwitch which enables intra-pod communication via logical networks (logical switches and routers).</td>
<td>Packet is encapsulated either via <a href=https://datatracker.ietf.org/doc/draft-gross-geneve/>GENEVE</a> or <a href=https://datatracker.ietf.org/doc/draft-davie-stt/>STT</a> tunneling to reach pods which are not on the same host. <br> Packets are forwarded or dropped via the tunnel metadata information supplied by the ovn network controller. <br> NAT is done for north-south communication.</td>
<td><a href=https://github.com/openvswitch/ovn-kubernetes>ovn-kubernetes</a></td>
<td><a href=https://github.com/openvswitch/ovn-kubernetes/tree/master/contrib>Deploy via ansible</a>. Distributed ACLs can be applied via Kubernetes policies. IPAM support. Load-balancing can be achieved without kube-proxy. NATing is done without using iptables/netsh.</td>
</tr>
<tr>
<td>NAT (<em>not used in Kubernetes</em>)</td>
<td>Containers are given a vNIC connected to an internal vSwitch. DNS/DHCP is provided using an internal component called <a href=https://techcommunity.microsoft.com/t5/virtualization/windows-nat-winnat-capabilities-and-limitations/ba-p/382303>WinNAT</a></td>
<td>MAC and IP is rewritten to host MAC/IP.</td>
<td><a href=https://github.com/Microsoft/windows-container-networking/tree/master/plugins/nat>nat</a></td>
<td>Included here for completeness</td>
</tr>
</tbody>
</table>
<p>As outlined above, the <a href=https://github.com/coreos/flannel>Flannel</a>
CNI <a href=https://github.com/containernetworking/plugins/tree/master/plugins/meta/flannel>meta plugin</a>
is also <a href=https://github.com/containernetworking/plugins/tree/master/plugins/meta/flannel#windows-support-experimental>supported</a> on Windows via the
<a href=https://github.com/coreos/flannel/blob/master/Documentation/backends.md#vxlan>VXLAN network backend</a> (<strong>alpha support</strong> ; delegates to win-overlay)
and <a href=https://github.com/coreos/flannel/blob/master/Documentation/backends.md#host-gw>host-gateway network backend</a> (stable support; delegates to win-bridge).</p>
<p>This plugin supports delegating to one of the reference CNI plugins (win-overlay,
win-bridge), to work in conjunction with Flannel daemon on Windows (Flanneld) for
automatic node subnet lease assignment and HNS network creation. This plugin reads
in its own configuration file (cni.conf), and aggregates it with the environment
variables from the FlannelD generated subnet.env file. It then delegates to one of
the reference CNI plugins for network plumbing, and sends the correct configuration
containing the node-assigned subnet to the IPAM plugin (for example: <code>host-local</code>).</p>
<p>For Node, Pod, and Service objects, the following network flows are supported for
TCP/UDP traffic:</p>
<ul>
<li>Pod → Pod (IP)</li>
<li>Pod → Pod (Name)</li>
<li>Pod → Service (Cluster IP)</li>
<li>Pod → Service (PQDN, but only if there are no ".")</li>
<li>Pod → Service (FQDN)</li>
<li>Pod → external (IP)</li>
<li>Pod → external (DNS)</li>
<li>Node → Pod</li>
<li>Pod → Node</li>
</ul>
<h4 id=cni-plugin-limitations>CNI plugin limitations</h4>
<ul>
<li>Windows reference network plugins win-bridge and win-overlay do not implement
<a href=https://github.com/containernetworking/cni/blob/master/SPEC.md>CNI spec</a> v0.4.0,
due to a missing <code>CHECK</code> implementation.</li>
<li>The Flannel VXLAN CNI plugin has the following limitations on Windows:</li>
</ul>
<ol>
<li>Node-pod connectivity isn't possible by design. It's only possible for local pods with Flannel v0.12.0 (or higher).</li>
<li>Flannel is restricted to using VNI 4096 and UDP port 4789. See the official
<a href=https://github.com/coreos/flannel/blob/master/Documentation/backends.md#vxlan>Flannel VXLAN</a>
backend docs for more details on these parameters.</li>
</ol>
<h4 id=ipam>IP address management (IPAM)</h4>
<p>The following IPAM options are supported on Windows:</p>
<ul>
<li><a href=https://github.com/containernetworking/plugins/tree/master/plugins/ipam/host-local>host-local</a></li>
<li>HNS IPAM (Inbox platform IPAM, this is a fallback when no IPAM is set)</li>
<li><a href=https://github.com/Azure/azure-container-networking/blob/master/docs/ipam.md>azure-vnet-ipam</a> (for azure-cni only)</li>
</ul>
<h4 id=load-balancing-and-services>Load balancing and Services</h4>
<p>A Kubernetes <a class=glossary-tooltip title="A way to expose an application running on a set of Pods as a network service." data-toggle=tooltip data-placement=top href=/docs/concepts/services-networking/service/ target=_blank aria-label=Service>Service</a> is an abstraction
that defines a logical set of Pods and a means to access them over a network.
In a cluster that includes Windows nodes, you can use the following types of Service:</p>
<ul>
<li><code>NodePort</code></li>
<li><code>ClusterIP</code></li>
<li><code>LoadBalancer</code></li>
<li><code>ExternalName</code></li>
</ul>
<div class="alert alert-danger warning callout" role=alert>
<strong>Warning:</strong> <p>There are known issue with NodePort services on overlay networking, if the target destination node is running Windows Server 2022.
To avoid the issue entirely, you can configure the service with <code>externalTrafficPolicy: Local</code>.</p>
<p>There are known issues with pod to pod connectivity on l2bridge network on Windows Server 2022 with KB5005619 or higher installed.
To workaround the issue and restore pod-pod connectivity, you can disable the WinDSR feature in kube-proxy.</p>
<p>These issues require OS fixes.
Please follow <a href=https://github.com/microsoft/Windows-Containers/issues/204>https://github.com/microsoft/Windows-Containers/issues/204</a> for updates.</p>
</div>
<p>Windows container networking differs in some important ways from Linux networking.
The <a href=https://docs.microsoft.com/en-us/virtualization/windowscontainers/container-networking/architecture>Microsoft documentation for Windows Container Networking</a> provides
additional details and background.</p>
<p>On Windows, you can use the following settings to configure Services and load
balancing behavior:</p>
<table><caption style=display:none>Windows Service Settings</caption>
<thead>
<tr>
<th>Feature</th>
<th>Description</th>
<th>Supported Kubernetes version</th>
<th>Supported Windows OS build</th>
<th>How to enable</th>
</tr>
</thead>
<tbody>
<tr>
<td>Session affinity</td>
<td>Ensures that connections from a particular client are passed to the same Pod each time.</td>
<td>v1.20+</td>
<td><a href=https://blogs.windows.com/windowsexperience/2020/01/28/announcing-windows-server-vnext-insider-preview-build-19551/>Windows Server vNext Insider Preview Build 19551</a> (or higher)</td>
<td>Set <code>service.spec.sessionAffinity</code> to "ClientIP"</td>
</tr>
<tr>
<td>Direct Server Return (DSR)</td>
<td>Load balancing mode where the IP address fixups and the LBNAT occurs at the container vSwitch port directly; service traffic arrives with the source IP set as the originating pod IP.</td>
<td>v1.20+</td>
<td>Windows Server 2019</td>
<td>Set the following flags in kube-proxy: <code>--feature-gates="WinDSR=true" --enable-dsr=true</code></td>
</tr>
<tr>
<td>Preserve-Destination</td>
<td>Skips DNAT of service traffic, thereby preserving the virtual IP of the target service in packets reaching the backend Pod. Also disables node-node forwarding.</td>
<td>v1.20+</td>
<td>Windows Server, version 1903 (or higher)</td>
<td>Set <code>"preserve-destination": "true"</code> in service annotations and enable DSR in kube-proxy.</td>
</tr>
<tr>
<td>IPv4/IPv6 dual-stack networking</td>
<td>Native IPv4-to-IPv4 in parallel with IPv6-to-IPv6 communications to, from, and within a cluster</td>
<td>v1.19+</td>
<td>Windows Server, version 2019</td>
<td>See <a href=#ipv4ipv6-dual-stack>IPv4/IPv6 dual-stack</a></td>
</tr>
<tr>
<td>Client IP preservation</td>
<td>Ensures that source IP of incoming ingress traffic gets preserved. Also disables node-node forwarding.</td>
<td>v1.20+</td>
<td>Windows Server, version 2019</td>
<td>Set <code>service.spec.externalTrafficPolicy</code> to "Local" and enable DSR in kube-proxy</td>
</tr>
</tbody>
</table>
<h5 id=session-affinity>Session affinity</h5>
<p>Setting the maximum session sticky time for Windows services using
<code>service.spec.sessionAffinityConfig.clientIP.timeoutSeconds</code> is not supported.</p>
<h4 id=dns-limitations>DNS</h4>
<ul>
<li>ClusterFirstWithHostNet is not supported for DNS. Windows treats all names with a
<code>.</code> as a FQDN and skips FQDN resolution</li>
<li>On Linux, you have a DNS suffix list, which is used when trying to resolve PQDNs. On
Windows, you can only have 1 DNS suffix, which is the DNS suffix associated with that
pod's namespace (mydns.svc.cluster.local for example). Windows can resolve FQDNs
and services or names resolvable with just that suffix. For example, a pod spawned
in the default namespace, will have the DNS suffix <strong>default.svc.cluster.local</strong>.
Inside a Windows pod, you can resolve both <strong>kubernetes.default.svc.cluster.local</strong>
and <strong>kubernetes</strong>, but not the in-betweens, like <strong>kubernetes.default</strong> or
<strong>kubernetes.default.svc</strong>.</li>
<li>On Windows, there are multiple DNS resolvers that can be used. As these come with
slightly different behaviors, using the <code>Resolve-DNSName</code> utility for name query
resolutions is recommended.</li>
</ul>
<h4 id=ipv6-networking>IPv6 networking</h4>
<p>Kubernetes on Windows does not support single-stack "IPv6-only" networking. However,
dual-stack IPv4/IPv6 networking for pods and nodes with single-family services
is supported.</p>
<p>You can use IPv4/IPv6 dual-stack networking with <code>l2bridge</code> networks. See <a href=/docs/concepts/services-networking/dual-stack#configure-ipv4-ipv6-dual-stack>configure IPv4/IPv6 dual stack</a> for more details.</p>
<div class="alert alert-info note callout" role=alert>
<strong>Note:</strong> Overlay (VXLAN) networks on Windows do not support dual-stack networking.
</div>
<h3 id=compatibility-storage>Persistent storage</h3>
<p>Windows has a layered filesystem driver to mount container layers and create a copy
filesystem based on NTFS. All file paths in the container are resolved only within
the context of that container.</p>
<ul>
<li>With Docker, volume mounts can only target a directory in the container, and not
an individual file. This limitation does not exist with CRI-containerD runtime.</li>
<li>Volume mounts cannot project files or directories back to the host filesystem.</li>
<li>Read-only filesystems are not supported because write access is always required
for the Windows registry and SAM database. However, read-only volumes are supported.</li>
<li>Volume user-masks and permissions are not available. Because the SAM is not shared
between the host & container, there's no mapping between them. All permissions are
resolved within the context of the container.</li>
</ul>
<p>As a result, the following storage functionality is not supported on Windows nodes:</p>
<ul>
<li>Volume subpath mounts: only the entire volume can be mounted in a Windows container</li>
<li>Subpath volume mounting for Secrets</li>
<li>Host mount projection</li>
<li>Read-only root filesystem (mapped volumes still support <code>readOnly</code>)</li>
<li>Block device mapping</li>
<li>Memory as the storage medium (for example, <code>emptyDir.medium</code> set to <code>Memory</code>)</li>
<li>File system features like uid/gid; per-user Linux filesystem permissions</li>
<li>DefaultMode (due to UID/GID dependency)</li>
<li>NFS based storage/volume support</li>
<li>Expanding the mounted volume (resizefs)</li>
</ul>
<p>Kubernetes <a class=glossary-tooltip title="A directory containing data, accessible to the containers in a pod." data-toggle=tooltip data-placement=top href=/docs/concepts/storage/volumes/ target=_blank aria-label=volumes>volumes</a> enable complex
applications, with data persistence and Pod volume sharing requirements, to be deployed
on Kubernetes. Management of persistent volumes associated with a specific storage
back-end or protocol includes actions such as provisioning/de-provisioning/resizing
of volumes, attaching/detaching a volume to/from a Kubernetes node and
mounting/dismounting a volume to/from individual containers in a pod that needs to
persist data.</p>
<p>The code implementing these volume management actions for a specific storage back-end
or protocol is shipped in the form of a Kubernetes volume
<a href=/docs/concepts/storage/volumes/#types-of-volumes>plugin</a>.
The following broad classes of Kubernetes volume plugins are supported on Windows:</p>
<h5 id=in-tree-volume-plugins>In-tree volume plugins</h5>
<p>Code associated with in-tree volume plugins ship as part of the core Kubernetes code
base. Deployment of in-tree volume plugins do not require installation of additional
scripts or deployment of separate containerized plugin components. These plugins can
handle provisioning/de-provisioning and resizing of volumes in the storage backend,
attaching/detaching of volumes to/from a Kubernetes node and mounting/dismounting a
volume to/from individual containers in a pod. The following in-tree plugins support
persistent storage on Windows nodes:</p>
<ul>
<li><a href=/docs/concepts/storage/volumes/#awselasticblockstore><code>awsElasticBlockStore</code></a></li>
<li><a href=/docs/concepts/storage/volumes/#azuredisk><code>azureDisk</code></a></li>
<li><a href=/docs/concepts/storage/volumes/#azurefile><code>azureFile</code></a></li>
<li><a href=/docs/concepts/storage/volumes/#gcepersistentdisk><code>gcePersistentDisk</code></a></li>
<li><a href=/docs/concepts/storage/volumes/#vspherevolume><code>vsphereVolume</code></a></li>
</ul>
<h4 id=flexvolume-plugins>FlexVolume plugins</h4>
<p>Code associated with <a href=/docs/concepts/storage/volumes/#flexVolume>FlexVolume</a>
plugins ship as out-of-tree scripts or binaries that need to be deployed directly
on the host. FlexVolume plugins handle attaching/detaching of volumes to/from a
Kubernetes node and mounting/dismounting a volume to/from individual containers
in a pod. Provisioning/De-provisioning of persistent volumes associated
with FlexVolume plugins may be handled through an external provisioner that
is typically separate from the FlexVolume plugins. The following FlexVolume
<a href=https://github.com/Microsoft/K8s-Storage-Plugins/tree/master/flexvolume/windows>plugins</a>,
deployed as PowerShell scripts on the host, support Windows nodes:</p>
<ul>
<li><a href=https://github.com/microsoft/K8s-Storage-Plugins/tree/master/flexvolume/windows/plugins/microsoft.com~smb.cmd>SMB</a></li>
<li><a href=https://github.com/microsoft/K8s-Storage-Plugins/tree/master/flexvolume/windows/plugins/microsoft.com~iscsi.cmd>iSCSI</a></li>
</ul>
<h4 id=csi-plugins>CSI plugins</h4>
<div style=margin-top:10px;margin-bottom:10px>
<b>FEATURE STATE:</b> <code>Kubernetes v1.19 [beta]</code>
</div>
<p>Code associated with <a class=glossary-tooltip title="The Container Storage Interface (CSI) defines a standard interface to expose storage systems to containers." data-toggle=tooltip data-placement=top href=/docs/concepts/storage/volumes/#csi target=_blank aria-label=CSI>CSI</a> plugins ship
as out-of-tree scripts and binaries that are typically distributed as container
images and deployed using standard Kubernetes constructs like DaemonSets and
StatefulSets.
CSI plugins handle a wide range of volume management actions in Kubernetes:
provisioning/de-provisioning/resizing of volumes, attaching/detaching of volumes
to/from a Kubernetes node and mounting/dismounting a volume to/from individual
containers in a pod, backup/restore of persistent data using snapshots and cloning.
CSI plugins typically consist of node plugins (that run on each node as a DaemonSet)
and controller plugins.</p>
<p>CSI node plugins (especially those associated with persistent volumes exposed as
either block devices or over a shared file-system) need to perform various privileged
operations like scanning of disk devices, mounting of file systems, etc. These
operations differ for each host operating system. For Linux worker nodes, containerized
CSI node plugins are typically deployed as privileged containers. For Windows worker
nodes, privileged operations for containerized CSI node plugins is supported using
<a href=https://github.com/kubernetes-csi/csi-proxy>csi-proxy</a>, a community-managed,
stand-alone binary that needs to be pre-installed on each Windows node.</p>
<p>For more details, refer to the deployment guide of the CSI plugin you wish to deploy.</p>
<h3 id=kubelet-compatibility>Command line options for the kubelet</h3>
<p>The behavior of some kubelet command line options behave differently on Windows, as described below:</p>
<ul>
<li>The <code>--windows-priorityclass</code> lets you set the scheduling priority of the kubelet process (see <a href=#resource-management-cpu>CPU resource management</a>)</li>
<li>The <code>--kubelet-reserve</code>, <code>--system-reserve</code> , and <code>--eviction-hard</code> flags update <a href=/docs/tasks/administer-cluster/reserve-compute-resources/#node-allocatable>NodeAllocatable</a></li>
<li>Eviction by using <code>--enforce-node-allocable</code> is not implemented</li>
<li>Eviction by using <code>--eviction-hard</code> and <code>--eviction-soft</code> are not implemented</li>
<li>A kubelet running on a Windows node does not have memory
restrictions. <code>--kubelet-reserve</code> and <code>--system-reserve</code> do not set limits on
kubelet or processes running on the host. This means kubelet or a process on the host
could cause memory resource starvation outside the node-allocatable and scheduler.</li>
<li>The <code>MemoryPressure</code> Condition is not implemented</li>
<li>The kubelet does not take OOM eviction actions</li>
</ul>
<h3 id=api>API compatibility</h3>
<p>There are no differences in how most of the Kubernetes APIs work for Windows. The
subtleties around what's different come down to differences in the OS and container
runtime. In certain situations, some properties on workload resources were designed
under the assumption that they would be implemented on Linux, and fail to run on Windows.</p>
<p>At a high level, these OS concepts are different:</p>
<ul>
<li>Identity - Linux uses userID (UID) and groupID (GID) which
are represented as integer types. User and group names
are not canonical - they are just an alias in <code>/etc/groups</code>
or <code>/etc/passwd</code> back to UID+GID. Windows uses a larger binary
<a href=https://docs.microsoft.com/en-us/windows/security/identity-protection/access-control/security-identifiers>security identifier</a> (SID)
which is stored in the Windows Security Access Manager (SAM) database. This
database is not shared between the host and containers, or between containers.</li>
<li>File permissions - Windows uses an access control list based on (SIDs), whereas
POSIX systems such as Linux use a bitmask based on object permissions and UID+GID,
plus <em>optional</em> access control lists.</li>
<li>File paths - the convention on Windows is to use <code>\</code> instead of <code>/</code>. The Go IO
libraries typically accept both and just make it work, but when you're setting a
path or command line that's interpreted inside a container, <code>\</code> may be needed.</li>
<li>Signals - Windows interactive apps handle termination differently, and can
implement one or more of these:
<ul>
<li>A UI thread handles well-defined messages including <code>WM_CLOSE</code>.</li>
<li>Console apps handle Ctrl-C or Ctrl-break using a Control Handler.</li>
<li>Services register a Service Control Handler function that can accept
<code>SERVICE_CONTROL_STOP</code> control codes.</li>
</ul>
</li>
</ul>
<p>Container exit codes follow the same convention where 0 is success, and nonzero is failure.
The specific error codes may differ across Windows and Linux. However, exit codes
passed from the Kubernetes components (kubelet, kube-proxy) are unchanged.</p>
<h5 id=compatibility-v1-pod-spec-containers>Field compatibility for container specifications</h5>
<p>The following list documents differences between how Pod container specifications
work between Windows and Linux:</p>
<ul>
<li>Huge pages are not implemented in the Windows container
runtime, and are not available. They require <a href=https://docs.microsoft.com/en-us/windows/desktop/Memory/large-page-support>asserting a user
privilege</a>
that's not configurable for containers.</li>
<li><code>requests.cpu</code> and <code>requests.memory</code> - requests are subtracted
from node available resources, so they can be used to avoid overprovisioning a
node. However, they cannot be used to guarantee resources in an overprovisioned
node. They should be applied to all containers as a best practice if the operator
wants to avoid overprovisioning entirely.</li>
<li><code>securityContext.allowPrivilegeEscalation</code> -
not possible on Windows; none of the capabilities are hooked up</li>
<li><code>securityContext.capabilities</code> -
POSIX capabilities are not implemented on Windows</li>
<li><code>securityContext.privileged</code> -
Windows doesn't support privileged containers</li>
<li><code>securityContext.procMount</code> -
Windows doesn't have a <code>/proc</code> filesystem</li>
<li><code>securityContext.readOnlyRootFilesystem</code> -
not possible on Windows; write access is required for registry & system
processes to run inside the container</li>
<li><code>securityContext.runAsGroup</code> -
not possible on Windows as there is no GID support</li>
<li><code>securityContext.runAsNonRoot</code> -
this setting will prevent containers from running as <code>ContainerAdministrator</code>
which is the closest equivalent to a root user on Windows.</li>
<li><code>securityContext.runAsUser</code> -
use <a href=/docs/tasks/configure-pod-container/configure-runasusername><code>runAsUserName</code></a>
instead</li>
<li><code>securityContext.seLinuxOptions</code> -
not possible on Windows as SELinux is Linux-specific</li>
<li><code>terminationMessagePath</code> -
this has some limitations in that Windows doesn't support mapping single files. The
default value is <code>/dev/termination-log</code>, which does work because it does not
exist on Windows by default.</li>
</ul>
<h5 id=compatibility-v1-pod>Field compatibility for Pod specifications</h5>
<p>The following list documents differences between how Pod specifications work between Windows and Linux:</p>
<ul>
<li><code>hostIPC</code> and <code>hostpid</code> - host namespace sharing is not possible on Windows</li>
<li><code>hostNetwork</code> - There is no Windows OS support to share the host network</li>
<li><code>dnsPolicy</code> - setting the Pod <code>dnsPolicy</code> to <code>ClusterFirstWithHostNet</code> is
not supported on Windows because host networking is not provided. Pods always
run with a container network.</li>
<li><code>podSecurityContext</code> (see below)</li>
<li><code>shareProcessNamespace</code> - this is a beta feature, and depends on Linux namespaces
which are not implemented on Windows. Windows cannot share process namespaces or
the container's root filesystem. Only the network can be shared.</li>
<li><code>terminationGracePeriodSeconds</code> - this is not fully implemented in Docker on Windows,
see the <a href=https://github.com/moby/moby/issues/25982>GitHub issue</a>.
The behavior today is that the ENTRYPOINT process is sent CTRL_SHUTDOWN_EVENT,
then Windows waits 5 seconds by default, and finally shuts down
all processes using the normal Windows shutdown behavior. The 5
second default is actually in the Windows registry
<a href=https://github.com/moby/moby/issues/25982#issuecomment-426441183>inside the container</a>,
so it can be overridden when the container is built.</li>
<li><code>volumeDevices</code> - this is a beta feature, and is not implemented on Windows.
Windows cannot attach raw block devices to pods.</li>
<li><code>volumes</code>
<ul>
<li>If you define an <code>emptyDir</code> volume, you cannot set its volume source to <code>memory</code>.</li>
</ul>
</li>
<li>You cannot enable <code>mountPropagation</code> for volume mounts as this is not
supported on Windows.</li>
</ul>
<h5 id=compatibility-v1-pod-spec-containers-securitycontext>Field compatibility for Pod security context</h5>
<p>None of the Pod <a href=/docs/reference/kubernetes-api/workload-resources/pod-v1/#security-context><code>securityContext</code></a> fields work on Windows.</p>
<h3 id=node-problem-detector>Node problem detector</h3>
<p>The node problem detector (see
<a href=/docs/tasks/debug/debug-cluster/monitor-node-health/>Monitor Node Health</a>)
is not compatible with Windows.</p>
<h3 id=pause-container>Pause container</h3>
<p>In a Kubernetes Pod, an infrastructure or “pause” container is first created
to host the container. In Linux, the cgroups and namespaces that make up a pod
need a process to maintain their continued existence; the pause process provides
this. Containers that belong to the same pod, including infrastructure and worker
containers, share a common network endpoint (same IPv4 and / or IPv6 address, same
network port spaces). Kubernetes uses pause containers to allow for worker containers
crashing or restarting without losing any of the networking configuration.</p>
<p>Kubernetes maintains a multi-architecture image that includes support for Windows.
For Kubernetes v1.23 the recommended pause image is <code>k8s.gcr.io/pause:3.6</code>.
The <a href=https://github.com/kubernetes/kubernetes/tree/master/build/pause>source code</a>
is available on GitHub.</p>
<p>Microsoft maintains a different multi-architecture image, with Linux and Windows
amd64 support, that you can find as <code>mcr.microsoft.com/oss/kubernetes/pause:3.6</code>.
This image is built from the same source as the Kubernetes maintained image but
all of the Windows binaries are <a href=https://docs.microsoft.com/en-us/windows-hardware/drivers/install/authenticode>authenticode signed</a> by Microsoft.
The Kubernetes project recommends using the Microsoft maintained image if you are
deploying to a production or production-like environment that requires signed
binaries.</p>
<h3 id=container-runtime>Container runtimes</h3>
<p>You need to install a
<a class=glossary-tooltip title="The container runtime is the software that is responsible for running containers." data-toggle=tooltip data-placement=top href=/docs/setup/production-environment/container-runtimes target=_blank aria-label="container runtime">container runtime</a>
into each node in the cluster so that Pods can run there.</p>
<p>The following container runtimes work with Windows:</p>
<div class="alert alert-secondary callout third-party-content" role=alert><strong>Note:</strong>
This section links to third party projects that provide functionality required by Kubernetes. The Kubernetes project authors aren't responsible for these projects, which are listed alphabetically. To add a project to this list, read the <a href=/docs/contribute/style/content-guide/#third-party-content>content guide</a> before submitting a change. <a href=#third-party-content-disclaimer>More information.</a></div>
<h4 id=cri-containerd>cri-containerd</h4>
<div style=margin-top:10px;margin-bottom:10px>
<b>FEATURE STATE:</b> <code>Kubernetes v1.20 [stable]</code>
</div>
<p>You can use <a class=glossary-tooltip title="A container runtime with an emphasis on simplicity, robustness and portability" data-toggle=tooltip data-placement=top href=https://containerd.io/docs/ target=_blank aria-label=ContainerD>ContainerD</a> 1.4.0+
as the container runtime for Kubernetes nodes that run Windows.</p>
<p>Learn how to <a href=/docs/setup/production-environment/container-runtimes/#install-containerd>install ContainerD on a Windows node</a>.</p>
<div class="alert alert-info note callout" role=alert>
<strong>Note:</strong> There is a <a href=/docs/tasks/configure-pod-container/configure-gmsa/#gmsa-limitations>known limitation</a>
when using GMSA with containerd to access Windows network shares, which requires a
kernel patch.
</div>
<h4 id=mcr>Mirantis Container Runtime</h4>
<p><a href=https://docs.mirantis.com/mcr/20.10/overview.html>Mirantis Container Runtime</a> (MCR) is available as a container runtime for all Windows Server 2019 and later versions.</p>
<p>See <a href=https://docs.mirantis.com/mcr/20.10/install/mcr-windows.html>Install MCR on Windows Servers</a> for more information.</p>
<h2 id=windows-os-version-support>Windows OS version compatibility</h2>
<p>On Windows nodes, strict compatibility rules apply where the host OS version must
match the container base image OS version. Only Windows containers with a container
operating system of Windows Server 2019 are fully supported.</p>
<p>For Kubernetes v1.23, operating system compatibility for Windows nodes (and Pods)
is as follows:</p>
<dl>
<dt>Windows Server LTSC release</dt>
<dd>Windows Server 2019</dd>
<dd>Windows Server 2022</dd>
<dt>Windows Server SAC release</dt>
<dd>Windows Server version 20H2</dd>
</dl>
<p>The Kubernetes <a href=/docs/setup/release/version-skew-policy/>version-skew policy</a> also applies.</p>
<h2 id=security>Security for Windows nodes</h2>
<p>On Windows, data from Secrets are written out in clear text onto the node's local
storage (as compared to using tmpfs / in-memory filesystems on Linux). As a cluster
operator, you should take both of the following additional measures:</p>
<ol>
<li>Use file ACLs to secure the Secrets' file location.</li>
<li>Apply volume-level encryption using <a href=https://docs.microsoft.com/en-us/windows/security/information-protection/bitlocker/bitlocker-how-to-deploy-on-windows-server>BitLocker</a>.</li>
</ol>
<p><a href=/docs/tasks/configure-pod-container/configure-runasusername>RunAsUsername</a>
can be specified for Windows Pods or containers to execute the container
processes as a node-default user. This is roughly equivalent to
<a href=/docs/concepts/security/pod-security-policy/#users-and-groups>RunAsUser</a>.</p>
<p>Linux-specific pod security context privileges such as SELinux, AppArmor, Seccomp, or capabilities (POSIX capabilities), and others are not supported.</p>
<p>Privileged containers are <a href=#compatibility-v1-pod-spec-containers-securitycontext>not supported</a> on Windows.</p>
<h2 id=troubleshooting>Getting help and troubleshooting</h2>
<p>Your main source of help for troubleshooting your Kubernetes cluster should start
with the <a href=/docs/tasks/debug/debug-cluster/>Troubleshooting</a>
page.</p>
<p>Some additional, Windows-specific troubleshooting help is included
in this section. Logs are an important element of troubleshooting
issues in Kubernetes. Make sure to include them any time you seek
troubleshooting assistance from other contributors. Follow the
instructions in the
SIG Windows <a href=https://github.com/kubernetes/community/blob/master/sig-windows/CONTRIBUTING.md#gathering-logs>contributing guide on gathering logs</a>.</p>
<h3 id=troubleshooting-node>Node-level troubleshooting</h3>
<ol>
<li>
<p>How do I know <code>start.ps1</code> completed successfully?</p>
<p>You should see kubelet, kube-proxy, and (if you chose Flannel as your networking
solution) flanneld host-agent processes running on your node, with running logs
being displayed in separate PowerShell windows. In addition to this, your Windows
node should be listed as "Ready" in your Kubernetes cluster.</p>
</li>
<li>
<p>Can I configure the Kubernetes node processes to run in the background as services?</p>
<p>The kubelet and kube-proxy are already configured to run as native Windows Services,
offering resiliency by re-starting the services automatically in the event of
failure (for example a process crash). You have two options for configuring these
node components as services.</p>
<ol>
<li>
<p>As native Windows Services</p>
<p>You can run the kubelet and kube-proxy as native Windows Services using <code>sc.exe</code>.</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-powershell data-lang=powershell><span style=color:#080;font-style:italic># Create the services for kubelet and kube-proxy in two separate commands</span>
sc.exe create &lt;component_name&gt; binPath= <span style=color:#b44>&#34;&lt;path_to_binary&gt; --service &lt;other_args&gt;&#34;</span>

<span style=color:#080;font-style:italic># Please note that if the arguments contain spaces, they must be escaped.</span>
sc.exe create kubelet binPath= <span style=color:#b44>&#34;C:\kubelet.exe --service --hostname-override &#39;minion&#39; &lt;other_args&gt;&#34;</span>

<span style=color:#080;font-style:italic># Start the services</span>
<span style=color:#a2f>Start-Service</span> kubelet
<span style=color:#a2f>Start-Service</span> <span style=color:#a2f>kube-proxy</span>

<span style=color:#080;font-style:italic># Stop the service</span>
<span style=color:#a2f>Stop-Service</span> kubelet (-Force)
<span style=color:#a2f>Stop-Service</span> <span style=color:#a2f>kube-proxy</span> (-Force)

<span style=color:#080;font-style:italic># Query the service status</span>
<span style=color:#a2f>Get-Service</span> kubelet
<span style=color:#a2f>Get-Service</span> <span style=color:#a2f>kube-proxy</span>
</code></pre></div></li>
<li>
<p>Using <code>nssm.exe</code></p>
<p>You can also always use alternative service managers like
<a href=https://nssm.cc/>nssm.exe</a> to run these processes (flanneld,
kubelet & kube-proxy) in the background for you. You can use this
<a href=https://github.com/Microsoft/SDN/tree/master/Kubernetes/flannel/register-svc.ps1>sample script</a>,
leveraging nssm.exe to register kubelet, kube-proxy, and flanneld.exe to run
as Windows services in the background.</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-powershell data-lang=powershell><span style=color:#a2f>register-svc</span>.ps1 -NetworkMode &lt;Network mode&gt; -ManagementIP &lt;Windows Node IP&gt; -ClusterCIDR &lt;Cluster subnet&gt; -KubeDnsServiceIP &lt;<span style=color:#a2f>Kube-dns</span> Service IP&gt; -LogDir &lt;Directory to place logs&gt;

<span style=color:#080;font-style:italic># NetworkMode      = The network mode l2bridge (flannel host-gw, also the default value) or overlay (flannel vxlan) chosen as a network solution</span>
<span style=color:#080;font-style:italic># ManagementIP     = The IP address assigned to the Windows node. You can use ipconfig to find this</span>
<span style=color:#080;font-style:italic># ClusterCIDR      = The cluster subnet range. (Default value 10.244.0.0/16)</span>
<span style=color:#080;font-style:italic># KubeDnsServiceIP = The Kubernetes DNS service IP (Default value 10.96.0.10)</span>
<span style=color:#080;font-style:italic># LogDir           = The directory where kubelet and kube-proxy logs are redirected into their respective output files (Default value C:\k)</span>
</code></pre></div><p>If the above referenced script is not suitable, you can manually configure
<code>nssm.exe</code> using the following examples.</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-powershell data-lang=powershell><span style=color:#080;font-style:italic># Register flanneld.exe</span>
nssm install flanneld C:\flannel\flanneld.exe
nssm <span style=color:#a2f>set </span>flanneld AppParameters --kubeconfig<span style=color:#666>-file</span>=c:\k\config --iface=&lt;ManagementIP&gt; --ip-masq=1 --kube-subnet-mgr=1
nssm <span style=color:#a2f>set </span>flanneld AppEnvironmentExtra NODE_NAME=&lt;hostname&gt;
nssm <span style=color:#a2f>set </span>flanneld AppDirectory C:\flannel
nssm <span style=color:#a2f>start </span>flanneld

<span style=color:#080;font-style:italic># Register kubelet.exe</span>
<span style=color:#080;font-style:italic># Microsoft releases the pause infrastructure container at mcr.microsoft.com/oss/kubernetes/pause:3.6</span>
nssm install kubelet C:\k\kubelet.exe
nssm <span style=color:#a2f>set </span>kubelet AppParameters --hostname-override=&lt;hostname&gt; --v=6 --pod-infra-container-image=mcr.microsoft.com/oss/kubernetes/pause<span>:</span>3.6 --resolv-conf=<span style=color:#b44>&#34;&#34;</span> --allow-privileged=true --enable-debugging-handlers --cluster-dns=&lt;<span style=color:#a2f>DNS-service</span>-IP&gt; --cluster-domain=cluster.local --kubeconfig=c:\k\config --hairpin-mode=<span style=color:#a2f>promiscuous-bridge</span> --image-pull-progress-deadline=20m --cgroups-per-qos=false  --log-dir=&lt;log directory&gt; --logtostderr=false --enforce-node-allocatable=<span style=color:#b44>&#34;&#34;</span> --network-plugin=cni --cni-bin-dir=c:\k\cni --cni-conf-dir=c:\k\cni\config
nssm <span style=color:#a2f>set </span>kubelet AppDirectory C:\k
nssm <span style=color:#a2f>start </span>kubelet

<span style=color:#080;font-style:italic># Register kube-proxy.exe (l2bridge / host-gw)</span>
nssm install <span style=color:#a2f>kube-proxy</span> C:\k\<span style=color:#a2f>kube-proxy</span>.exe
nssm <span style=color:#a2f>set kube-proxy</span> AppDirectory c:\k
nssm <span style=color:#a2f>set kube-proxy</span> AppParameters --v=4 --proxy-mode=kernelspace --hostname-override=&lt;hostname&gt;--kubeconfig=c:\k\config --enable-dsr=false --log-dir=&lt;log directory&gt; --logtostderr=false
nssm.exe <span style=color:#a2f>set kube-proxy</span> AppEnvironmentExtra KUBE_NETWORK=cbr0
nssm <span style=color:#a2f>set kube-proxy</span> DependOnService kubelet
nssm <span style=color:#a2f>start kube-proxy</span>

<span style=color:#080;font-style:italic># Register kube-proxy.exe (overlay / vxlan)</span>
nssm install <span style=color:#a2f>kube-proxy</span> C:\k\<span style=color:#a2f>kube-proxy</span>.exe
nssm <span style=color:#a2f>set kube-proxy</span> AppDirectory c:\k
nssm <span style=color:#a2f>set kube-proxy</span> AppParameters --v=4 --proxy-mode=kernelspace --feature-gates=<span style=color:#b44>&#34;WinOverlay=true&#34;</span> --hostname-override=&lt;hostname&gt; --kubeconfig=c:\k\config --network-name=vxlan0 --source-vip=&lt;<span style=color:#a2f>source-vip</span>&gt; --enable-dsr=false --log-dir=&lt;log directory&gt; --logtostderr=false
nssm <span style=color:#a2f>set kube-proxy</span> DependOnService kubelet
nssm <span style=color:#a2f>start kube-proxy</span>
</code></pre></div><p>For initial troubleshooting, you can use the following flags in <a href=https://nssm.cc/>nssm.exe</a> to redirect stdout and stderr to a output file:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-powershell data-lang=powershell>nssm <span style=color:#a2f>set </span>&lt;Service Name&gt; AppStdout C:\k\mysvc.log
nssm <span style=color:#a2f>set </span>&lt;Service Name&gt; AppStderr C:\k\mysvc.log
</code></pre></div><p>For additional details, see <a href=https://nssm.cc/usage>NSSM - the Non-Sucking Service Manager</a>.</p>
</li>
</ol>
</li>
<li>
<p>My Pods are stuck at "Container Creating" or restarting over and over</p>
<p>Check that your pause image is compatible with your OS version. The
<a href=https://docs.microsoft.com/en-us/virtualization/windowscontainers/kubernetes/deploying-resources>instructions</a>
assume that both the OS and the containers are version 1803. If you have a later
version of Windows, such as an Insider build, you need to adjust the images
accordingly. See <a href=#pause-container>Pause container</a> for more details.</p>
</li>
</ol>
<h3 id=troubleshooting-network>Network troubleshooting</h3>
<ol>
<li>
<p>My Windows Pods do not have network connectivity</p>
<p>If you are using virtual machines, ensure that MAC spoofing is <strong>enabled</strong> on all
the VM network adapter(s).</p>
</li>
<li>
<p>My Windows Pods cannot ping external resources</p>
<p>Windows Pods do not have outbound rules programmed for the ICMP protocol. However,
TCP/UDP is supported. When trying to demonstrate connectivity to resources
outside of the cluster, substitute <code>ping &lt;IP></code> with corresponding
<code>curl &lt;IP></code> commands.</p>
<p>If you are still facing problems, most likely your network configuration in
<a href=https://github.com/Microsoft/SDN/blob/master/Kubernetes/flannel/l2bridge/cni/config/cni.conf>cni.conf</a>
deserves some extra attention. You can always edit this static file. The
configuration update will apply to any new Kubernetes resources.</p>
<p>One of the Kubernetes networking requirements
(see <a href=/docs/concepts/cluster-administration/networking/>Kubernetes model</a>) is
for cluster communication to occur without
NAT internally. To honor this requirement, there is an
<a href=https://github.com/Microsoft/SDN/blob/master/Kubernetes/flannel/l2bridge/cni/config/cni.conf#L20>ExceptionList</a>
for all the communication where you do not want outbound NAT to occur. However,
this also means that you need to exclude the external IP you are trying to query
from the <code>ExceptionList</code>. Only then will the traffic originating from your Windows
pods be SNAT'ed correctly to receive a response from the outside world. In this
regard, your <code>ExceptionList</code> in <code>cni.conf</code> should look as follows:</p>
<pre><code class=language-conf data-lang=conf>&quot;ExceptionList&quot;: [
                &quot;10.244.0.0/16&quot;,  # Cluster subnet
                &quot;10.96.0.0/12&quot;,   # Service subnet
                &quot;10.127.130.0/24&quot; # Management (host) subnet
            ]
</code></pre></li>
<li>
<p>My Windows node cannot access <code>NodePort</code> type Services</p>
<p>Local NodePort access from the node itself fails. This is a known
limitation. NodePort access works from other nodes or external clients.</p>
</li>
<li>
<p>vNICs and HNS endpoints of containers are being deleted</p>
<p>This issue can be caused when the <code>hostname-override</code> parameter is not passed to
<a href=/docs/reference/command-line-tools-reference/kube-proxy/>kube-proxy</a>. To resolve
it, users need to pass the hostname to kube-proxy as follows:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-powershell data-lang=powershell>C:\k\<span style=color:#a2f>kube-proxy</span>.exe --hostname-override=$(hostname)
</code></pre></div></li>
<li>
<p>With flannel, my nodes are having issues after rejoining a cluster</p>
<p>Whenever a previously deleted node is being re-joined to the cluster, flannelD
tries to assign a new pod subnet to the node. Users should remove the old pod
subnet configuration files in the following paths:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-powershell data-lang=powershell><span style=color:#a2f>Remove-Item</span> C:\k\SourceVip.json
<span style=color:#a2f>Remove-Item</span> C:\k\SourceVipRequest.json
</code></pre></div></li>
<li>
<p>After launching <code>start.ps1</code>, flanneld is stuck in "Waiting for the Network to be created"</p>
<p>There are numerous reports of this <a href=https://github.com/coreos/flannel/issues/1066>issue</a>; most likely it is a timing issue for when the management IP of the flannel network is set. A workaround is to relaunch <code>start.ps1</code> or relaunch it manually as follows:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-powershell data-lang=powershell><span style=color:#800>[Environment]</span>::SetEnvironmentVariable(<span style=color:#b44>&#34;NODE_NAME&#34;</span>, <span style=color:#b44>&#34;&lt;Windows_Worker_Hostname&gt;&#34;</span>)
C:\flannel\flanneld.exe --kubeconfig<span style=color:#666>-file</span>=c:\k\config --iface=&lt;Windows_Worker_Node_IP&gt; --ip-masq=1 --kube-subnet-mgr=1
</code></pre></div></li>
<li>
<p>My Windows Pods cannot launch because of missing <code>/run/flannel/subnet.env</code></p>
<p>This indicates that Flannel didn't launch correctly. You can either try
to restart <code>flanneld.exe</code> or you can copy the files over manually from
<code>/run/flannel/subnet.env</code> on the Kubernetes master to <code>C:\run\flannel\subnet.env</code>
on the Windows worker node and modify the <code>FLANNEL_SUBNET</code> row to a different
number. For example, if node subnet 10.244.4.1/24 is desired:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-env data-lang=env><span style=color:#b8860b>FLANNEL_NETWORK</span><span style=color:#666>=</span>10.244.0.0/16
<span style=color:#b8860b>FLANNEL_SUBNET</span><span style=color:#666>=</span>10.244.4.1/24
<span style=color:#b8860b>FLANNEL_MTU</span><span style=color:#666>=</span><span style=color:#666>1500</span>
<span style=color:#b8860b>FLANNEL_IPMASQ</span><span style=color:#666>=</span><span style=color:#a2f>true</span>
</code></pre></div></li>
<li>
<p>My Windows node cannot access my services using the service IP</p>
<p>This is a known limitation of the networking stack on Windows. However, Windows Pods can access the Service IP.</p>
</li>
<li>
<p>No network adapter is found when starting the kubelet</p>
<p>The Windows networking stack needs a virtual adapter for Kubernetes networking to work. If the following commands return no results (in an admin shell), virtual network creation — a necessary prerequisite for the kubelet to work — has failed:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-powershell data-lang=powershell><span style=color:#a2f>Get-HnsNetwork</span> | ? Name <span style=color:#666>-ieq</span> <span style=color:#b44>&#34;cbr0&#34;</span>
<span style=color:#a2f>Get-NetAdapter</span> | ? Name <span style=color:#666>-Like</span> <span style=color:#b44>&#34;vEthernet (Ethernet*&#34;</span>
</code></pre></div><p>Often it is worthwhile to modify the <a href=https://github.com/microsoft/SDN/blob/master/Kubernetes/flannel/start.ps1#L7>InterfaceName</a> parameter of the start.ps1 script, in cases where the host's network adapter isn't "Ethernet". Otherwise, consult the output of the <code>start-kubelet.ps1</code> script to see if there are errors during virtual network creation.</p>
</li>
<li>
<p>DNS resolution is not properly working</p>
<p>Check the DNS limitations for Windows in this <a href=#dns-limitations>section</a>.</p>
</li>
<li>
<p><code>kubectl port-forward</code> fails with "unable to do port forwarding: wincat not found"</p>
<p>This was implemented in Kubernetes 1.15 by including <code>wincat.exe</code> in the pause infrastructure container <code>mcr.microsoft.com/oss/kubernetes/pause:3.6</code>. Be sure to use a supported version of Kubernetes.
If you would like to build your own pause infrastructure container be sure to include <a href=https://github.com/kubernetes/kubernetes/tree/master/build/pause/windows/wincat>wincat</a>.</p>
</li>
<li>
<p>My Kubernetes installation is failing because my Windows Server node is behind a proxy</p>
<p>If you are behind a proxy, the following PowerShell environment variables must be defined:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-PowerShell data-lang=PowerShell><span style=color:#800>[Environment]</span>::SetEnvironmentVariable(<span style=color:#b44>&#34;HTTP_PROXY&#34;</span>, <span style=color:#b44>&#34;http://proxy.example.com:80/&#34;</span>, <span style=color:#800>[EnvironmentVariableTarget]</span>::Machine)
<span style=color:#800>[Environment]</span>::SetEnvironmentVariable(<span style=color:#b44>&#34;HTTPS_PROXY&#34;</span>, <span style=color:#b44>&#34;http://proxy.example.com:443/&#34;</span>, <span style=color:#800>[EnvironmentVariableTarget]</span>::Machine)
</code></pre></div></li>
</ol>
<h3 id=further-investigation>Further investigation</h3>
<p>If these steps don't resolve your problem, you can get help running Windows containers on Windows nodes in Kubernetes through:</p>
<ul>
<li>StackOverflow <a href=https://stackoverflow.com/questions/tagged/windows-server-container>Windows Server Container</a> topic</li>
<li>Kubernetes Official Forum <a href=https://discuss.kubernetes.io/>discuss.kubernetes.io</a></li>
<li>Kubernetes Slack <a href=https://kubernetes.slack.com/messages/sig-windows>#SIG-Windows Channel</a></li>
</ul>
<h3 id=reporting-issues-and-feature-requests>Reporting issues and feature requests</h3>
<p>If you have what looks like a bug, or you would like to
make a feature request, please use the
<a href=https://github.com/kubernetes/kubernetes/issues>GitHub issue tracking system</a>.
You can open issues on
<a href=https://github.com/kubernetes/kubernetes/issues/new/choose>GitHub</a> and assign
them to SIG-Windows. You should first search the list of issues in case it was
reported previously and comment with your experience on the issue and add additional
logs. SIG-Windows Slack is also a great avenue to get some initial support and
troubleshooting ideas prior to creating a ticket.</p>
<p>If filing a bug, please include detailed information about how to reproduce the problem, such as:</p>
<ul>
<li>Kubernetes version: output from <code>kubectl version</code></li>
<li>Environment details: Cloud provider, OS distro, networking choice and configuration, and Docker version</li>
<li>Detailed steps to reproduce the problem</li>
<li><a href=https://github.com/kubernetes/community/blob/master/sig-windows/CONTRIBUTING.md#gathering-logs>Relevant logs</a></li>
</ul>
<p>It helps if you tag the issue as <strong>sig/windows</strong>, by commenting on the issue with <code>/sig windows</code>. This helps to bring
the issue to a SIG Windows member's attention</p>
<h2 id=what-s-next>What's next</h2>
<h3 id=deployment-tools>Deployment tools</h3>
<p>The kubeadm tool helps you to deploy a Kubernetes cluster, providing the control
plane to manage the cluster it, and nodes to run your workloads.
<a href=/docs/tasks/administer-cluster/kubeadm/adding-windows-nodes/>Adding Windows nodes</a>
explains how to deploy Windows nodes to your cluster using kubeadm.</p>
<p>The Kubernetes <a href=https://cluster-api.sigs.k8s.io/>cluster API</a> project also provides means to automate deployment of Windows nodes.</p>
<h3 id=windows-distribution-channels>Windows distribution channels</h3>
<p>For a detailed explanation of Windows distribution channels see the <a href=https://docs.microsoft.com/en-us/windows-server/get-started-19/servicing-channels-19>Microsoft documentation</a>.</p>
<p>Information on the different Windows Server servicing channels
including their support models can be found at
<a href=https://docs.microsoft.com/en-us/windows-server/get-started/servicing-channels-comparison>Windows Server servicing channels</a>.</p>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-3a51e66c5de55f9093a8dc55742006d3>2 - Guide for scheduling Windows containers in Kubernetes</h1>
<p>Windows applications constitute a large portion of the services and applications that run in many organizations.
This guide walks you through the steps to configure and deploy a Windows container in Kubernetes.</p>
<h2 id=objectives>Objectives</h2>
<ul>
<li>Configure an example deployment to run Windows containers on the Windows node</li>
<li>(Optional) Configure an Active Directory Identity for your Pod using Group Managed Service Accounts (GMSA)</li>
</ul>
<h2 id=before-you-begin>Before you begin</h2>
<ul>
<li>Create a Kubernetes cluster that includes a
control plane and a <a href=/docs/tasks/administer-cluster/kubeadm/adding-windows-nodes/>worker node running Windows Server</a></li>
<li>It is important to note that creating and deploying services and workloads on Kubernetes
behaves in much the same way for Linux and Windows containers.
<a href=/docs/reference/kubectl/>Kubectl commands</a> to interface with the cluster are identical.
The example in the section below is provided to jumpstart your experience with Windows containers.</li>
</ul>
<h2 id=getting-started-deploying-a-windows-container>Getting Started: Deploying a Windows container</h2>
<p>To deploy a Windows container on Kubernetes, you must first create an example application.
The example YAML file below creates a simple webserver application.
Create a service spec named <code>win-webserver.yaml</code> with the contents below:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>win-webserver<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>win-webserver<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:#080;font-style:italic># the port that this service should serve on</span><span style=color:#bbb>
</span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>win-webserver<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>NodePort<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Deployment<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>win-webserver<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>win-webserver<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>2</span><span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>win-webserver<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>win-webserver<span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>win-webserver<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span><span style=color:#bbb>     </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>windowswebserver<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>mcr.microsoft.com/windows/servercore:ltsc2019<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb>
</span><span style=color:#bbb>        </span>- powershell.exe<span style=color:#bbb>
</span><span style=color:#bbb>        </span>- -command<span style=color:#bbb>
</span><span style=color:#bbb>        </span>- <span style=color:#b44>&#34;&lt;#code used from https://gist.github.com/19WAS85/5424431#&gt; ; $$listener = New-Object System.Net.HttpListener ; $$listener.Prefixes.Add(&#39;http://*:80/&#39;) ; $$listener.Start() ; $$callerCounts = @{} ; Write-Host(&#39;Listening at http://*:80/&#39;) ; while ($$listener.IsListening) { ;$$context = $$listener.GetContext() ;$$requestUrl = $$context.Request.Url ;$$clientIP = $$context.Request.RemoteEndPoint.Address ;$$response = $$context.Response ;Write-Host &#39;&#39; ;Write-Host(&#39;&gt; {0}&#39; -f $$requestUrl) ;  ;$$count = 1 ;$$k=$$callerCounts.Get_Item($$clientIP) ;if ($$k -ne $$null) { $$count += $$k } ;$$callerCounts.Set_Item($$clientIP, $$count) ;$$ip=(Get-NetAdapter | Get-NetIpAddress); $$header=&#39;&lt;html&gt;&lt;body&gt;&lt;H1&gt;Windows Container Web Server&lt;/H1&gt;&#39; ;$$callerCountsString=&#39;&#39; ;$$callerCounts.Keys | % { $$callerCountsString+=&#39;&lt;p&gt;IP {0} callerCount {1} &#39; -f $$ip[1].IPAddress,$$callerCounts.Item($$_) } ;$$footer=&#39;&lt;/body&gt;&lt;/html&gt;&#39; ;$$content=&#39;{0}{1}{2}&#39; -f $$header,$$callerCountsString,$$footer ;Write-Output $$content ;$$buffer = [System.Text.Encoding]::UTF8.GetBytes($$content) ;$$response.ContentLength64 = $$buffer.Length ;$$response.OutputStream.Write($$buffer, 0, $$buffer.Length) ;$$response.Close() ;$$responseStatus = $$response.StatusCode ;Write-Host(&#39;&lt; {0}&#39; -f $$responseStatus)  } ; &#34;</span><span style=color:#bbb>
</span><span style=color:#bbb>     </span><span style=color:green;font-weight:700>nodeSelector</span>:<span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>kubernetes.io/os</span>:<span style=color:#bbb> </span>windows<span style=color:#bbb>
</span></code></pre></div><div class="alert alert-info note callout" role=alert>
<strong>Note:</strong> Port mapping is also supported, but for simplicity in this example
the container port 80 is exposed directly to the service.
</div>
<ol>
<li>
<p>Check that all nodes are healthy:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>kubectl get nodes
</code></pre></div></li>
<li>
<p>Deploy the service and watch for pod updates:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>kubectl apply -f win-webserver.yaml
kubectl get pods -o wide -w
</code></pre></div><p>When the service is deployed correctly both Pods are marked as Ready. To exit the watch command, press Ctrl+C.</p>
</li>
<li>
<p>Check that the deployment succeeded. To verify:</p>
<ul>
<li>Two containers per pod on the Windows node, use <code>docker ps</code></li>
<li>Two pods listed from the Linux control plane node, use <code>kubectl get pods</code></li>
<li>Node-to-pod communication across the network, <code>curl</code> port 80 of your pod IPs from the Linux control plane node
to check for a web server response</li>
<li>Pod-to-pod communication, ping between pods (and across hosts, if you have more than one Windows node)
using docker exec or kubectl exec</li>
<li>Service-to-pod communication, <code>curl</code> the virtual service IP (seen under <code>kubectl get services</code>)
from the Linux control plane node and from individual pods</li>
<li>Service discovery, <code>curl</code> the service name with the Kubernetes <a href=/docs/concepts/services-networking/dns-pod-service/#services>default DNS suffix</a></li>
<li>Inbound connectivity, <code>curl</code> the NodePort from the Linux control plane node or machines outside of the cluster</li>
<li>Outbound connectivity, <code>curl</code> external IPs from inside the pod using kubectl exec</li>
</ul>
</li>
</ol>
<div class="alert alert-info note callout" role=alert>
<strong>Note:</strong> Windows container hosts are not able to access the IP of services scheduled on them due to current platform limitations of the Windows networking stack.
Only Windows pods are able to access service IPs.
</div>
<h2 id=observability>Observability</h2>
<h3 id=capturing-logs-from-workloads>Capturing logs from workloads</h3>
<p>Logs are an important element of observability; they enable users to gain insights
into the operational aspect of workloads and are a key ingredient to troubleshooting issues.
Because Windows containers and workloads inside Windows containers behave differently from Linux containers,
users had a hard time collecting logs, limiting operational visibility.
Windows workloads for example are usually configured to log to ETW (Event Tracing for Windows)
or push entries to the application event log.
<a href=https://github.com/microsoft/windows-container-tools/tree/master/LogMonitor>LogMonitor</a>, an open source tool by Microsoft,
is the recommended way to monitor configured log sources inside a Windows container.
LogMonitor supports monitoring event logs, ETW providers, and custom application logs,
piping them to STDOUT for consumption by <code>kubectl logs &lt;pod></code>.</p>
<p>Follow the instructions in the LogMonitor GitHub page to copy its binaries and configuration files
to all your containers and add the necessary entrypoints for LogMonitor to push your logs to STDOUT.</p>
<h2 id=using-configurable-container-usernames>Using configurable Container usernames</h2>
<p>Starting with Kubernetes v1.16, Windows containers can be configured to run their entrypoints and processes
with different usernames than the image defaults.
The way this is achieved is a bit different from the way it is done for Linux containers.
Learn more about it <a href=/docs/tasks/configure-pod-container/configure-runasusername/>here</a>.</p>
<h2 id=managing-workload-identity-with-group-managed-service-accounts>Managing Workload Identity with Group Managed Service Accounts</h2>
<p>Starting with Kubernetes v1.14, Windows container workloads can be configured to use Group Managed Service Accounts (GMSA).
Group Managed Service Accounts are a specific type of Active Directory account that provides automatic password management,
simplified service principal name (SPN) management, and the ability to delegate the management to other administrators across multiple servers.
Containers configured with a GMSA can access external Active Directory Domain resources while carrying the identity configured with the GMSA.
Learn more about configuring and using GMSA for Windows containers <a href=/docs/tasks/configure-pod-container/configure-gmsa/>here</a>.</p>
<h2 id=taints-and-tolerations>Taints and Tolerations</h2>
<p>Users today need to use some combination of taints and node selectors in order to
keep Linux and Windows workloads on their respective OS-specific nodes.
This likely imposes a burden only on Windows users. The recommended approach is outlined below,
with one of its main goals being that this approach should not break compatibility for existing Linux workloads.
<div class="alert alert-info note callout" role=alert>
<strong>Note:</strong> <p>If the <code>IdentifyPodOS</code> <a href=/docs/reference/command-line-tools-reference/feature-gates/>feature gate</a> is
enabled, you can (and should) set <code>.spec.os.name</code> for a Pod to indicate the operating system
that the containers in that Pod are designed for. For Pods that run Linux containers, set
<code>.spec.os.name</code> to <code>linux</code>. For Pods that run Windows containers, set <code>.spec.os.name</code>
to Windows.</p>
<p>The scheduler does not use the value of <code>.spec.os.name</code> when assigning Pods to nodes. You should
use normal Kubernetes mechanisms for
<a href=/docs/concepts/scheduling-eviction/assign-pod-node/>assigning pods to nodes</a>
to ensure that the control plane for your cluster places pods onto nodes that are running the
appropriate operating system.
no effect on the scheduling of the Windows pods, so taints and tolerations and node selectors are still required
to ensure that the Windows pods land onto appropriate Windows nodes.</p>
</div></p>
<h3 id=ensuring-os-specific-workloads-land-on-the-appropriate-container-host>Ensuring OS-specific workloads land on the appropriate container host</h3>
<p>Users can ensure Windows containers can be scheduled on the appropriate host using Taints and Tolerations.
All Kubernetes nodes today have the following default labels:</p>
<ul>
<li>kubernetes.io/os = [windows|linux]</li>
<li>kubernetes.io/arch = [amd64|arm64|...]</li>
</ul>
<p>If a Pod specification does not specify a nodeSelector like <code>"kubernetes.io/os": windows</code>,
it is possible the Pod can be scheduled on any host, Windows or Linux.
This can be problematic since a Windows container can only run on Windows and a Linux container can only run on Linux.
The best practice is to use a nodeSelector.</p>
<p>However, we understand that in many cases users have a pre-existing large number of deployments for Linux containers,
as well as an ecosystem of off-the-shelf configurations, such as community Helm charts, and programmatic Pod generation cases, such as with Operators.
In those situations, you may be hesitant to make the configuration change to add nodeSelectors.
The alternative is to use Taints. Because the kubelet can set Taints during registration,
it could easily be modified to automatically add a taint when running on Windows only.</p>
<p>For example: <code>--register-with-taints='os=windows:NoSchedule'</code></p>
<p>By adding a taint to all Windows nodes, nothing will be scheduled on them (that includes existing Linux Pods).
In order for a Windows Pod to be scheduled on a Windows node,
it would need both the nodeSelector and the appropriate matching toleration to choose Windows.</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:green;font-weight:700>nodeSelector</span>:<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>kubernetes.io/os</span>:<span style=color:#bbb> </span>windows<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>node.kubernetes.io/windows-build</span>:<span style=color:#bbb> </span><span style=color:#b44>&#39;10.0.17763&#39;</span><span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>tolerations</span>:<span style=color:#bbb>
</span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;os&#34;</span><span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;Equal&#34;</span><span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;windows&#34;</span><span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>effect</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;NoSchedule&#34;</span><span style=color:#bbb>
</span></code></pre></div><h3 id=handling-multiple-windows-versions-in-the-same-cluster>Handling multiple Windows versions in the same cluster</h3>
<p>The Windows Server version used by each pod must match that of the node. If you want to use multiple Windows
Server versions in the same cluster, then you should set additional node labels and nodeSelectors.</p>
<p>Kubernetes 1.17 automatically adds a new label <code>node.kubernetes.io/windows-build</code> to simplify this.
If you're running an older version, then it's recommended to add this label manually to Windows nodes.</p>
<p>This label reflects the Windows major, minor, and build number that need to match for compatibility.
Here are values used today for each Windows Server version.</p>
<table>
<thead>
<tr>
<th>Product Name</th>
<th>Build Number(s)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Windows Server 2019</td>
<td>10.0.17763</td>
</tr>
<tr>
<td>Windows Server version 1809</td>
<td>10.0.17763</td>
</tr>
<tr>
<td>Windows Server version 1903</td>
<td>10.0.18362</td>
</tr>
</tbody>
</table>
<h3 id=simplifying-with-runtimeclass>Simplifying with RuntimeClass</h3>
<p><a href=https://kubernetes.io/docs/concepts/containers/runtime-class/>RuntimeClass</a> can be used to simplify the process of using taints and tolerations.
A cluster administrator can create a <code>RuntimeClass</code> object which is used to encapsulate these taints and tolerations.</p>
<ol>
<li>Save this file to <code>runtimeClasses.yml</code>. It includes the appropriate <code>nodeSelector</code>
for the Windows OS, architecture, and version.</li>
</ol>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>node.k8s.io/v1<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>RuntimeClass<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>windows-2019<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>handler</span>:<span style=color:#bbb> </span><span style=color:#b44>&#39;docker&#39;</span><span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>scheduling</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>nodeSelector</span>:<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>kubernetes.io/os</span>:<span style=color:#bbb> </span><span style=color:#b44>&#39;windows&#39;</span><span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>kubernetes.io/arch</span>:<span style=color:#bbb> </span><span style=color:#b44>&#39;amd64&#39;</span><span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>node.kubernetes.io/windows-build</span>:<span style=color:#bbb> </span><span style=color:#b44>&#39;10.0.17763&#39;</span><span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>tolerations</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>effect</span>:<span style=color:#bbb> </span>NoSchedule<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>os<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>Equal<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;windows&#34;</span><span style=color:#bbb>
</span></code></pre></div><ol>
<li>Run <code>kubectl create -f runtimeClasses.yml</code> using as a cluster administrator</li>
<li>Add <code>runtimeClassName: windows-2019</code> as appropriate to Pod specs</li>
</ol>
<p>For example:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Deployment<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>iis-2019<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>iis-2019<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>iis-2019<span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>iis-2019<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>runtimeClassName</span>:<span style=color:#bbb> </span>windows-2019<span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>iis<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>mcr.microsoft.com/windows/servercore/iis:windowsservercore-ltsc2019<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>800Mi<span style=color:#bbb>
</span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span>.1<span style=color:#bbb>
</span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>300Mi<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span><span style=color:#bbb> </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>iis-2019<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>iis<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>LoadBalancer<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>iis-2019<span style=color:#bbb>
</span></code></pre></div>
</div>
</main>
</div>
</div>
<footer class=d-print-none>
<div class=footer__links>
<nav>
<a class=text-white href=/docs/home/>Home</a>
<a class=text-white href=/blog/>Blog</a>
<a class=text-white href=/training/>Training</a>
<a class=text-white href=/partners/>Partners</a>
<a class=text-white href=/community/>Community</a>
<a class=text-white href=/case-studies/>Case Studies</a>
</nav>
</div>
<div class=container-fluid>
<div class=row>
<div class="col-6 col-sm-2 text-xs-center order-sm-2">
<ul class="list-inline mb-0">
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="User mailing list" aria-label="User mailing list">
<a class=text-white target=_blank href=https://discuss.kubernetes.io>
<i class="fa fa-envelope"></i>
</a>
</li>
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Twitter aria-label=Twitter>
<a class=text-white target=_blank href=https://twitter.com/kubernetesio>
<i class="fab fa-twitter"></i>
</a>
</li>
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Calendar aria-label=Calendar>
<a class=text-white target=_blank href="https://calendar.google.com/calendar/embed?src=calendar%40kubernetes.io">
<i class="fas fa-calendar-alt"></i>
</a>
</li>
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Youtube aria-label=Youtube>
<a class=text-white target=_blank href=https://youtube.com/kubernetescommunity>
<i class="fab fa-youtube"></i>
</a>
</li>
</ul>
</div>
<div class="col-6 col-sm-2 text-right text-xs-center order-sm-3">
<ul class="list-inline mb-0">
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub>
<a class=text-white target=_blank href=https://github.com/kubernetes/kubernetes>
<i class="fab fa-github"></i>
</a>
</li>
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Slack aria-label=Slack>
<a class=text-white target=_blank href=https://slack.k8s.io>
<i class="fab fa-slack"></i>
</a>
</li>
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Contribute aria-label=Contribute>
<a class=text-white target=_blank href=https://git.k8s.io/community/contributors/guide>
<i class="fas fa-edit"></i>
</a>
</li>
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="Stack Overflow" aria-label="Stack Overflow">
<a class=text-white target=_blank href=https://stackoverflow.com/questions/tagged/kubernetes>
<i class="fab fa-stack-overflow"></i>
</a>
</li>
</ul>
</div>
<div class="col-12 col-sm-8 text-center order-sm-2">
<small class=text-white>&copy; 2023 The Kubernetes Authors | Documentation Distributed under <a href=https://git.k8s.io/website/LICENSE class=light-text>CC BY 4.0</a></small>
<br>
<small class=text-white>Copyright &copy; 2023 The Linux Foundation &reg;. All rights reserved. The Linux Foundation has registered trademarks and uses trademarks. For a list of trademarks of The Linux Foundation, please see our <a href=https://www.linuxfoundation.org/trademark-usage class=light-text>Trademark Usage page</a></small>
<br>
<small class=text-white>ICP license: 京ICP备17074266号-3</small>
</div>
</div>
</div>
</footer>
</div>
<script src=/js/popper-1.14.3.min.js integrity=sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49 crossorigin=anonymous></script>
<script src=/js/bootstrap-4.3.1.min.js integrity=sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM crossorigin=anonymous></script>
<script src=/js/main.min.40616251a9b6e4b689e7769be0340661efa4d7ebb73f957404e963e135b4ed52.js integrity="sha256-QGFiUam25LaJ53ab4DQGYe+k1+u3P5V0BOlj4TW07VI=" crossorigin=anonymous></script>
</body>
</html>