<!doctype html><html lang=ko class=no-js>
<head>
<meta name=ROBOTS content="NOINDEX, NOFOLLOW">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-JPP6RFM2BP"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date),gtag('config','G-JPP6RFM2BP')</script>
<link rel=alternate hreflang=en href=https://kubernetes.io/docs/setup/best-practices/>
<link rel=alternate hreflang=zh href=https://kubernetes.io/zh/docs/setup/best-practices/>
<link rel=alternate hreflang=ja href=https://kubernetes.io/ja/docs/setup/best-practices/>
<link rel=alternate hreflang=id href=https://kubernetes.io/id/docs/setup/best-practices/>
<link rel=alternate hreflang=uk href=https://kubernetes.io/uk/docs/setup/best-practices/>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=generator content="Hugo 0.87.0">
<link rel=canonical type=text/html href=https://kubernetes.io/ko/docs/setup/best-practices/>
<link rel="shortcut icon" type=image/png href=/images/favicon.png>
<link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180>
<link rel=manifest href=/manifest.webmanifest>
<link rel=apple-touch-icon href=/images/kubernetes-192x192.png>
<title>모범 사례 | Kubernetes</title><meta property="og:title" content="모범 사례">
<meta property="og:description" content="운영 수준의 컨테이너 오케스트레이션">
<meta property="og:type" content="website">
<meta property="og:url" content="https://kubernetes.io/ko/docs/setup/best-practices/"><meta property="og:site_name" content="Kubernetes">
<meta itemprop=name content="모범 사례">
<meta itemprop=description content="운영 수준의 컨테이너 오케스트레이션"><meta name=twitter:card content="summary">
<meta name=twitter:title content="모범 사례">
<meta name=twitter:description content="운영 수준의 컨테이너 오케스트레이션">
<link href=/scss/main.css rel=stylesheet>
<script src=/js/jquery-3.3.1.min.js integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin=anonymous></script>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","url":"https://kubernetes.io","logo":"https://kubernetes.io/images/favicon.png"}</script>
<meta name=theme-color content="#326ce5">
<link rel=stylesheet href=/css/feature-states.css>
<meta name=description content>
<meta property="og:description" content>
<meta name=twitter:description content>
<meta property="og:url" content="https://kubernetes.io/ko/docs/setup/best-practices/">
<meta property="og:title" content="모범 사례">
<meta name=twitter:title content="모범 사례">
<meta name=twitter:image content="https://kubernetes.io/images/favicon.png">
<meta name=twitter:image:alt content="Kubernetes">
<meta property="og:image" content="/images/kubernetes-horizontal-color.png">
<meta property="og:type" content="article">
<script src=/js/script.js></script>
</head>
<body class=td-section>
<header>
<nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar" data-auto-burger=primary>
<a class=navbar-brand href=/ko/></a>
<div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar>
<ul class="navbar-nav mt-2 mt-lg-0">
<li class="nav-item mr-2 mb-lg-0">
<a class="nav-link active" href=/ko/docs/>문서</a>
</li>
<li class="nav-item mr-2 mb-lg-0">
<a class=nav-link href=/ko/blog/>쿠버네티스 블로그</a>
</li>
<li class="nav-item mr-2 mb-lg-0">
<a class=nav-link href=/ko/training/>교육</a>
</li>
<li class="nav-item mr-2 mb-lg-0">
<a class=nav-link href=/ko/partners/>파트너</a>
</li>
<li class="nav-item mr-2 mb-lg-0">
<a class=nav-link href=/ko/community/>커뮤니티</a>
</li>
<li class="nav-item mr-2 mb-lg-0">
<a class=nav-link href=/ko/case-studies/>사례 연구</a>
</li>
<li class="nav-item dropdown">
<a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>
버전
</a>
<div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink>
<a class=dropdown-item href=/releases>Release Information</a>
<a class=dropdown-item href=https://kubernetes.io/ko/docs/setup/best-practices/>v1.27</a>
<a class=dropdown-item href=https://v1-26.docs.kubernetes.io/ko/docs/setup/best-practices/>v1.26</a>
<a class=dropdown-item href=https://v1-25.docs.kubernetes.io/ko/docs/setup/best-practices/>v1.25</a>
<a class=dropdown-item href=https://v1-24.docs.kubernetes.io/ko/docs/setup/best-practices/>v1.24</a>
<a class=dropdown-item href=https://v1-23.docs.kubernetes.io/ko/docs/setup/best-practices/>v1.23</a>
</div>
</li>
<li class="nav-item dropdown">
<a class="nav-link dropdown-toggle" href=# id=navbarDropdownMenuLink role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>
한국어 Korean
</a>
<div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink>
<a class=dropdown-item href=/docs/setup/best-practices/>English</a>
<a class=dropdown-item href=/zh/docs/setup/best-practices/>中文 Chinese</a>
<a class=dropdown-item href=/ja/docs/setup/best-practices/>日本語 Japanese</a>
<a class=dropdown-item href=/id/docs/setup/best-practices/>Bahasa Indonesia</a>
<a class=dropdown-item href=/uk/docs/setup/best-practices/>Українська</a>
</div>
</li>
</ul>
</div>
<button id=hamburger onclick=kub.toggleMenu() data-auto-burger-exclude><div></div></button>
</nav>
</header>
<div class="container-fluid td-outer">
<div class=td-main>
<div class="row flex-xl-nowrap">
<main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main>
<div class=td-content>
<div class="pageinfo pageinfo-primary d-print-none">
<p>
이 섹션의 다중 페이지 출력 화면임.
<a href=# onclick="return print(),!1">여기를 클릭하여 프린트</a>.
</p><p>
<a href=/ko/docs/setup/best-practices/>이 페이지의 일반 화면으로 돌아가기</a>.
</p>
</div>
<h1 class=title>모범 사례</h1>
<ul>
<li>1: <a href=#pg-c797ee17120176c685455db89ae091a9>대형 클러스터에 대한 고려 사항</a></li>
<li>2: <a href=#pg-970615c97499e3651fd3a98e0387cefc>여러 영역에서 실행</a></li>
<li>3: <a href=#pg-f89867de1d34943f1524f67a241f5cc9>노드 구성 검증하기</a></li>
<li>4: <a href=#pg-0394f813094b7a35058dffe5b8bacd20>PKI 인증서 및 요구 사항</a></li>
</ul>
<div class=content>
</div>
</div>
<div class=td-content>
<h1 id=pg-c797ee17120176c685455db89ae091a9>1 - 대형 클러스터에 대한 고려 사항</h1>
<p>클러스터는 <a class=glossary-tooltip title="컨테이너의 라이프사이클을 정의, 배포, 관리하기 위한 API와 인터페이스들을 노출하는 컨테이너 오케스트레이션 레이어." data-toggle=tooltip data-placement=top href="/ko/docs/reference/glossary/?all=true#term-control-plane" target=_blank aria-label="컨트롤 플레인">컨트롤 플레인</a>에서 관리하는
쿠버네티스 에이전트를 실행하는 <a class=glossary-tooltip title="노드는 쿠버네티스의 작업 장비(worker machine)이다." data-toggle=tooltip data-placement=top href=/ko/docs/concepts/architecture/nodes/ target=_blank aria-label=노드>노드</a>(물리
또는 가상 머신)의 집합이다.
쿠버네티스 v1.23는 노드 5,000개까지의 클러스터를 지원한다. 보다 정확하게는,
쿠버네티스는 다음 기준을 <em>모두</em> 만족하는 설정을 수용하도록 설계되었다.</p>
<ul>
<li>노드 당 파드 110 개 이하</li>
<li>노드 5,000개 이하</li>
<li>전체 파드 150,000개 이하</li>
<li>전체 컨테이너 300,000개 이하</li>
</ul>
<p>노드를 추가하거나 제거하여 클러스터를 확장할 수 있다. 이를 수행하는 방법은
클러스터 배포 방법에 따라 다르다.</p>
<h2 id=quota-issues>클라우드 프로바이더 리소스 쿼터</h2>
<p>여러 노드를 가지는 클러스터를 만들 때, 클라우드 프로바이더 쿼터 이슈를 피하기 위해
고려할 점은 다음과 같다.</p>
<ul>
<li>다음과 같은 클라우드 리소스에 대한 쿼터 증가를 요청한다.
<ul>
<li>컴퓨터 인스턴스</li>
<li>CPU</li>
<li>스토리지 볼륨</li>
<li>사용 중인 IP 주소</li>
<li>패킷 필터링 규칙 세트</li>
<li>로드밸런서 개수</li>
<li>로그 스트림</li>
</ul>
</li>
<li>일부 클라우드 프로바이더는 새로운 인스턴스 생성 속도에 상한이 있어, 클러스터 확장 작업 간 새로운 노드를 일괄적으로 배치하고, 배치 간에 일시 중지한다.</li>
</ul>
<h2 id=컨트롤-플레인-컴포넌트>컨트롤 플레인 컴포넌트</h2>
<p>대규모 클러스터의 경우, 충분한 컴퓨트 및 기타 리소스가 있는 컨트롤 플레인이
필요하다.</p>
<p>일반적으로 장애 영역 당 하나 또는 두 개의 컨트롤 플레인 인스턴스를
실행하고, 해당 인스턴스를 수직으로(vertically) 먼저 확장한 다음 (수직) 규모로 하락하는
지점에 도달한 후 수평으로(horizontally) 확장한다.</p>
<p>내결함성을 제공하려면 장애 영역 당 하나 이상의 인스턴스를 실행해야 한다. 쿠버네티스
노드는 동일한 장애 영역에 있는 컨트롤 플레인 엔드포인트로 트래픽을
자동으로 조정하지 않는다. 그러나, 클라우드 프로바이더는 이를 수행하기 위한 자체 메커니즘을 가지고 있을 수 있다.</p>
<p>예를 들어, 관리형 로드 밸런서를 사용하여 장애 영역 <em>A</em> 의
kubelet 및 파드에서 시작되는 트래픽을 전송하도록 로드 밸런서를 구성하고, 해당 트래픽을
<em>A</em> 영역에 있는 컨트롤 플레인 호스트로만 전달한다. 단일 컨트롤 플레인 호스트 또는
엔드포인트 장애 영역 <em>A</em> 이 오프라인이 되면, 영역 <em>A</em> 의 노드에 대한
모든 컨트롤 플레인 트래픽이 이제 영역간에 전송되고 있음을 의미한다. 각 영역에서 여러 컨트롤 플레인 호스트를
실행하면 가용성이 낮아진다.</p>
<h3 id=etcd-저장소>etcd 저장소</h3>
<p>큰 클러스터의 성능 향상을 위해, 사용자는 이벤트 오브젝트를 각각의
전용 etcd 인스턴스에 저장한다.</p>
<p>클러스터 생성시의 부가 스트립트이다.
클러스터 생성 시에 (사용자 도구를 사용하여) 다음을 수행할 수 있다.</p>
<ul>
<li>추가 etcd 인스턴스 시작 및 설정</li>
<li>이벤트를 저장하기 위한 <a class=glossary-tooltip title="쿠버네티스 API를 제공하는 컨트롤 플레인 컴포넌트." data-toggle=tooltip data-placement=top href=/ko/docs/concepts/overview/components/#kube-apiserver target=_blank aria-label="API server">API server</a> 설정</li>
</ul>
<p><a href=/docs/tasks/administer-cluster/configure-upgrade-etcd/>쿠버네티스를 위한 etcd 클러스터 운영하기</a>와
<a href=/docs/setup/production-environment/tools/kubeadm/setup-ha-etcd-with-kubeadm/>kubeadm을 이용하여 고가용성 etcd 생성하기</a>에서
큰 클러스터를 위한 etcd를 설정하고 관리하는 방법에 대한 상세 사항을 확인한다.</p>
<h2 id=애드온-리소스>애드온 리소스</h2>
<p>쿠버네티스 <a href=/ko/docs/concepts/configuration/manage-resources-containers/>리소스 제한</a>은
파드와 컨테이너가 다른 컴포넌트에 영향을 줄 수 있는 메모리 누수 및 기타 방식의 영향을
최소화하는 데 도움이 된다. 이러한 리소스 제한은 애플리케이션 워크로드에 적용될 수 있는 것처럼
<a class=glossary-tooltip title="Resources that extend the functionality of Kubernetes." data-toggle=tooltip data-placement=top href=/docs/concepts/cluster-administration/addons/ target=_blank aria-label=애드온>애드온</a> 리소스에도 적용될 수 있다.</p>
<p>예를 들어, 로깅 컴포넌트에 대한 CPU 및 메모리 제한을 설정할 수 있다.</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:#bbb>  </span>...<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>fluentd-cloud-logging<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>fluent/fluentd-kubernetes-daemonset:v1<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span>100m<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>200Mi<span style=color:#bbb>
</span></code></pre></div><p>애드온의 기본 제한은 일반적으로 중소형 쿠버네티스 클러스터에서
각 애드온을 실행한 경험에서 수집된 데이터를 기반으로 한다. 대규모 클러스터에서
실행할 때, 애드온은 종종 기본 제한보다 많은 리소스를 소비한다.
이러한 값을 조정하지 않고 대규모 클러스터를 배포하면, 애드온이
메모리 제한에 계속 도달하기 때문에 지속적으로 종료될 수 있다.
또는, 애드온이 실행될 수 있지만 CPU 시간 슬라이스 제한으로 인해
성능이 저하된다.</p>
<p>클러스터 애드온 리소스 문제가 발생하지 않도록, 노드가 많은 클러스터를
만들 때, 다음 사항을 고려한다.</p>
<ul>
<li>일부 애드온은 수직으로 확장된다. 클러스터 또는 전체 장애 영역을
제공하는 애드온 레플리카가 하나 있다. 이러한 애드온의 경우, 클러스터를 확장할 때
요청과 제한을 늘린다.</li>
<li>많은 애드온은 수평으로 확장된다. 더 많은 파드를 실행하여 용량을 추가하지만,
매우 큰 클러스터에서는 CPU 또는 메모리 제한을 약간 높여야 할 수도 있다.
VerticalPodAutoscaler는 <em>recommender</em> 모드에서 실행되어 요청 및 제한에 대한
제안 수치를 제공할 수 있다.</li>
<li>일부 애드온은 <a class=glossary-tooltip title="파드의 복제본을 클러스터 노드 집합에서 동작하게 한다." data-toggle=tooltip data-placement=top href=/ko/docs/concepts/workloads/controllers/daemonset target=_blank aria-label=데몬셋(DaemonSet)>데몬셋(DaemonSet)</a>에 의해 제어되는 노드 당 하나의 복사본으로 실행된다(예: 노드 수준 로그 수집기). 수평
확장 애드온의 경우와 유사하게, CPU 또는 메모리 제한을 약간 높여야
할 수도 있다.</li>
</ul>
<h2 id=다음-내용>다음 내용</h2>
<p><code>VerticalPodAutoscaler</code> 는 리소스 요청 및 파드 제한을 관리하는 데 도움이 되도록
클러스터에 배포할 수 있는 사용자 정의 리소스이다.
클러스터에 중요한 애드온을 포함하여 클러스터 컴포넌트를 확장하는 방법에 대한
자세한 내용은 <a href=https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler#readme>Vertical Pod Autoscaler</a>를
방문하여 배워본다.</p>
<p><a href=https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler#readme>클러스터 오토스케일러</a>는
여러 클라우드 프로바이더와 통합되어 클러스터의 리소스 요구 수준에 맞는
노드 수를 실행할 수 있도록 도와준다.</p>
<p><a href=https://github.com/kubernetes/autoscaler/tree/master/addon-resizer#readme>addon resizer</a>는
클러스터 스케일이 변경될 때 자동으로 애드온 크기를 조정할 수 있도록 도와준다.</p>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-970615c97499e3651fd3a98e0387cefc>2 - 여러 영역에서 실행</h1>
<p>이 페이지에서는 여러 영역에서 쿠버네티스를 실행하는 방법을 설명한다.</p>
<h2 id=배경>배경</h2>
<p>쿠버네티스는 단일 쿠버네티스 클러스터가 여러 장애 영역에서
실행될 수 있도록 설계되었다. 일반적으로 이러한 영역은 <em>지역(region)</em> 이라는
논리적 그룹 내에 적합하다. 주요 클라우드 제공자는 지역을 일관된 기능 집합을
제공하는 장애 영역 집합(<em>가용성 영역</em> 이라고도 함)으로
정의한다. 지역 내에서 각 영역은 동일한 API 및
서비스를 제공한다.</p>
<p>일반적인 클라우드 아키텍처는 한 영역의 장애가 다른 영역의 서비스도
손상시킬 가능성을 최소화하는 것을 목표로 한다.</p>
<h2 id=컨트롤-플레인-동작>컨트롤 플레인 동작</h2>
<p>모든 <a href=/ko/docs/concepts/overview/components/#%EC%BB%A8%ED%8A%B8%EB%A1%A4-%ED%94%8C%EB%A0%88%EC%9D%B8-%EC%BB%B4%ED%8F%AC%EB%84%8C%ED%8A%B8>컨트롤 플레인 컴포넌트</a>는
컴포넌트별로 복제되는 교환 가능한 리소스 풀로 실행을
지원한다.</p>
<p>클러스터 컨트롤 플레인을 배포할 때, 여러 장애 영역에
컨트롤 플레인 컴포넌트의 복제본을 배치한다. 가용성이
중요한 문제인 경우, 3개 이상의 장애 영역을 선택하고
각 개별 컨트롤 플레인 컴포넌트(API 서버, 스케줄러, etcd,
클러스터 컨트롤러 관리자)를 3개 이상의 장애 영역에 복제한다.
클라우드 컨트롤러 관리자를 실행 중인 경우 선택한
모든 장애 영역에 걸쳐 이를 복제해야 한다.</p>
<div class="alert alert-info note callout" role=alert>
<strong>참고:</strong> 쿠버네티스는 API 서버 엔드포인트에 대한 교차 영역 복원성을 제공하지
않는다. DNS 라운드-로빈, SRV 레코드 또는 상태 확인 기능이 있는
써드파티 로드 밸런싱 솔루션을 포함하여 다양한 기술을 사용하여
클러스터 API 서버의 가용성을 향상시킬 수 있다.
</div>
<h2 id=노드-동작>노드 동작</h2>
<p>쿠버네티스는 클러스터의 여러 노드에 걸쳐
워크로드 리소스(예: <a class=glossary-tooltip title="클러스터에서 복제된 애플리케이션을 관리한다." data-toggle=tooltip data-placement=top href=/ko/docs/concepts/workloads/controllers/deployment/ target=_blank aria-label=디플로이먼트(Deployment)>디플로이먼트(Deployment)</a>
또는 <a class=glossary-tooltip title="내구성이 있는 스토리지와 파드별로 지속성 식별자를 사용해서 파드 집합의 디플로이먼트와 스케일링을 관리한다." data-toggle=tooltip data-placement=top href=/ko/docs/concepts/workloads/controllers/statefulset/ target=_blank aria-label=스테이트풀셋(StatefulSet)>스테이트풀셋(StatefulSet)</a>)에
대한 파드를 자동으로 분배한다. 이러한 분배는
실패에 대한 영향을 줄이는 데 도움이 된다.</p>
<p>노드가 시작되면, 각 노드의 kubelet이 쿠버네티스 API에서
특정 kubelet을 나타내는 노드 오브젝트에
<a class=glossary-tooltip title="사용자에게 의미 있고 관련성 높은 특징으로 식별할 수 있도록 오브젝트에 태그를 붙인다." data-toggle=tooltip data-placement=top href=/ko/docs/concepts/overview/working-with-objects/labels target=_blank aria-label=레이블>레이블</a>을 자동으로 추가한다.
이러한 레이블에는
<a href=/ko/docs/reference/labels-annotations-taints/#topologykubernetesiozone>영역 정보</a>가 포함될 수 있다.</p>
<p>클러스터가 여러 영역 또는 지역에 걸쳐있는 경우,
<a href=/ko/docs/concepts/workloads/pods/pod-topology-spread-constraints/>파드 토폴로지 분배 제약 조건</a>과
함께 노드 레이블을 사용하여
파드가 장애 도메인(지역, 영역, 특정 노드) 간 클러스터에
분산되는 방식을 제어할 수 있다.
이러한 힌트를 통해
<a class=glossary-tooltip title="노드가 배정되지 않은 새로 생성된 파드를 감지하고, 실행할 노드를 선택하는 컨트롤 플레인 컴포넌트." data-toggle=tooltip data-placement=top href=/docs/reference/command-line-tools-reference/kube-scheduler/ target=_blank aria-label=스케줄러>스케줄러</a>는
더 나은 예상 가용성을 위해 파드를 배치할 수 있으므로, 상관 관계가 있는
오류가 전체 워크로드에 영향을 미칠 위험을 줄일 수 있다.</p>
<p>예를 들어, 가능할 때마다 스테이트풀셋의
3개 복제본이 모두 서로 다른 영역에서 실행되도록 제약 조건을
설정할 수 있다. 각 워크로드에 사용 중인
가용 영역을 명시적으로 정의하지 않고 이를 선언적으로
정의할 수 있다.</p>
<h3 id=여러-영역에-노드-분배>여러 영역에 노드 분배</h3>
<p>쿠버네티스의 코어는 사용자를 위해 노드를 생성하지 않는다. 사용자가 직접 수행하거나,
<a href=https://cluster-api.sigs.k8s.io/>클러스터 API</a>와 같은 도구를 사용하여
사용자 대신 노드를 관리해야 한다.</p>
<p>클러스터 API와 같은 도구를 사용하면 여러 장애 도메인에서
클러스터의 워커 노드로 실행할 머신 집합과 전체 영역 서비스 중단 시
클러스터를 자동으로 복구하는 규칙을 정의할 수 있다.</p>
<h2 id=파드에-대한-수동-영역-할당>파드에 대한 수동 영역 할당</h2>
<p>생성한 파드와 디플로이먼트, 스테이트풀셋, 잡(Job)과
같은 워크로드 리소스의 파드 템플릿에 <a href=/ko/docs/concepts/scheduling-eviction/assign-pod-node/#%EB%85%B8%EB%93%9C-%EC%85%80%EB%A0%89%ED%84%B0-nodeselector>노드 셀렉터 제약 조건</a>을
적용할 수 있다.</p>
<h2 id=영역에-대한-스토리지-접근>영역에 대한 스토리지 접근</h2>
<p>퍼시스턴트 볼륨이 생성되면, <code>PersistentVolumeLabel</code>
<a href=/docs/reference/access-authn-authz/admission-controllers/>어드미션 컨트롤러</a>는
특정 영역에 연결된 모든 퍼시스턴트볼륨(PersistentVolume)에 영역 레이블을 자동으로
추가한다. 그런 다음 <a class=glossary-tooltip title="노드가 배정되지 않은 새로 생성된 파드를 감지하고, 실행할 노드를 선택하는 컨트롤 플레인 컴포넌트." data-toggle=tooltip data-placement=top href=/docs/reference/command-line-tools-reference/kube-scheduler/ target=_blank aria-label=스케줄러>스케줄러</a>는
<code>NoVolumeZoneConflict</code> 프레디케이트(predicate)를 통해 주어진 퍼시스턴트볼륨을 요구하는 파드가
해당 볼륨과 동일한 영역에만 배치되도록 한다.</p>
<p>해당 클래스의 스토리지가 사용할 수 있는 장애 도메인(영역)을 지정하는
퍼시스턴트볼륨클레임(PersistentVolumeClaims)에 대한
<a class=glossary-tooltip title="스토리지클래스는 관리자가 사용 가능한 다양한 스토리지 유형을 설명할 수 있는 방법을 제공한다." data-toggle=tooltip data-placement=top href=/ko/docs/concepts/storage/storage-classes target=_blank aria-label=스토리지클래스(StorageClass)>스토리지클래스(StorageClass)</a>를 지정할 수 있다.
장애 도메인 또는 영역을 인식하는 스토리지클래스 구성에 대한 자세한 내용은
<a href=/ko/docs/concepts/storage/storage-classes/#%ED%97%88%EC%9A%A9%EB%90%9C-%ED%86%A0%ED%8F%B4%EB%A1%9C%EC%A7%80>허용된 토폴로지</a>를 참고한다.</p>
<h2 id=네트워킹>네트워킹</h2>
<p>쿠버네티스가 스스로 영역-인지(zone-aware) 네트워킹을 포함하지는 않는다.
<a href=/ko/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/>네트워크 플러그인</a>을
사용하여 클러스터 네트워킹을 구성할 수 있으며, 해당 네트워크 솔루션에는 영역별 요소가
있을 수 있다. 예를 들어, 클라우드 제공자가
<code>type=LoadBalancer</code> 를 사용하여 서비스를 지원하는 경우, 로드 밸런서는 지정된 연결을 처리하는
로드 밸런서 요소와 동일한 영역에서 실행 중인 파드로만 트래픽을 보낼 수 있다.
자세한 내용은 클라우드 제공자의 문서를 확인한다.</p>
<p>사용자 정의 또는 온-프레미스 배포의 경우, 비슷한 고려 사항이 적용된다.
다른 장애 영역 처리를 포함한 <a class=glossary-tooltip title="네트워크 서비스로 파드 집합에서 실행 중인 애플리케이션을 노출하는 방법" data-toggle=tooltip data-placement=top href=/ko/docs/concepts/services-networking/service/ target=_blank aria-label=서비스>서비스</a>와
<a class=glossary-tooltip title="클러스터 내의 서비스에 대한 외부 접근을 관리하는 API 오브젝트이며, 일반적으로 HTTP를 관리함." data-toggle=tooltip data-placement=top href=/ko/docs/concepts/services-networking/ingress/ target=_blank aria-label=인그레스(Ingress)>인그레스(Ingress)</a> 동작은
클러스터가 설정된 방식에 명확히 의존한다.</p>
<h2 id=장애-복구>장애 복구</h2>
<p>클러스터를 설정할 때, 한 지역의 모든 장애 영역이 동시에
오프라인 상태가 되는 경우 설정에서 서비스를 복원할 수 있는지
여부와 방법을 고려해야 할 수도 있다. 예를 들어, 영역에서 파드를 실행할 수 있는
노드가 적어도 하나 이상 있어야 하는가?
클러스터에 중요한 복구 작업이 클러스터에
적어도 하나 이상의 정상 노드에 의존하지 않는지 확인한다. 예를 들어, 모든 노드가
비정상인 경우, 하나 이상의 노드를 서비스할 수 있을 만큼 복구를 완료할 수 있도록 특별한
<a class=glossary-tooltip title="세 가지 필수 속성: 키(key), 값(value), 효과(effect)로 구성된 코어 오브젝트. 톨러레이션은 매칭되는 테인트(taint)를 가진 노드나 노드 그룹에 파드가 스케줄링되는 것을 활성화한다." data-toggle=tooltip data-placement=top href=/ko/docs/concepts/scheduling-eviction/taint-and-toleration/ target=_blank aria-label=톨러레이션(toleration)>톨러레이션(toleration)</a>으로
복구 작업을 실행해야 할 수 있다.</p>
<p>쿠버네티스는 이 문제에 대한 답을 제공하지 않는다. 그러나,
고려해야 할 사항이다.</p>
<h2 id=다음-내용>다음 내용</h2>
<p>스케줄러가 구성된 제약 조건을 준수하면서, 클러스터에 파드를 배치하는 방법을 알아보려면,
<a href=/ko/docs/concepts/scheduling-eviction/>스케줄링과 축출(eviction)</a>을 참고한다.</p>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-f89867de1d34943f1524f67a241f5cc9>3 - 노드 구성 검증하기</h1>
<h2 id=노드-적합성-테스트>노드 적합성 테스트</h2>
<p><em>노드 적합성 테스트</em> 는 노드의 시스템 검증과 기능 테스트를 제공하기 위해 컨테이너화된 테스트 프레임워크이다.
테스트는 노드가 쿠버네티스를 위한 최소 요구조건을 만족하는지를 검증한다. 그리고 테스트를 통과한 노드는 쿠버네티스 클러스터에 참
여할 자격이 주어진다.</p>
<h2 id=노드-필수-구성-요소>노드 필수 구성 요소</h2>
<p>노드 적합성 테스트를 실행하기 위해서는, 해당 노드는 표준 쿠버네티스 노드로서 동일한 전제조건을 만족해야 한다.
노드는 최소한 아래 데몬들이 설치되어 있어야 한다.</p>
<ul>
<li>컨테이너 런타임 (Docker)</li>
<li>Kubelet</li>
</ul>
<h2 id=노드-적합성-테스트-실행>노드 적합성 테스트 실행</h2>
<p>노드 적합성 테스트는 다음 순서로 진행된다.</p>
<ol>
<li>kubelet에 대한 <code>--kubeconfig</code> 옵션의 값을 계산한다. 예를 들면, 다음과 같다.
<code>--kubeconfig = / var / lib / kubelet / config.yaml</code>.
테스트 프레임워크는 kubelet을 테스트하기 위해 로컬 컨트롤 플레인을 시작하기 때문에,
<code>http://localhost:8080</code> 을 API 서버의 URL로 사용한다.
사용할 수 있는 kubelet 커맨드 라인 파라미터가 몇 개 있다.</li>
</ol>
<ul>
<li><code>--pod-cidr</code>: <code>kubenet</code>을 사용 중이라면, 임의의 CIDR을 Kubelet에 지정해주어야 한다. 예) <code>--pod-cidr=10.180.0.0/24</code>.</li>
<li><code>--cloud-provider</code>: <code>--cloud-provider=gce</code>를 사용 중이라면, 테스트 실행 시에는 제거해야 한다.</li>
</ul>
<ol start=2>
<li>다음 커맨드로 노드 적합성 테스트를 실행한다.</li>
</ol>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=color:#080;font-style:italic># $CONFIG_DIR는 Kublet의 파드 매니페스트 경로이다.</span>
<span style=color:#080;font-style:italic># $LOG_DIR는 테스트 출력 경로이다.</span>
sudo docker run -it --rm --privileged --net<span style=color:#666>=</span>host <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>  -v /:/rootfs -v <span style=color:#b8860b>$CONFIG_DIR</span>:<span style=color:#b8860b>$CONFIG_DIR</span> -v <span style=color:#b8860b>$LOG_DIR</span>:/var/result <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>  k8s.gcr.io/node-test:0.2
</code></pre></div><h2 id=다른-아키텍처에서-노드-적합성-테스트-실행>다른 아키텍처에서 노드 적합성 테스트 실행</h2>
<p>쿠버네티스는 다른 아키텍쳐용 노드 적합성 테스트 Docker 이미지도 제공한다.</p>
<table>
<thead>
<tr>
<th>Arch</th>
<th style=text-align:center>Image</th>
</tr>
</thead>
<tbody>
<tr>
<td>amd64</td>
<td style=text-align:center>node-test-amd64</td>
</tr>
<tr>
<td>arm</td>
<td style=text-align:center>node-test-arm</td>
</tr>
<tr>
<td>arm64</td>
<td style=text-align:center>node-test-arm64</td>
</tr>
</tbody>
</table>
<h2 id=선택된-테스트-실행>선택된 테스트 실행</h2>
<p>특정 테스트만 실행하기 위해서는 환경 변수 <code>FOCUS</code>에 테스트하고자 하는 테스트를 정규식으로 지정한다.</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>sudo docker run -it --rm --privileged --net<span style=color:#666>=</span>host <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>  -v /:/rootfs:ro -v <span style=color:#b8860b>$CONFIG_DIR</span>:<span style=color:#b8860b>$CONFIG_DIR</span> -v <span style=color:#b8860b>$LOG_DIR</span>:/var/result <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>  -e <span style=color:#b8860b>FOCUS</span><span style=color:#666>=</span>MirrorPod <span style=color:#b62;font-weight:700>\ </span><span style=color:#080;font-style:italic># MirrorPod 테스트만 실행</span>
  k8s.gcr.io/node-test:0.2
</code></pre></div><p>특정 테스트를 건너뛰기 위해서는, 환경 변수 <code>SKIP</code>에 건너뛰고자 하는 테스트를 정규식으로 지정한다.</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>sudo docker run -it --rm --privileged --net<span style=color:#666>=</span>host <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>  -v /:/rootfs:ro -v <span style=color:#b8860b>$CONFIG_DIR</span>:<span style=color:#b8860b>$CONFIG_DIR</span> -v <span style=color:#b8860b>$LOG_DIR</span>:/var/result <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>  -e <span style=color:#b8860b>SKIP</span><span style=color:#666>=</span>MirrorPod <span style=color:#b62;font-weight:700>\ </span><span style=color:#080;font-style:italic># MirrorPod 테스트만 건너뛰고 모든 적합성 테스트를 실행한다</span>
  k8s.gcr.io/node-test:0.2
</code></pre></div><p>노드 적합성 테스트는 <a href=https://github.com/kubernetes/community/blob/master/contributors/devel/sig-node/e2e-node-tests.md>노드 e2e 테스트</a>를 컨테이너화한 버전이다.
기본적으로, 모든 적합성 테스트를 실행한다.</p>
<p>이론적으로, 컨테이너와 필요한 볼륨을 적절히 설정했다면 어떤 노드 e2e 테스트도 수행할 수 있다.
하지만, 적합성 테스트가 아닌 테스트들은 훨씬 복잡한 설정이 필요하기 때문에 <strong>적합성 테스트만 실행하기를 강하게 추천한다.</strong></p>
<h2 id=주의-사항>주의 사항</h2>
<ul>
<li>테스트 후, 노드 적합성 테스트 이미지 및 기능 테스트에 사용된 이미지들을 포함하여 몇 개의 Docker 이미지들이 노드에 남는다.</li>
<li>테스트 후, 노드에 죽은 컨테이너가 남는다. 기능 테스트 도중에 생성된 컨테이너들이다.</li>
</ul>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-0394f813094b7a35058dffe5b8bacd20>4 - PKI 인증서 및 요구 사항</h1>
<p>쿠버네티스는 TLS를 통한 인증을 위해서 PKI 인증서가 필요하다.
만약 <a href=/ko/docs/reference/setup-tools/kubeadm/>kubeadm</a>으로 쿠버네티스를 설치한다면, 클러스터에 필요한 인증서는 자동으로 생성된다.
또한 더 안전하게 자신이 소유한 인증서를 생성할 수 있다. 이를 테면, 개인키를 API 서버에 저장하지 않으므로 더 안전하게 보관할 수 있다.
이 페이지는 클러스터가 필요로 하는 인증서에 대해서 설명한다.</p>
<h2 id=클러스터에서-인증서가-이용되는-방식>클러스터에서 인증서가 이용되는 방식</h2>
<p>쿠버네티스는 다음 작업에서 PKI를 필요로 한다.</p>
<ul>
<li>kubelet에서 API 서버 인증서를 인증시 사용하는 클라이언트 인증서</li>
<li>API 서버 엔드포인트를 위한 서버 인증서</li>
<li>API 서버에 클러스터 관리자 인증을 위한 클라이언트 인증서</li>
<li>API 서버에서 kubelet과 통신을 위한 클라이언트 인증서</li>
<li>API 서버에서 etcd 간의 통신을 위한 클라이언트 인증서</li>
<li>컨트롤러 매니저와 API 서버 간의 통신을 위한 클라이언트 인증서/kubeconfig</li>
<li>스케줄러와 API 서버간 통신을 위한 클라이언트 인증서/kubeconfig</li>
<li><a href=/docs/tasks/extend-kubernetes/configure-aggregation-layer/>front-proxy</a>를 위한 클라이언트와 서버 인증서</li>
</ul>
<div class="alert alert-info note callout" role=alert>
<strong>참고:</strong> <code>front-proxy</code> 인증서는 kube-proxy에서 <a href=/ko/docs/tasks/extend-kubernetes/setup-extension-api-server/>API 서버 확장</a>을 지원할 때만 kube-proxy에서 필요하다.
</div>
<p>etcd 역시 클라이언트와 피어 간에 상호 TLS 인증을 구현한다.</p>
<h2 id=인증서를-저장하는-위치>인증서를 저장하는 위치</h2>
<p>만약 쿠버네티스를 kubeadm으로 설치했다면, 대부분의 인증서는 <code>/etc/kubernetes/pki</code>에 저장된다. 이 문서에 언급된 모든 파일 경로는 그 디렉터리에 상대적이나, kubeadm이 <code>/etc/kubernetes</code>에 저장하는 사용자 어카운트 인증서는 예외이다.</p>
<h2 id=인증서-수동-설정>인증서 수동 설정</h2>
<p>필요한 인증서를 kubeadm으로 생성하기 싫다면, 단일 루트 CA를 이용하거나 모든 인증서를 제공하여 생성할 수 있다. 소유한 인증기관을 이용해서 생성하는 방법에 대해서는 <a href=/ko/docs/tasks/administer-cluster/certificates/>인증서</a>를 살펴본다.
인증서를 관리하는 방법에 대해서는 <a href=/ko/docs/tasks/administer-cluster/kubeadm/kubeadm-certs/>kubeadm을 사용한 인증서 관리</a>를 살펴본다.</p>
<h3 id=단일-루트-ca>단일 루트 CA</h3>
<p>관리자에 의해 제어되는 단일 루트 CA를 만들 수 있다. 이 루트 CA는 여러 중간 CA를 생성할 수 있고, 모든 추가 생성에 관해서도 쿠버네티스 자체에 위임할 수 있다.</p>
<p>필요 CA:</p>
<table>
<thead>
<tr>
<th>경로</th>
<th>기본 CN</th>
<th>설명</th>
</tr>
</thead>
<tbody>
<tr>
<td>ca.crt,key</td>
<td>kubernetes-ca</td>
<td>쿠버네티스 일반 CA</td>
</tr>
<tr>
<td>etcd/ca.crt,key</td>
<td>etcd-ca</td>
<td>모든 etcd 관련 기능을 위해서</td>
</tr>
<tr>
<td>front-proxy-ca.crt,key</td>
<td>kubernetes-front-proxy-ca</td>
<td><a href=/docs/tasks/extend-kubernetes/configure-aggregation-layer/>front-end proxy</a> 위해서</td>
</tr>
</tbody>
</table>
<p>위의 CA외에도, 서비스 계정 관리를 위한 공개/개인 키 쌍인 <code>sa.key</code> 와 <code>sa.pub</code> 을 얻는 것이 필요하다.
다음은 이전 표에 나온 CA 키와 인증서 파일을 보여준다.</p>
<pre><code>/etc/kubernetes/pki/ca.crt
/etc/kubernetes/pki/ca.key
/etc/kubernetes/pki/etcd/ca.crt
/etc/kubernetes/pki/etcd/ca.key
/etc/kubernetes/pki/front-proxy-ca.crt
/etc/kubernetes/pki/front-proxy-ca.key
</code></pre><h3 id=모든-인증서>모든 인증서</h3>
<p>이런 개인키를 API 서버에 복사하기 원치 않는다면, 모든 인증서를 스스로 생성할 수 있다.</p>
<p>필요한 인증서:</p>
<table>
<thead>
<tr>
<th>기본 CN</th>
<th>부모 CA</th>
<th>O (주체에서)</th>
<th>종류</th>
<th>호스트 (SAN)</th>
</tr>
</thead>
<tbody>
<tr>
<td>kube-etcd</td>
<td>etcd-ca</td>
<td></td>
<td>server, client</td>
<td><code>&lt;hostname></code>, <code>&lt;Host_IP></code>, <code>localhost</code>, <code>127.0.0.1</code></td>
</tr>
<tr>
<td>kube-etcd-peer</td>
<td>etcd-ca</td>
<td></td>
<td>server, client</td>
<td><code>&lt;hostname></code>, <code>&lt;Host_IP></code>, <code>localhost</code>, <code>127.0.0.1</code></td>
</tr>
<tr>
<td>kube-etcd-healthcheck-client</td>
<td>etcd-ca</td>
<td></td>
<td>client</td>
<td></td>
</tr>
<tr>
<td>kube-apiserver-etcd-client</td>
<td>etcd-ca</td>
<td>system:masters</td>
<td>client</td>
<td></td>
</tr>
<tr>
<td>kube-apiserver</td>
<td>kubernetes-ca</td>
<td></td>
<td>server</td>
<td><code>&lt;hostname></code>, <code>&lt;Host_IP></code>, <code>&lt;advertise_IP></code>, <code>[1]</code></td>
</tr>
<tr>
<td>kube-apiserver-kubelet-client</td>
<td>kubernetes-ca</td>
<td>system:masters</td>
<td>client</td>
<td></td>
</tr>
<tr>
<td>front-proxy-client</td>
<td>kubernetes-front-proxy-ca</td>
<td></td>
<td>client</td>
<td></td>
</tr>
</tbody>
</table>
<p>[1]: 클러스터에 접속한 다른 IP 또는 DNS 이름(<a href=/ko/docs/reference/setup-tools/kubeadm/>kubeadm</a>이 사용하는
로드 밸런서 안정 IP 또는 DNS 이름, <code>kubernetes</code>, <code>kubernetes.default</code>, <code>kubernetes.default.svc</code>,
<code>kubernetes.default.svc.cluster</code>, <code>kubernetes.default.svc.cluster.local</code>)</p>
<p><code>kind</code>는 하나 이상의 <a href=https://godoc.org/k8s.io/api/certificates/v1beta1#KeyUsage>x509 키 사용</a> 종류를 가진다.</p>
<table>
<thead>
<tr>
<th>종류</th>
<th>키 사용</th>
</tr>
</thead>
<tbody>
<tr>
<td>server</td>
<td>digital signature, key encipherment, server auth</td>
</tr>
<tr>
<td>client</td>
<td>digital signature, key encipherment, client auth</td>
</tr>
</tbody>
</table>
<div class="alert alert-info note callout" role=alert>
<strong>참고:</strong> 위에 나열된 호스트/SAN은 작업 중인 클러스터를 획득하는데 권장된다. 특정 설정이 필요한 경우, 모든 서버 인증서에 SAN을 추가할 수 있다.
</div>
<div class="alert alert-info note callout" role=alert>
<strong>참고:</strong> <p>kubeadm 사용자만 해당:</p>
<ul>
<li>개인 키 없이 클러스터 CA 인증서에 복사하는 시나리오는 kubeadm 문서에서 외부 CA라고 한다.</li>
<li>위 목록을 kubeadm이 생성한 PKI와 비교하는 경우, <code>kube-etcd</code>, <code>kube-etcd-peer</code> 와 <code>kube-etcd-healthcheck-client</code> 인증서는
외부 etcd 케이스에서는 생성하지 않는 것을 알고 있어야 한다.</li>
</ul>
</div>
<h3 id=certificate-paths>인증서 파일 경로</h3>
<p>인증서는 권고하는 파일 경로에 존재해야 한다(<a href=/ko/docs/reference/setup-tools/kubeadm/>kubeadm</a>에서 사용되는 것처럼).
경로는 위치에 관계없이 주어진 파라미터를 사용하여 지정해야 한다.</p>
<table>
<thead>
<tr>
<th>기본 CN</th>
<th>권고되는 키 파일 경로</th>
<th>권고하는 인증서 파일 경로</th>
<th>명령어</th>
<th>키 파라미터</th>
<th>인증서 파라미터</th>
</tr>
</thead>
<tbody>
<tr>
<td>etcd-ca</td>
<td>etcd/ca.key</td>
<td>etcd/ca.crt</td>
<td>kube-apiserver</td>
<td></td>
<td>--etcd-cafile</td>
</tr>
<tr>
<td>kube-apiserver-etcd-client</td>
<td>apiserver-etcd-client.key</td>
<td>apiserver-etcd-client.crt</td>
<td>kube-apiserver</td>
<td>--etcd-keyfile</td>
<td>--etcd-certfile</td>
</tr>
<tr>
<td>kubernetes-ca</td>
<td>ca.key</td>
<td>ca.crt</td>
<td>kube-apiserver</td>
<td></td>
<td>--client-ca-file</td>
</tr>
<tr>
<td>kubernetes-ca</td>
<td>ca.key</td>
<td>ca.crt</td>
<td>kube-controller-manager</td>
<td>--cluster-signing-key-file</td>
<td>--client-ca-file, --root-ca-file, --cluster-signing-cert-file</td>
</tr>
<tr>
<td>kube-apiserver</td>
<td>apiserver.key</td>
<td>apiserver.crt</td>
<td>kube-apiserver</td>
<td>--tls-private-key-file</td>
<td>--tls-cert-file</td>
</tr>
<tr>
<td>kube-apiserver-kubelet-client</td>
<td>apiserver-kubelet-client.key</td>
<td>apiserver-kubelet-client.crt</td>
<td>kube-apiserver</td>
<td>--kubelet-client-key</td>
<td>--kubelet-client-certificate</td>
</tr>
<tr>
<td>front-proxy-ca</td>
<td>front-proxy-ca.key</td>
<td>front-proxy-ca.crt</td>
<td>kube-apiserver</td>
<td></td>
<td>--requestheader-client-ca-file</td>
</tr>
<tr>
<td>front-proxy-ca</td>
<td>front-proxy-ca.key</td>
<td>front-proxy-ca.crt</td>
<td>kube-controller-manager</td>
<td></td>
<td>--requestheader-client-ca-file</td>
</tr>
<tr>
<td>front-proxy-client</td>
<td>front-proxy-client.key</td>
<td>front-proxy-client.crt</td>
<td>kube-apiserver</td>
<td>--proxy-client-key-file</td>
<td>--proxy-client-cert-file</td>
</tr>
<tr>
<td>etcd-ca</td>
<td>etcd/ca.key</td>
<td>etcd/ca.crt</td>
<td>etcd</td>
<td></td>
<td>--trusted-ca-file, --peer-trusted-ca-file</td>
</tr>
<tr>
<td>kube-etcd</td>
<td>etcd/server.key</td>
<td>etcd/server.crt</td>
<td>etcd</td>
<td>--key-file</td>
<td>--cert-file</td>
</tr>
<tr>
<td>kube-etcd-peer</td>
<td>etcd/peer.key</td>
<td>etcd/peer.crt</td>
<td>etcd</td>
<td>--peer-key-file</td>
<td>--peer-cert-file</td>
</tr>
<tr>
<td>etcd-ca</td>
<td></td>
<td>etcd/ca.crt</td>
<td>etcdctl</td>
<td></td>
<td>--cacert</td>
</tr>
<tr>
<td>kube-etcd-healthcheck-client</td>
<td>etcd/healthcheck-client.key</td>
<td>etcd/healthcheck-client.crt</td>
<td>etcdctl</td>
<td>--key</td>
<td>--cert</td>
</tr>
</tbody>
</table>
<p>서비스 계정 키 쌍에도 동일한 고려 사항이 적용된다.</p>
<table>
<thead>
<tr>
<th>개인키 경로</th>
<th>공개 키 경로</th>
<th>명령어</th>
<th>파라미터</th>
</tr>
</thead>
<tbody>
<tr>
<td>sa.key</td>
<td></td>
<td>kube-controller-manager</td>
<td>--service-account-private-key-file</td>
</tr>
<tr>
<td></td>
<td>sa.pub</td>
<td>kube-apiserver</td>
<td>--service-account-key-file</td>
</tr>
</tbody>
</table>
<p>다음은 키와 인증서를 모두 생성할 때에 제공해야 하는 <a href=#certificate-paths>이전 표에 있는</a> 파일의 경로를 보여준다.</p>
<pre><code>/etc/kubernetes/pki/etcd/ca.key
/etc/kubernetes/pki/etcd/ca.crt
/etc/kubernetes/pki/apiserver-etcd-client.key
/etc/kubernetes/pki/apiserver-etcd-client.crt
/etc/kubernetes/pki/ca.key
/etc/kubernetes/pki/ca.crt
/etc/kubernetes/pki/apiserver.key
/etc/kubernetes/pki/apiserver.crt
/etc/kubernetes/pki/apiserver-kubelet-client.key
/etc/kubernetes/pki/apiserver-kubelet-client.crt
/etc/kubernetes/pki/front-proxy-ca.key
/etc/kubernetes/pki/front-proxy-ca.crt
/etc/kubernetes/pki/front-proxy-client.key
/etc/kubernetes/pki/front-proxy-client.crt
/etc/kubernetes/pki/etcd/server.key
/etc/kubernetes/pki/etcd/server.crt
/etc/kubernetes/pki/etcd/peer.key
/etc/kubernetes/pki/etcd/peer.crt
/etc/kubernetes/pki/etcd/healthcheck-client.key
/etc/kubernetes/pki/etcd/healthcheck-client.crt
/etc/kubernetes/pki/sa.key
/etc/kubernetes/pki/sa.pub
</code></pre><h2 id=각-사용자-계정을-위한-인증서-설정하기>각 사용자 계정을 위한 인증서 설정하기</h2>
<p>반드시 이런 관리자 계정과 서비스 계정을 설정해야 한다.</p>
<table>
<thead>
<tr>
<th>파일명</th>
<th>자격증명 이름</th>
<th>기본 CN</th>
<th>O (주체에서)</th>
</tr>
</thead>
<tbody>
<tr>
<td>admin.conf</td>
<td>default-admin</td>
<td>kubernetes-admin</td>
<td>system:masters</td>
</tr>
<tr>
<td>kubelet.conf</td>
<td>default-auth</td>
<td>system:node:<code>&lt;nodeName></code> (note를 보자)</td>
<td>system:nodes</td>
</tr>
<tr>
<td>controller-manager.conf</td>
<td>default-controller-manager</td>
<td>system:kube-controller-manager</td>
<td></td>
</tr>
<tr>
<td>scheduler.conf</td>
<td>default-scheduler</td>
<td>system:kube-scheduler</td>
<td></td>
</tr>
</tbody>
</table>
<div class="alert alert-info note callout" role=alert>
<strong>참고:</strong> <code>kubelet.conf</code>을 위한 <code>&lt;nodeName></code>값은 API 서버에 등록된 것처럼 kubelet에 제공되는 노드 이름 값과 <strong>반드시</strong> 정확히 일치해야 한다. 더 자세한 내용은 <a href=/docs/reference/access-authn-authz/node/>노드 인증</a>을 살펴보자.
</div>
<ol>
<li>
<p>각 환경 설정에 대해 주어진 CN과 O를 이용하여 x509 인증서와 키쌍을 생성한다.</p>
</li>
<li>
<p>각 환경 설정에 대해 다음과 같이 <code>kubectl</code>를 실행한다.</p>
</li>
</ol>
<pre><code>KUBECONFIG=&lt;filename&gt; kubectl config set-cluster default-cluster --server=https://&lt;host ip&gt;:6443 --certificate-authority &lt;path-to-kubernetes-ca&gt; --embed-certs
KUBECONFIG=&lt;filename&gt; kubectl config set-credentials &lt;credential-name&gt; --client-key &lt;path-to-key&gt;.pem --client-certificate &lt;path-to-cert&gt;.pem --embed-certs
KUBECONFIG=&lt;filename&gt; kubectl config set-context default-system --cluster default-cluster --user &lt;credential-name&gt;
KUBECONFIG=&lt;filename&gt; kubectl config use-context default-system
</code></pre><p>이 파일들은 다음과 같이 사용된다.</p>
<table>
<thead>
<tr>
<th>파일명</th>
<th>명령어</th>
<th>설명</th>
</tr>
</thead>
<tbody>
<tr>
<td>admin.conf</td>
<td>kubectl</td>
<td>클러스터 관리자를 설정한다.</td>
</tr>
<tr>
<td>kubelet.conf</td>
<td>kubelet</td>
<td>클러스터 각 노드를 위해 필요하다.</td>
</tr>
<tr>
<td>controller-manager.conf</td>
<td>kube-controller-manager</td>
<td>반드시 매니페스트를 <code>manifests/kube-controller-manager.yaml</code>에 추가해야 한다.</td>
</tr>
<tr>
<td>scheduler.conf</td>
<td>kube-scheduler</td>
<td>반드시 매니페스트를 <code>manifests/kube-scheduler.yaml</code>에 추가해야 한다.</td>
</tr>
</tbody>
</table>
<p>다음의 파일은 이전 표에 나열된 파일의 전체 경로를 보여준다.</p>
<pre><code>/etc/kubernetes/admin.conf
/etc/kubernetes/kubelet.conf
/etc/kubernetes/controller-manager.conf
/etc/kubernetes/scheduler.conf
</code></pre>
</div>
</main>
</div>
</div>
<footer class=d-print-none>
<div class=footer__links>
<nav>
<a class=text-white href=/ko/docs/home/>홈</a>
<a class=text-white href=/ko/blog/>블로그</a>
<a class=text-white href=/ko/training/>교육</a>
<a class=text-white href=/ko/partners/>파트너</a>
<a class=text-white href=/ko/community/>커뮤니티</a>
<a class=text-white href=/ko/case-studies/>사례 연구</a>
</nav>
</div>
<div class=container-fluid>
<div class=row>
<div class="col-6 col-sm-2 text-xs-center order-sm-2">
<ul class="list-inline mb-0">
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="User mailing list" aria-label="User mailing list">
<a class=text-white target=_blank href=https://discuss.kubernetes.io>
<i class="fa fa-envelope"></i>
</a>
</li>
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Twitter aria-label=Twitter>
<a class=text-white target=_blank href=https://twitter.com/kubernetesio>
<i class="fab fa-twitter"></i>
</a>
</li>
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Calendar aria-label=Calendar>
<a class=text-white target=_blank href="https://calendar.google.com/calendar/embed?src=calendar%40kubernetes.io">
<i class="fas fa-calendar-alt"></i>
</a>
</li>
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Youtube aria-label=Youtube>
<a class=text-white target=_blank href=https://youtube.com/kubernetescommunity>
<i class="fab fa-youtube"></i>
</a>
</li>
</ul>
</div>
<div class="col-6 col-sm-2 text-right text-xs-center order-sm-3">
<ul class="list-inline mb-0">
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub>
<a class=text-white target=_blank href=https://github.com/kubernetes/kubernetes>
<i class="fab fa-github"></i>
</a>
</li>
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Slack aria-label=Slack>
<a class=text-white target=_blank href=https://slack.k8s.io>
<i class="fab fa-slack"></i>
</a>
</li>
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Contribute aria-label=Contribute>
<a class=text-white target=_blank href=https://git.k8s.io/community/contributors/guide>
<i class="fas fa-edit"></i>
</a>
</li>
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="Stack Overflow" aria-label="Stack Overflow">
<a class=text-white target=_blank href=https://stackoverflow.com/questions/tagged/kubernetes>
<i class="fab fa-stack-overflow"></i>
</a>
</li>
</ul>
</div>
<div class="col-12 col-sm-8 text-center order-sm-2">
<small class=text-white>&copy; 2023 The Kubernetes Authors | Documentation Distributed under <a href=https://git.k8s.io/website/LICENSE class=light-text>CC BY 4.0</a></small>
<br>
<small class=text-white>Copyright &copy; 2023 The Linux Foundation &reg;. All rights reserved. The Linux Foundation has registered trademarks and uses trademarks. For a list of trademarks of The Linux Foundation, please see our <a href=https://www.linuxfoundation.org/trademark-usage class=light-text>Trademark Usage page</a></small>
<br>
<small class=text-white>ICP license: 京ICP备17074266号-3</small>
</div>
</div>
</div>
</footer>
</div>
<script src=/js/popper-1.14.3.min.js integrity=sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49 crossorigin=anonymous></script>
<script src=/js/bootstrap-4.3.1.min.js integrity=sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM crossorigin=anonymous></script>
<script src=/js/main.min.40616251a9b6e4b689e7769be0340661efa4d7ebb73f957404e963e135b4ed52.js integrity="sha256-QGFiUam25LaJ53ab4DQGYe+k1+u3P5V0BOlj4TW07VI=" crossorigin=anonymous></script>
</body>
</html>